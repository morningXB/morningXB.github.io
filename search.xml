<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[强化学习(3)——Model_Based_Methods]]></title>
    <url>%2F2018%2F05%2F25%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-3-%E2%80%94%E2%80%94Model-Based-Methods%2F</url>
    <content type="text"><![CDATA[Introduction所谓的基于模型的方法就是在已知状态转移模型$P_{s\bar{s}}^a$以及奖励获得模型$R_s^a$的情况下，通过planning(规划)来获得最优策略，其实就是我们常接触的动态规划(DP)，通过Bellman或着Bellman_Optional方程迭代计算当前策略的值函数或着最优策略的值函数，有效的解决维度灾难，下面就开始介绍具体的方法。 Policy Prediction所谓Policy Prediction就是通过迭代的方法来就计算当前Policy的值函数，迭代公式如下： Policy IterationPolicy Prediction以及Policy Iteration是基于policy来进行优化的方法，Policy Prediction用来计算当前策略的值函数，通过当前的值函数来优化当前策略，再通过Policy Prediction计算值函数，再优化如此反复，直到当前策略始终等于优化后的策略。如下图所示：所谓的贪婪策略就是选取当前奖励加后续值函数最大的动作，从而获得优化策略。 Value Iteration所谓的Value Iteration即通过Bellman优化方程，直接迭代计算逼近$V_{\star}$，实质上即Policy Iteration中的Policy Prediction每迭代一次就进行优化。迭代方程如下： Next模型已知并且状态空间有限的问题属于动态规划的范畴，也是强化学习的基础，下面介绍当状态空间巨大或者模型不可知的情况下，如何通过与环境交互获得信息来进行强化学习，即model-free的学习方式，是强化学习的核心所在。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习(2)——Markov过程和Bellman等式]]></title>
    <url>%2F2018%2F05%2F23%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-2-%E2%80%94%E2%80%94Markov%E8%BF%87%E7%A8%8B%E5%92%8CBellman%E7%AD%89%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[马尔可夫过程所谓的Markov过程就是未来状态只与当前状态有关，而与以前的状态无关，状态转移概率分布具有独立性。用公式来表示该性质： P[S_{t+1}=s_{t+1}|S_t=s_t]=P[S_{t+1}=s_{t+1}|S_{t+1}=s_{t+1}|S_t=s_t,S_{t-1}=s_{t-1},\ldots,S_1=s_1]拥有Markov的状态集以及状态转移表，可以生成一个Markov链$[s_1,s_2,\ldots,s_{t-1},s_T]$为什么我们提Markov过程呢，因为根据Markov性质，我们发现大部分实际的决策过程都可以通过Markov过程来表征，而强化学习就是用来解决决策策略的。Markov过程S:有限状态集合；P:状态间转移概率矩阵，每一行的和为一。 由简到繁，加入Reward，构成MRP(Markov Reward Process):S:有限状态集合；P:状态间转移概率矩阵，每一行的和为一$P_{s\bar{s}}=P[S_{t+1}=\bar{s}|S_t=s]$；R:经过状态获得的奖励$R_s=E[R_{t+1}|S_t=s]$；$\Gamma$:时间衰减因子。根据相应的MRP模型可以生成Markov链$[s_1,r_2,s_2,r_3,\ldots,s_{t-1},r_T,s_T]$时间点t获得回报(return):从当前时间点往后获得Reward要逐步衰减，乘gamma时间因子，越往后衰减越大。所以值函数$V(s)=E[G_t|S_t=s]$通过下式的推导：即可得到Bellman方程： v(s)=E[R_{t+1}+\Gamma*v(S_{t+1})|S_t=s]可以看出Bellman等式是关于值函数的迭代式。 在加入Action，引入策略$\pi$构成MDP(Markov Decsion Process)与MRP不同的是，状态转移以及获得奖励都要采取的Action有关，采取何种动作组成了策略。 Bellman等式v(s)=E[R_{t+1}+\Gamma*v(S_{t+1})|S_t=s]由以上等式可以获得： v(s)=R_s+\Gamma*\sum_{\bar{s}\in S} P_{s\bar{s}}v(\bar{s})即当前状态值函数等于当前获得奖励期望加上下一个状态的值函数期望。(迭代式)可以推出Bellman等式矩阵形式：$v=R+\GammaPv$所以$v=(1-\GammaP)^{-1}R$在知道model的所有信息时，可以采用上式计算该MRP的值函数，但是当维度过高时，会发生维度灾难，可以通过迭代式来进行求解。 在MDP中除了状态值函数之外还有状态动作Q价值函数，表示在状态S下采取动作A后获得的回报Q(S,A)。在MRP的基础上推导MDP下的Bellman等式：如此通过迭代式计算可以获得在policy$\pi$下的值函数。 Bellman优化等式在MDP中不同的policy有不同的值函数，目的当然是希望过的最大的值函数。对于两个策略，如果在策略A下的所有值函数大于策略B，那么策略A优于策略B。所以在知道$Q_\star$的情况下，即可获得最优策略。下面是优化Bellman等式通过迭代可以获得$Q_\star$。 next在Bellman方程中我们求得是当前policy的值函数，在优化Bellman方程中我们求得是最优值函数，在维度较低时可以通过矩阵求解，但在维度过大或者非线性优化bellman方程时，不能直接求解，只能通过迭代式求得，下一节关于model-based的强化学习算法，包括policy prediction，policy iteration，value iteration。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习(1)——introduction]]></title>
    <url>%2F2018%2F05%2F22%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-1-%E2%80%94%E2%80%94introduction%2F</url>
    <content type="text"><![CDATA[强化学习是一个多学科，多领域融合，用于决策的学习方法，在机器学习学科中，主要有监督学习和非监督学习两大类，而强化学习是属于机器学习的第三类学习方法，从2015年deepmind使用RL(reinforcement learning)学习atari游戏，超过人类玩家，2016年deepmid开发alphago，2017年的alphazero，超过人类顶尖选手，使得RL从上个世纪的提出得以快速发展。强化学习与监督学习和非监督学习的不同：监督学习的学习数据有特征和相应的label即正确值，而非监督学习的学习数据有特征，但是没有label，常见方法kmeans等，对于强化学习并没有事先准备好的训练数据，强化学习需要自我实践获得数据，这里的数据指reward，并非label，通过反馈的奖励reward学习优化自我的决策选择。下面介绍一下强化学习的学习过程以及一些主要元素：agent：智能体，即我们通过强化学习试图训练的类似于人类的程序，可以自行采取最优行动。action：行动$A_t$,类似于人类在某一状态下，执行的某一动作，通过动作改变环境或者自身的状态，这里是agent智能体在时间点t采取的动作。observation：智能体通过周围环境获取的相关条件，比如环境中有几个树，是白天还是黑夜等等。state：agent通过周围环境的observation以及自身的属性，合成获得agent当前的状态，并且agent会根据state来猜去行动。reward：奖励，agent采取行动后会获得相应的奖励，$ R_t $表示时间点t时获得的奖励，比如游戏存活R=1，游戏失败R=-1000，学习的最终目标就是使得$\sum_{t=1}^T R_t$最大。policy：agent采取行动的策略，分为绝对策略和随机策略，分别是在某一state下决定采取某一最优动作和采取不同动作有不同概率。通常用$\pi$表示。episode：表示一次与环境的交互完整过程，比如玩一款游戏直到输或赢$[S_1,A_1,R_2,S_2,A_2,\ldots,S_T]$model：分为状态转移model和reward模型，分别是状态之间转移的概率分布以及状态下执行动作的期望奖励。 P_{s\bar{s}}^a=P[\bar{S}=\bar{s}|A=a,S=s]R_s^a=E[R|A_t=a,S_t=s]学习过程：agent初始化一个policy，开始接受observation，得到一个当前state，根据policy做出action，获得reward转移到下一个state，根据获得的reward优化policy，如此反复直到policy最优。在强化学习中奖励具有延迟性，即当前动作不仅影响当前state以及reward对未来也存在影响。定义值函数来评价一个状态的优劣： V_{\pi} (s)=E[R_{t+1}+\Lambda*R_{t+1}+\Lambda^2*R_{t+2}+\ldots+\Lambda^n*R_{t+n-1}|S_t=s]其中lambda就是reward的时间衰减因子。强化学习的方法分类：value based：mc，td，sarsa ，Q-learningpolicy based：policy gradientactor critic 强化学习中通常面临的是model-free的情况，即不知道转移和奖励模型，此时就需要通过取样episode学习learning，获得优化policy，当然也可以学习model然后通过model来planning得到优化ploicy。在model-based的情况，我们知道所有状态的转移概率，所有奖励大小，此时问题转化为动态规划问题，我们成为planning，这是model-free方法的基础，也是强化学习的一个重要分支，alphago中采用的蒙特卡洛树搜索就是典型planning问题。但是大部分时候由于状态连续动作连续或者状态数目过多，我们的model过大，所以采用model-free的方法来解决。此外强化学习比较中的一个tradeoff就是探索和利用，探索就是开发那些从来没有做过的动作，利用就是直接按照经验采取当前最优的动作，探索过多会导致学习时间过长不收敛，只利用会导致结果为次优策略即本地收敛。到这儿强化学习的基本介绍就结束了。下一节将会说的是markov过程，作为强化学习一切的基础和推导出的bellman方程。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Work Plan]]></title>
    <url>%2F2018%2F05%2F02%2FWork-Plan%2F</url>
    <content type="text"><![CDATA[看到师兄师姐们，纷纷找到工作真的是心慌慌呀。还有一年差不多也要找工作了。至于自己工作的方向，我还没有一个明确的规划，一方面这些年陆续学习了不少类别的知识，另一方面作为一个硕士研究生，觉得这样读完毕业太草率了，想有所作为，甚是惭愧。自此列下接下来几个月的工作计划：1.我个人是通过吴恩达的斯坦福教程入门机器学习的，接下来的书单大概是西瓜树，深度学习等，方向大概是深度学习中的强化学习，个人对其在starcraft中的AIBot开发很感兴趣，预计会在此分享一些机器学习基础以及相关论文知识。2.当然不会忘记导师的研究方向，分布式存储方面预计会做一篇文章出来，这里就不说了，可以的话会写一些相关进度。3.希望时间富裕的话，还会分享一些其他知识。]]></content>
      <categories>
        <category>随口一说</category>
      </categories>
      <tags>
        <tag>Welcome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-AVLTree]]></title>
    <url>%2F2018%2F05%2F02%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-AVLTree%2F</url>
    <content type="text"><![CDATA[AVL树首先是一个二叉搜索树，对于任意根节点，左孩子小于自身，右孩子大于自身，通过这种特殊的数据结构，理想情况下，可以将搜索复杂度由普通的O(n)下降为O(logn)，但是由于二叉树插入顺序不同，考虑到极端的插入顺序，会造成特殊的二叉搜索树，比如所有节点没有左孩子，我们称为搜索树失衡，这种情况下，搜索树的复杂度仍然为O(n)。为了充分利用好二叉搜索树的优点，在每次插入和删除树的节点后我们需要调节树的平衡，这就是AVL树也就是平衡二叉搜索树的由来。那么如何定义AVL树的平衡呢？对于每一个根结点，其左子树和右子树的高度差的绝对值小于2即，该在节点上平衡，如果一个树的所有节点都平衡那么该树为平衡树。于是在二叉搜索树节点的基础上我们增加一个属性bf，用来记录当前节点平衡状态，如果bf=2，即左子树过高，左失衡，相反bf=-2，即右失衡，bf=0，该节点保持平衡，bf=1/-1，表示该节点相对平衡，即将失衡。对于AVL树的操作难点，主要就是插入节点以及删除节点的平衡调整，下面我们着重介绍插入节点后的平衡调整。因为左右失衡是对称的操作，所以这里举一个方向例子。如图1，插入节点3时，打破了左子树的平衡，自底向上调整，节点8的bf=2，节点6的bf=1，此时我们通过右旋来处理，如图2，围绕节点6右旋，节点8挂到节点6的右子树上，节点6作为节点10的左子树根节点。节点6原有的右子树挂到节点8的左子树上。（上述过程，节点6的右子树为空）如图3，插入节点7时，同样打破了左子树的平衡，自底向上的调整，结果为图4所示，很明显结果不符合二叉搜索树的特性，原因是节点8的bf=2而节点6的bf=-1，左右相反，与上面的例子不同，对于这种情况，先进行左旋，在进行右旋，左旋后的结果为图5，此时节点7和节点8的bf同号，再右旋可以得到平衡的二叉搜索树如图6所示。同样对于删除节点，删除操作与搜索二叉树的删除操作类似，寻找目标节点的前序或者后继节点代替，然后删除代替节点即可，在此基础上，同样自底向上的检查子树节点的bf值，并进行调整。java实现代码如下：节点类123456public class AVLTreeNode &#123; int value = 0; int bf = 0;// -1,0,1 AVLTreeNode left = null; AVLTreeNode right = null;&#125; AVL树类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258public class AVLTree &#123; AVLTreeNode root = null; boolean taller = false; public void init(int[] data) &#123; for (int i = 0; i &lt; data.length; i++) &#123; insert(data[i], root); &#125; &#125; /** * 删除AVL树中节点 同时保持树的平衡性 * * @param value * @param p * @return */ public AVLTreeNode delete(int value, AVLTreeNode p) &#123; AVLTreeNode temp; int oldheight; if (p == null) &#123; return null; &#125; else if (value &lt; p.value) &#123; oldheight = getDepthByRoot(p.left); p.left = delete(value, p.left); p.bf = p.bf - (oldheight - getDepthByRoot(p.left)); if (p.bf == -2) &#123; rightBalance(p); &#125; &#125; else if (value &gt; p.value) &#123; oldheight = getDepthByRoot(p.right); p.right = delete(value, p.right); p.bf = p.bf + (oldheight - getDepthByRoot(p.right)); if (p.bf == 2) &#123; leftBalance(p); &#125; &#125; else if (p.left != null &amp;&amp; p.right != null) &#123; temp = AVLFindMin(p.right); p.value = temp.value; p.right = delete(p.value, p.right); &#125; else &#123; temp = p; if (p.left == null) &#123; p = p.right; &#125; else if (p.right == null) &#123; p = p.left; &#125; temp = null; &#125; return p; &#125; /** * 用于寻找root的后驱节点 即右子树中最小的节点 * * @param right * @return */ private AVLTreeNode AVLFindMin(AVLTreeNode right) &#123; AVLTreeNode min = right; AVLTreeNode res = null; while (min.left != null) &#123; res = min; min = min.left; &#125; return res; &#125; /** * AVL插入节点并调整平衡 * * @param value * @param p * @return */ public boolean insert(int value, AVLTreeNode p) &#123; if (p == null) &#123; AVLTreeNode node = new AVLTreeNode(); node.bf = 0; node.value = value; taller = true; &#125; else &#123; if (value == p.value) &#123; taller = false; return false; &#125; if (value &lt; p.value) &#123; if (!insert(value, p.left)) &#123; return false; &#125; if (taller) &#123; switch (p.bf) &#123; case 1: leftBalance(p); taller = false; break; case -1: p.bf = 0; taller = false; break; case 0: p.bf = 1; taller = true; break; &#125; &#125; &#125; else &#123; if (!insert(value, p.right)) &#123; return false; &#125; if (taller) &#123; switch (p.bf) &#123; case 1: p.bf = 0; taller = false; break; case 0: p.bf = -1; taller = true; break; case -1: rightBalance(p); p.bf = 0; break; &#125; &#125; &#125; &#125; return true; &#125; /** * 对于p节点 bf&lt;-1 左旋 * * @param p */ private void L_Rotate(AVLTreeNode p) &#123; AVLTreeNode R; R = p.right; p.right = R.left; R.left = p; p = R; &#125; /** * 对于p节点 bf&gt;1 右旋 * * @param p */ private void R_Rotate(AVLTreeNode p) &#123; AVLTreeNode L; L = p.left; p.left = L.right; L.right = p; p = L; &#125; private void rightBalance(AVLTreeNode p) &#123; AVLTreeNode R = p.right; AVLTreeNode Rl = null; switch (R.bf) &#123; case -1: p.bf = 0; R.bf = 0; L_Rotate(p); break; case 1: Rl = R.left; switch (Rl.bf) &#123; case 1: p.bf = 0; R.bf = -1; break; case 0: p.bf = 0; R.bf = 0; break; case -1: p.bf = 1; R.bf = 0; break; &#125; Rl.bf = 0; R_Rotate(p.right); L_Rotate(p); break; &#125; &#125; private void leftBalance(AVLTreeNode p) &#123; AVLTreeNode L = p.left; AVLTreeNode Lr = null; switch (L.bf) &#123; case 1: p.bf = 0; L.bf = 0; R_Rotate(p); break; case -1: // 先左子树左旋在p树右旋 Lr = L.right; switch (Lr.bf) &#123; case 1: L.bf = 0; p.bf = -1; break; case 0: L.bf = 0; p.bf = 0; break; case -1: p.bf = 0; L.bf = 1; break; &#125; Lr.bf = 0; L_Rotate(p.left); R_Rotate(p); break; &#125; &#125; /** * 搜索树 如果找到返回节点否则返回null * * @param value * @param root * @return */ public AVLTreeNode search(int value, AVLTreeNode root) &#123; if (root == null) &#123; return null; &#125; else &#123; if (root.value == value) &#123; return root; &#125; else if (root.value &gt; value) &#123; return search(value, root.left); &#125; else &#123; return search(value, root.right); &#125; &#125; &#125; private int getDepthByRoot(AVLTreeNode node) &#123; if (node == null) &#123; return 0; &#125; if (node.left == null &amp;&amp; node.right == null) &#123; return 1; &#125; int leftdepth = getDepthByRoot(node.left); int rightdepth = getDepthByRoot(node.right); return leftdepth &gt; rightdepth ? leftdepth + 1 : rightdepth + 1; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-图的拓扑排序算法]]></title>
    <url>%2F2018%2F04%2F09%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E7%9A%84%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[所谓拓扑排序是一种图论中的顶点排序算法，将有向图中的顶点以线性方式进行排序，对于任何连接自顶点u到顶点v的有向边，最后排序结果顶点u必然在顶点v之前，拥有顺序的顶点序列，存在前后关系或者没有联通前后关系，所以拓扑排序的图必然是有向无环图(DAG)。传统的拓扑排序算法流程大概是：a.从有向图中选取一个没有前驱的顶点，并输出之；b.从有向图中删去此顶点以及所有以它为尾的弧；重复上述两步，直至图空。经典的算法有kahn以及dfs.1.kahn：该算法就是对上述流程的实现，L&lt;-Empty list that will contain the sorted elementsS&lt;-Set of all nodes with no incoming edgeswhile S is non-empty do remove a node n from S insert n into L foreach node m with an edge e from nto m do remove edge e from thegraph ifm has no other incoming edges then insert m into Sif graph has edges then return error (graph has at least onecycle)else return L (a topologically sortedorder)java实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445public void kahnTopologicalSort(int[] path) &#123; int[][] matrixcopy = Arrays.copyOf(matrix, matrix.length); int count = 0; ArrayList&lt;Integer&gt; S = new ArrayList&lt;&gt;(); boolean isNoIncoming = true; for (int i = 0; i &lt; vexnum; i++) &#123; isNoIncoming = true; for (int j = 0; j &lt; vexnum; j++) &#123; if (matrixcopy[j][i] &lt; Integer.MAX_VALUE) &#123; isNoIncoming = false; break; &#125; &#125; if (isNoIncoming) &#123; S.add(i); &#125; &#125; while (!S.isEmpty()) &#123; int vex = S.get(0); path[count++] = vex; for (int i = 0; i &lt; vexnum; i++) &#123; if (matrixcopy[vex][i] &lt; Integer.MAX_VALUE) &#123; matrixcopy[vex][i] = Integer.MAX_VALUE; isNoIncoming = true; for (int j = 0; j &lt; vexnum; j++) &#123; if (matrixcopy[j][i] &lt; Integer.MAX_VALUE) &#123; isNoIncoming = false; break; &#125; &#125; if (isNoIncoming) &#123; S.add(i); &#125; &#125; &#125; &#125; if (count != vexnum) &#123; System.out.println("fail to sort"); &#125; else &#123; System.out.println("success to sort look up Array path"); &#125;&#125; 2.dfs:dfs利用图的深度优先遍历算法，利用栈来记录拓扑排序的顺序。L ← Empty list that will contain the sorted nodesS ← Set of all nodes with no outgoing edgesfor each node n in S do visit(n)function visit(node n) if n has not been visited yet then mark n as visited for each node m with an edgefrom m to ndo visit(m) add n to L结尾的add n to L保证了当前节点在没有后续的情况下被加入栈，体现了拓扑排序的顺序。java实现：12345678910111213141516171819202122232425262728public void dfsTopologicalSort(int[] path) &#123; boolean[] visit = new boolean[vexnum]; for (int i = 0; i &lt; vexnum; i++) &#123; visit[i] = false; &#125; Stack&lt;Integer&gt; L = new Stack&lt;&gt;(); for (int i = 0; i &lt; vexnum; i++) &#123; if (visit[i] == false) &#123; dfs(i, visit, L); &#125; &#125; for (int i = 0; i &lt; vexnum; i++) &#123; path[i] = L.pop(); &#125;&#125;private void dfs(int i, boolean[] visit, Stack&lt;Integer&gt; L) &#123; visit[i] = true; for (int j = 0; j &lt; vexnum; j++) &#123; if (matrix[i][j] &lt; Integer.MAX_VALUE) &#123; if (visit[j] == false) &#123; dfs(j, visit, L); &#125; &#125; &#125; L.push(i);&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-图的最短路径算法]]></title>
    <url>%2F2018%2F04%2F09%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[所谓最短路径算法就是图中任何一个顶点到其他顶点的最短路径长度以及path。经典的算法有dijkstra，还有简单聪明的floyd算法。1.dijkstra最短路径的经典算法，需要两个集合A，B，A用来存储已经找到最短路径以及长度的顶点，初始化A中存放v0顶点即我们的起始顶点，B中存放未确定最短路径的顶点，另外用一个数组存放v0到各个顶点的当前最短距离。在B中寻找到v0最短的顶点vi，加入A，然后用vi作为中介节点来连接v0到B集合中顶点的长度，更新最短距离数组，重复上述步骤直到B集合为空，此时得到v0到所有其他节点的最短路径长度。伪代码：func dijkstra v0 初始点 pathMatrix init v0最短路径记录数组 shortPath init length between v0 to vi 最短路径长度数组 isfinal init 0 是否找到最短路径数组 isfinal[v0] = 1 shortPath[v0] = 0 foreach all vex look for the smallest path from shortPath and isfinal=0 get k vex isfinal[k] = 1 for all vex if isnotfinal and min+length(vex to k)&lt;shortpath[vex] update shortpath and pathMatrix 下面是java实现：123456789101112131415161718192021222324252627public void dijkstra(int v0, int[] pathMatrix, int[] shortPath) &#123; int[] isfinal = new int[vexnum]; int min, k = 0; for (int i = 0; i &lt; vexnum; i++) &#123; pathMatrix[i] = v0; isfinal[i] = 0; shortPath[i] = matrix[v0][i]; &#125; isfinal[v0] = 1; shortPath[v0] = 0; for (int i = 1; i &lt; vexnum; i++) &#123; min = Integer.MAX_VALUE; for (int j = 0; i &lt; vexnum; j++) &#123; if (isfinal[j] != 1 &amp;&amp; shortPath[j] &lt; min) &#123; min = shortPath[j]; k = j; &#125; &#125; isfinal[k] = 1; for (int j = 0; j &lt; vexnum; j++) &#123; if (isfinal[j] != 1 &amp;&amp; min + matrix[k][j] &lt; shortPath[j]) &#123; shortPath[j] = min + matrix[k][j]; pathMatrix[j] = k; &#125; &#125; &#125;&#125; 2.floyddijkstra算法可以获得一个顶点到其他顶点的最短距离路径，这样对每个顶点重复运行算法可以求得图中任意两个顶点之间的最短距离。floyd算法简单明了的实现了上述要求，虽然算法的复杂度并没有下降，但是比较容易理解其简单。其核心就是寻找两个顶点之间可以缩短距离的桥梁节点。初始化两个矩阵表，一个记录两点之间的最短距离，一个记录任意一个顶点的后续顶点。func floyd init pathMatrix init shortPath foreach vex i foreach vex j foreach vex k if length(j-&gt;i and i-&gt;k)k) update shortPath update pathMatrix下面是java实现：1234567891011121314151617181920212223242526272829/* * floyd算法 时间复杂度和dijkstra相同，但是算法简单明了，算出任意两个点之间的最短距离和路径 */public void floyd(int[][] pathMatrix, int[][] shortPath) &#123; int select = 0; // 先初始化 for (int i = 0; i &lt; vexnum; i++) &#123; for (int j = 0; j &lt; vexnum; j++) &#123; shortPath[i][j] = matrix[i][j]; pathMatrix[i][j] = j; &#125; &#125; // 三重循环 更新信息 for (int i = 0; i &lt; vexnum; i++) &#123; for (int j = 0; j &lt; vexnum; j++) &#123; for (int k = 0; k &lt; vexnum; k++) &#123; select = shortPath[j][i] == Integer.MAX_VALUE || shortPath[i][k] == Integer.MAX_VALUE ? Integer.MAX_VALUE : shortPath[j][i] + shortPath[i][k]; if (select &lt; shortPath[j][k]) &#123; shortPath[j][k] = shortPath[j][i] + shortPath[i][k]; pathMatrix[j][k] = pathMatrix[j][i]; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-图的最小生成树算法]]></title>
    <url>%2F2018%2F04%2F09%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E7%9A%84%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一个有n个顶点的连通图存在最小生成树，该树由n个顶点和n-1条边构成，删去了原图中的一些边，并且树中边的权重和最小。这在实际生活中经常用到，比如在n个乡镇之间需要互通网络，需要铺设光纤，这时候考虑到乡镇之间的距离纪委权重，要让权重之和最小并且所有乡镇之间互通，用最小生成树算法刚好合适。最小生成树算法一般由两种prim和kruskal算法，分别从图的顶点和边入手。1.prim当原图的n个顶点都加入到最小生成树中即生成完成。随意选取一个顶点开始，记录下当前顶点构成的图到其他所有顶点的最短距离，选取最短路径的邻点加入生成树中，利用新加入的点来更新最短距离数组，如果需要（距离更短）。循环直到所有顶点加入。func prim init lowcost 记录最短距离 init adjvex 记录当前顶点的最短距离邻点 lowcost[0] = 0;// 表示点0已经加入 adjvex[0] = 0; 初始化到点0的最短距离以及邻点表 loop vexnum-1 lookfor the shortest path and lowcost!=0 vex k lowcost[k] = 0 update adjvex and lowcostjava实现如下：1234567891011121314151617181920212223242526272829303132333435// prim方法通过寻找点的最短连线，逐个添加边public void prim() &#123; int[] lowcost = new int[vexnum]; int[] adjvex = new int[vexnum]; int min, k = 0;// k 记录最短的edge的相关顶点 lowcost[0] = 0;// 表示点0已经加入 adjvex[0] = 0; for (int i = 1; i &lt; vexnum; i++) &#123; lowcost[i] = matrix[0][i]; adjvex[i] = 0; &#125; for (int i = 0; i &lt; vexnum - 1; i++) &#123; min = Integer.MIN_VALUE; for (int j = 1; j &lt; vexnum; j++) &#123; if (lowcost[j] != 0 &amp;&amp; lowcost[j] &lt; min) &#123; min = lowcost[j]; k = j; &#125; &#125; lowcost[k] = 0; System.out.println(k + "--" + adjvex[k]); // 更新最短连线记录 for (int j = 1; j &lt; vexnum; j++) &#123; if (lowcost[j] != 0 &amp;&amp; matrix[k][j] &lt; lowcost[j]) &#123; lowcost[j] = matrix[k][j]; adjvex[j] = k; &#125; &#125; &#125;&#125; 2.kruskalkruskal方法直接从原图的边入手，将原图的边从小到大排序，依次加入生成树中，每次加入前判断加入该边后是否会构成环，由于原图是连通图，所以循环所有的边即可得到最小生成树。func kruskal: sort edges loop edgenum add one edge check wheather being circlejava代码实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// kruskal 方法直接通过寻找最短边添加构成最小生成树，但是要判断是否构成回路 public void kruskal() &#123; // 先对所有的边排序 Edge[] edges = sort(); int m, n; int[] parent = new int[vexnum]; for (int i = 0; i &lt; vexnum; i++) &#123; parent[i] = -1; &#125; for (int i = 0; i &lt; edgenum; i++) &#123; m = find(edges[i].m, parent); n = find(edges[i].n, parent); if (m != n) &#123; parent[m] = n;// 合并连通分量顶点集合 System.out.println(edges[i].m + "--" + edges[i].n + " " + edges[i].weight); &#125; &#125; &#125; // 寻找m顶点的连通分量集合的root private int find(int i, int[] parent) &#123; while (parent[i] &gt;= 0) &#123; i = parent[i]; &#125; return i; &#125; // 正对无向图的排序 private Edge[] sort() &#123; Edge[] edges = new Edge[edgenum]; Edge temp; int index = 0; for (int i = 0; i &lt; vexnum; i++) &#123; for (int j = i + 1; i &lt; vexnum; j++) &#123; if (matrix[i][j] &lt; Integer.MAX_VALUE) &#123; edges[index++] = new Edge(i, j, matrix[i][j]); &#125; &#125; &#125; for (int i = 0; i &lt; edgenum - 1; i++) &#123; for (int j = 0; j &lt; edgenum - i - 1; j++) &#123; if (edges[j].weight &gt; edges[j + 1].weight) &#123; temp = edges[j]; edges[j] = edges[j + 1]; edges[j + 1] = temp; &#125; &#125; &#125; return edges; &#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-图的遍历]]></title>
    <url>%2F2018%2F04%2F09%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[不同于tree结构的自顶向下，一对多的层次结构，图结构是多对多的数据结构，所以采用树的遍历方法可能会造成重复访问，所以在遍历时需要记录下每个节点的访问记录，防止重复访问，主要分为两种遍历方法：深度优先以及广度优先。1.深度优先其主要思想是，访问当前节点，然后自左向右访问节点的第一个邻节点，对邻节点同样左向右寻找第一个邻节点访问，如果访问过就访问第二节点，直到所有的节点访问完毕。（假设开始节点联通所有其他节点），如果不联通，循环所有节点执行上述过程即可。伪代码：func depth_visit init visit 访问记录数组 start 开始节点 depth_visit_Internal(start,visit)func depth_visit_Intrnal visit[start]=true for vex connect to start if visit[vex]==false depth_visit_Intrnal(vex,visit) 下面是java的实现，实现中图结构采用邻接矩阵来存储123456789101112131415161718192021222324252627public class SimpleGraph &#123; int edgenum; int vexnum; String[] vexs; int[][] matrix;&#125;/** 深度优先遍历 param:start 开始遍历的顶点标号 利用一个数组记录顶点是否访问*/public void depthTraversal(int start) &#123; boolean visit[] = new boolean[vexnum]; for (int i = 0; i &lt; vexnum; i++) &#123; visit[i] = false; &#125; depthTraversal_Internal(start, visit); &#125; private void depthTraversal_Internal(int start, boolean visit[]) &#123; System.out.print(start + " "); visit[start] = true; for (int i = 0; i &lt; vexnum; i++) &#123; if (matrix[start][i] &lt; Integer.MAX_VALUE &amp;&amp; visit[i] == false) &#123; depthTraversal_Internal(i, visit); &#125; &#125; &#125; 2.广度优先其主要思想与树的层次遍历相似，同样用visit数组来记录访问记录，用一个队列来存储待访问的顶点。伪代码：func breadhTraversal init visit 访问记录数组 start 开始节点 quene 待访问队列 quene.add(start) while quene is not empty visit[quene.top]=true; for vex connect to quene.top if visit[vex]==false quene.add(vex) quene.pop下面是java的实现代码：123456789101112131415161718public void breadhTraversal(int start) &#123; boolean visit[] = new boolean[vexnum]; for (int i = 0; i &lt; vexnum; i++) &#123; visit[i] = false; &#125; ArrayList&lt;Integer&gt; quene = new ArrayList&lt;Integer&gt;(); quene.add(quene.size(), start); while (!quene.isEmpty()) &#123; int index = quene.remove(0); System.out.print(index + " "); visit[index] = true; for (int i = 0; i &lt; vexnum; i++) &#123; if (matrix[index][i] &lt; Integer.MAX_VALUE &amp;&amp; visit[i] == false) &#123; quene.add(quene.size(), index); &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-二叉树的遍历]]></title>
    <url>%2F2018%2F04%2F09%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[定义二叉树的定义：是n(n&gt;=0)个节点的有限结合，该集合或者为空集（称为空二叉树），或者由一个根节点和两颗互不相交的，分别称为root节点的左子树和右子树的二叉树组成。摘自大话数据结构。下图是一个典型的二叉树： 性质二叉树的性质： 遍历遍历分为前序，中序和后序遍历，所谓前序遍历就是从root节点开始，先遍历本节点，在依次遍历左子树和右子树。而中序就是先遍历左子树再访问本节点再遍历右子树，后序遍历就是依次遍历左子树和右子树然后访问本节点。下面是java的代码简单实现,采用递归的方式遍历完整的树结构，visit_fuc为一个访问接口对象。1234567891011121314151617181920212223242526public void PreOrderTraverse(LinkedBinaryTreeNode&lt;T&gt; root, NodeVisit&lt;T&gt; visit_fuc) &#123; if (root == null) &#123; return; &#125; visit_fuc.visit(root); PreOrderTraverse(root.left, visit_fuc); PreOrderTraverse(root.right, visit_fuc); &#125; public void InOrderTraverse(LinkedBinaryTreeNode&lt;T&gt; root, NodeVisit&lt;T&gt; visit_fuc) &#123; if (root == null) &#123; return; &#125; InOrderTraverse(root.left, visit_fuc); visit_fuc.visit(root); InOrderTraverse(root.right, visit_fuc); &#125; public void PostOrderTraverse(LinkedBinaryTreeNode&lt;T&gt; root, NodeVisit&lt;T&gt; visit_fuc) &#123; if (root == null) &#123; return; &#125; PostOrderTraverse(root.left, visit_fuc); PostOrderTraverse(root.right, visit_fuc); visit_fuc.visit(root); &#125; 其他在处理树结构的时候递归经常用到，比如计算树的高度，一次计算左树和右树高度，取较大的加一就是此节点为root的树的高度，删除树节点时，依次删除该节点的左子树和右子树节点，然后再删除此节点。简单实现如下：12345678910111213141516171819202122232425262728public void deleteNode(LinkedBinaryTreeNode&lt;T&gt; node) &#123; if (node == null) &#123; return; &#125; if (node.left != null) &#123; deleteNode(node.left); &#125; if (node.right != null) &#123; deleteNode(node.right); &#125; node = null; &#125;public int getDepth() &#123; return getDepthByRoot(root); &#125; private int getDepthByRoot(LinkedBinaryTreeNode&lt;T&gt; node) &#123; if (node == null) &#123; return 0; &#125; if (node.left == null &amp;&amp; node.right == null) &#123; return 1; &#125; int leftdepth = getDepthByRoot(node.left); int rightdepth = getDepthByRoot(node.right); return leftdepth &gt; rightdepth ? leftdepth + 1 : rightdepth + 1; &#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-KMP字符串模式匹配]]></title>
    <url>%2F2018%2F03%2F23%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-KMP%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[传统的模式匹配采用的是从原字符串的第一位依次截取字符串，然后与模式字符串比较，搜索匹配，所以在最坏情况下的时间复杂度为O(n*m)，n为原字符串的长度，m为模式字符串的长度。下面介绍一种优化算法KMP算法，时间复杂度为O(n+m)，它主要利用了模式字符串中的相同子串特点，在许多情况下，传统的模式匹配中的许多遍历是不必要的。下面举个例子说明：第一步检测前五个字符相同，但是第6个字符不同，传统算法，是模式字符串后移一步，继续比较，但是我们已经知道模式字符串中的第一个字符不等于第2-5的字符，所以当然2-5步的比较是没有必要的。KMP算法正是利用这个特点。在KMP算法中需要计算模式字符串的每个字符之前的字符串的最长相等前缀和后缀的长度，构成next数组。对于长度为j的模式字符串，next数组计算公式如下：（不同的程序设计使得next元素整体加1或减1）。对于字符串“ABCDABD”，next数组为：具体的例子运算过程可以参考大话数据结构一书的字符串章节。利用next数组：当模式字符串的第j个字符不相等时，next[j]=k,那么意味着第j个字符的前k个字符与模式字符串前k个字符相等，那么模式字符串没有必要后移一位比较，直接移动到原字符串中与后k个字符相等的位置，比较模式字符串的第k+1个以后的字符。匹配失配：j = next [j]，模式串向右移动的位数为：j - next[j]。换言之，当模式串的后缀pj-k pj-k+1, …, pj-1 跟文本串si-k si-k+1, …, si-1匹配成功，但pj 跟si匹配失败时，因为next[j] = k，相当于在不包含pj的模式串中有最大长度为k 的相同前缀后缀，即p0 p1 …pk-1 = pj-k pj-k+1…pj-1，故令j = next[j]，从而让模式串右移j - next[j] 位，使得模式串的前缀p0 p1, …, pk-1对应着文本串 si-k si-k+1, …, si-1，而后让pk 跟si 继续匹配。如下图所示：（该图形象地解释了为什么j=next[j]，实质上就是模式串向右移动j-next[j]位.）现在问题的重点变为next数组的求解：对于任意字符串next[0]=-1,next[1]=0,能否通过前一个next元素，以及当前字符来计算当前next元素。当然是可以的：假设当前为第j个字符，如果第next[j]=k个字符和当前字符相等，那么next[j+1]=next[j]+1=k+1。可见第二个c和第一个c相等所以next[6]=1+1=2;如果两个元素不相等的话，那么需要重新找最大的相等的后缀和前缀。比如D和E不相等，这时候进一步缩小前缀，k=next[k]；下图展示自我匹配的过程。在这个算法的基础上还有一个优化，试想当Pj和Si不等但是Pk和Pj相等时，下面的比较是不必要的，因为Pk当然不等于Si，所以这是后next[j]=next[next[j]];下面是算法的java实现：12345678910111213141516171819202122232425262728293031323334353637package string;public class KMP_String &#123; public int getIndexByKMP(String s, String p) &#123; int[] next = get_Next(p); int i=0,j=0; while(i&lt;s.length()&amp;&amp;j&lt;p.length()) &#123; if(j==-1||(s.charAt(i)==p.charAt(j))) &#123; j++; i++; &#125;else &#123; j=next[j]; &#125; &#125; return j==p.length()?i-j:-1; &#125; private int[] get_Next(String p) &#123; int length = p.length(); int[] next = new int[length]; next[0] = -1; int j = 0, k = -1;// 记录上一个next值 while (j &lt; length - 1) &#123; if (k == -1 || p.charAt(k) == p.charAt(j)) &#123; k++; j++; if (p.charAt(k) == p.charAt(j)) &#123; next[j] = next[k]; &#125; else &#123; next[j] = k; &#125; &#125; else &#123; k = next[k]; &#125; &#125; return next; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-时间复杂度]]></title>
    <url>%2F2018%2F03%2F23%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[衡量算法的方法：时间复杂度and空间复杂度时间复杂度计算：采用大O阶数表示法：T(n)=O(f(n))，n为问题规模。对于算法的执行步数，忽略次高阶项和常数项，取最高阶项将系数变为1，就可得到算法的时间复杂度。时间复杂度分为最差和平均复杂度，一般默认为最差时间复杂度。例子：执行12步，所以时间复杂度为O(1);执行2log2n+1步，所以时间复杂度为O(log2n);执行2n2+1步，所以时间复杂度为O(n2);执行n2/2+n/2步，所以时间复杂度为O(n2);常见的时间复杂度：时间从小到大依次排序：参考资料：《大话数据结构》第二章。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thrift]]></title>
    <url>%2F2018%2F03%2F15%2Fthrift%2F</url>
    <content type="text"><![CDATA[简介由于学业需求，最近在阅读Alluxio的源代码，发现其在rpc方面主要采用了thrift以及netty两种通信框架，其中netty主要负责的是数据的传输服务，而thrift负责的是request的请求响应动作发送一些短消息。本文主要关于thrift的简介以及使用实例。Thrift是一个软件框架，提供不同语言之间的RPC服务，首先编写thrift文件，然后通过thrift编译器生成不同语言的接口文件，再实现接口文件，编写服务器端和客户端程序（可在不同语言下），实现RPC通信。 安装官网：http://thriftruan.apache.org提供不同系统下的软件下载，以及编译需要的依赖。在MacOS下最新的thrift需要boost以及libevent，下载编译安装上述软件环境boost官网：http://www.boost.org下载解压然后执行：12./bootstrap.shsudo ./b2 threading=multi address-model=64 variant=release stage install libevent官网：http://libevent.org下载解压然后执行：123./configure --prefix=/usr/local makesudo make install 下载解压thrift最新版本，然后执行：1./configure --prefix=/usr/local/ --with-boost=/usr/local --with-libevent=/usr/local Mac环境下会出现：Bison version 2.5 or higher must be installed on the system!通过homebrew下载最新bisonbrew install bison依然出现上述问题，在mac中默认使用xcode自带的bison所以切换xcode中的bison执行下述指令：123cd /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/sudo mv bison bison111sudo cp /usr/local/Cellar/bison/3.0.4/bin/bison /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ 再次执行：1234./configure --prefix=/usr/local/ --with-boost=/usr/local --with-libevent=/usr/localmakemake installthrift –version 检查是否安装成功 再将默认bison改回123cd /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/sudo rm bisonsudo mv bison111 bison 至此thrift编译安装完毕 thrift文件编写 接口文件规则不同语言之间的无缝连接依靠的就是统一的接口语言IDL，通过generator生成不同语言的接口文件，在thrift的包中实现对socket的封装。IDL规则：1.基本类型byte 有符号字节数i16，i32，i64 short，int，long整型bool true or falsedouble 64位浮点数string 二进制字符串2.集合类型map hashmapset hashsetlist arraylist3,结构体相当于java中的bean，用于rpc中对象传输struct Object{……}比如：struct User{ 1:i32 id; 2:string name; 3:double salary; 4:bool hasCar;}4.服务类型service，重要的服务接口定义service HelloService{ string sayHello(1:string msg);}5.异常类型exception RequestException { 1:i32 code; 2:string detail;}6.枚举类型 enum Color{ RED, BLUE }7.namespace 定义文件的命名空间，防止冲突比如java工程中namespace java com.thrift.demo 传输协议thrift提供多种传输协议，包括文本和二进制两类，由于二进制传输快，所以一般采用二进制传输协议。服务器端和客户端的传输协议要求相同。TBinaryProtocol:使用二进制编码格式传输,是thrift的默认传输协议TCompactProtocol:使用压缩格式传输TJSONProtocol:使用JSON格式传输TDebugProtocol:使用易懂可读的文本格式进行传输，以便于debugTSimpleJSONProtocol:提供JSON只写的协议，适用于通过脚本语言解析 传输方式Thrift封装了一层传输层来支持底层的网络通信,在Thrift中称为Transport,不仅提供open,close,flush等方法,还有一些read/write方法.TSocket:阻塞式IO的Transport实现,用在客户端TServerSocket:非阻塞式Socket,用于服务器端,用于监听TSocketTNonblockingSocket:非阻塞式IO的实现TMemoryInputTransport:封装了一个字节数组byte[]来做输入流的封装TFramedTransport:同样使用非阻塞方式，按块的大小进行传输,输入流封装了TMemoryInputTransport 服务器种类TSimpleServer:单线程阻塞式IO处理，用于演示TNonblockingServer：单线程非阻塞式IO处理，NIO通信方式实现多路复用，当处理比较耗时时效率不高，因为所有socket都要排队处理。TThreadPoolServer：用线程池来同时处理多个socket，当连接数目较大时，效率不高。TThreadedSelectorServer：这是一种多线程半同步半异步的服务模型,是Thrift提供的最复杂最高级的服务模型,内部有一个专门负责处理监听Socket的线程,有多个专门处理业务中网络IO的线程,有一个专门负责决定将新Socket连接分配给哪一个线程处理的起负载均衡作用的线程,还有一个工作线程池.这种模型既可以响应大量并发连接的请求又可以快速对wangluoIO进行读写,能适配很多场景,因此是一种使用比较高频的服务模型. 服务器端 客户端程序实例thrift文件：123service HelloService&#123; string sayHello(1:string msg);&#125; 执行thrift指令：12345678910thrift --gen &lt;language&gt; &lt;Thrift filename&gt;``` 生成接口文件：下面实现接口,即每个request所对应的方法:``` javapublic class HelloServiceImpl implements HelloService.Iface &#123; public String sayHello(String msg) throws TException &#123; return &quot;Hello &quot;+msg+&quot; My name is thrift&quot;; &#125;&#125; server端程序：1234567891011121314151617181920212223242526272829public class ThriftServer &#123; public void startServer() throws TTransportException &#123; System.out.println("server start..........."); //实现服务处理接口impl //创建TProcessor TProcessor processor = new HelloService.Processor&lt;HelloService.Iface&gt;(new HelloServiceImpl()); //创建TServerTransport TServerTransport transport = new TServerSocket(8888); //创建TProtocol TBinaryProtocol.Factory protocol = new TBinaryProtocol.Factory(); //创建TServer TServer.Args args = new TServer.Args(transport); args.processor(processor); args.protocolFactory(protocol); TServer server = new TSimpleServer(args); //启动Server server.serve(); &#125; public static void main(String[] args)&#123; ThriftServer server = new ThriftServer(); try &#123; server.startServer(); &#125; catch (TTransportException e) &#123; e.printStackTrace(); &#125; &#125;&#125; client端程序：123456789101112131415161718192021public class ThriftClient &#123; public static void main(String[] args)&#123; System.out.println("client start........."); //创建TTransport TTransport transport = new TSocket("localhost",8888,3000); //创建TProtocol TBinaryProtocol protocol = new TBinaryProtocol(transport); //基于TTransport和TProtocol创建Client HelloService.Client client = new HelloService.Client(protocol); //调用Client的相应方法 try &#123; transport.open(); String result = client.sayHello("xubin"); System.out.println(result); &#125; catch (TException e) &#123; e.printStackTrace(); &#125;finally &#123; transport.close(); &#125; &#125;&#125; 结果：server start………..client start………Hello xubin My name is thrift参考：https://www.jianshu.com/p/10b7cf0a384e]]></content>
      <categories>
        <category>thrift</category>
      </categories>
      <tags>
        <tag>thrift</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UNIX-Socket socketopt套接字选项]]></title>
    <url>%2F2018%2F03%2F06%2FUNIX-Socket-socketopt%E5%A5%97%E6%8E%A5%E5%AD%97%E9%80%89%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[本文主要介绍关于套接字的一些常用选项以及它们的使用，本文的示例程序参考unix网络编程，列出常用选项的默认配置。 Socketopt API123#include &lt;sys/socket.h&gt;int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen);int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen);//ret-成功返回0 失败返回-1 用途：获取或设置套接字选项，参数：sockfd：已经打开的套接字描述符level：选项级别，主要有SOL_SOCKET即通用，IPPROTO_IP即IPV4地址族，IPPROTO_IPV6即IPV6地址族，IPPROTO_TCP即TCP传输协议，IPPROTO_SCTP即SCTP传输协议，IPPROTO_ICMPV6即ICMPV6传输协议。optname：选项名称下面会给出部分，具体参加[UNIX网络编程卷一]P151。optval：对应选项的值，对于标记选项值为0或1，对于值选项类型由内部定义。optlen：对应选项的值的长度。 Socketopt的常用选项注意：对于TCP已连接套接字，下面的套接字选项须从监听套接字继承得到：SO_DEBUG、SO_DONTROUTE、SO_KEEPALIVE、SO_LINGER、SO_OOBINLINE、SO_RCVBUF、SO_RCVLOWAT、SO_SNDBUF、SO_SNDLOWAT、TCP_MAXSEG、TCP_NODELAY。 SO_KEEPALIVE给TCP套接字设置一个保持存活选项后，如果两小时后和对端没有数据交互，那么向对端发送一个保持存活探测分节，对端在此时有三种情况：1）对端正常，接收到探测分节，回应一个期望ACK，在两小时后若还没有交互，继续发送下一个保持存活探测分节。2）在对端进程已经崩溃并且重启情况，那么对端回应一个RST，本端得知对方已经重启，关闭套接字。3）对端对保持存活探测分节没有任何回应，那么每个75秒会连续再发8次探测分节，试图得到回应，若还没有回应，则放弃探测，关闭套接字，值得说的是，对端可能是崩溃未重启，或者就是网络节点故障但对端套接字一切正常，但是概率很小，网络故障时间必须与8次探测分节发送时间吻合。一般在服务器端的socket()和bind()之间，设置该选项，让服务器知晓那些客户端关闭或者崩溃等等，不至于在read的情况下一直等待。 SO_RCVBUF，SO_SNDBUF每个套接字都有一个发送缓冲区和一个接收缓冲区，这两个套接字选项允许我们改变这两个缓冲区的默认大小。对于TCP来说，套接字接收缓冲区不可能溢出，因为不允许对端发出超过本端所通告窗口大小的数据，这就是TCP的流量控制。对于UDP来说，由于没有流量控制，较快的发送端可以很容易地淹没较慢的接收端，导致接收端的UDP丢弃数据报。当设置TCP套接字接收缓冲区的大小时，函数调用顺序很重要，这是因为TCP的窗口规模选项是在建立连接时用SYN分节与对端互换得到的。对于客户，这意味着SO_RCVBUF选项必须在调用connect之前设置；对于服务器，这意味着SO_RCVBUF选项必须在调用listen之前给监听套接字设置。 SO_RCVTIMEO，SO_SNDTIMEO给套接字的发送和接受设置超时值，设为0表示禁止超时。 SO_REUSEADDR地址重用选项，一般在服务器端都需要设置该选项。在UNIX-网络编程中阐述了4个作用：1）允许启动一个监听服务器并将其绑定到其众所周知的端口，即使以前建立的将该端口用作为它们的本地端口的连接还存在。可用在服务器连接的重启中。2）允许在同一端口启动统一服务器的多个实例，只要每个实例绑定的IP地址不同，在IP别名技术托管多个HTTP服务器的网点很常见。在TCP中绝不存在绑定统一IP和端口的多个实例，即重复绑定。3）允许单个进程绑定同一端口到多个套接字上，只要IP地址不同，对于UDP传输想知道客户端的请求地址来说，使用普遍。4）在UDP协议下，如果传输协议支持，可以允许完全重复的绑定。 TCP_MAXSEG设置TCP连接的最大分节大小，往往有对端决定，在ACK时会携带发送MSS告诉本端最大发送信息大小，当然也可能本端的TCP_MAXSEG小于对端，在未连接时，本端TCP_MAXSEG为默认大小。 TCP_NODELAYNAGLE算法：主要目的是抵消广域网上的小分组数目，在为接受到现有消息的ACK时，本端会将小分组暂存，等到对端ACK确认收到消息，再将小分组一起发送给对端，尽量使得分组大小接近MSS。ACK延迟算法：对端采用该算法为了减少广域网上的传输次数，所以对端会延迟50-200MS时间，如果有消息发送将ACK携带一起发送，如果超时则将ACK直接发送。典型的延迟情况时写-写-读的情况，本端将消息1发送，消息2小分组在本地等待ACK，但是对端没有消息发送，故要延迟50-200MS之后才发送ACK，本端之后才会发送消息2，这就造成了200MS左右的延迟。消除延迟的方式：1）使用writev而不是调用write两次。(推荐)2） 将4字节的请求类型和396字节的数据复制到单个缓冲区中，然后调用write。3）设置TCP_NODELAY套接字选项，继续调用两次write。（有损网络，通常不采用） Socketopt的默认选项下面程序会输出通用IP和TCP级别的默认套接字选项。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;netinet/in.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;sys/time.h&gt;#define error_exit(msg) \ do &#123; printf("%s\n", msg); exit(EXIT_FAILURE); &#125; while (0)union val &#123; int i_val; long l_val; struct linger linger_val; struct timeval timeval_val;&#125; val;static char *sock_str_flag(union val *, int);static char *sock_str_int(union val *, int);static char *sock_str_linger(union val *, int);static char *sock_str_timeval(union val *, int);struct sock_opts &#123; const char *opt_str; int opt_level; int opt_name; char *(*opt_val_str)(union val *, int);&#125; sock_opts[] = &#123; &#123; "SO_BROADCAST", SOL_SOCKET, SO_BROADCAST, sock_str_flag &#125;, &#123; "SO_DEBUG", SOL_SOCKET, SO_DEBUG, sock_str_flag &#125;, &#123; "SO_DONTROUTE", SOL_SOCKET, SO_DONTROUTE, sock_str_flag &#125;, &#123; "SO_ERROR", SOL_SOCKET, SO_ERROR, sock_str_int &#125;, &#123; "SO_KEEPALIVE", SOL_SOCKET, SO_KEEPALIVE, sock_str_flag &#125;, &#123; "SO_LINGER", SOL_SOCKET, SO_LINGER, sock_str_linger &#125;, &#123; "SO_OOBINLINE", SOL_SOCKET, SO_OOBINLINE, sock_str_flag &#125;, &#123; "SO_RCVBUF", SOL_SOCKET, SO_RCVBUF, sock_str_int &#125;, &#123; "SO_SNDBUF", SOL_SOCKET, SO_SNDBUF, sock_str_int &#125;, &#123; "SO_RCVLOWAT", SOL_SOCKET, SO_RCVLOWAT, sock_str_int &#125;, &#123; "SO_SNDLOWAT", SOL_SOCKET, SO_SNDLOWAT, sock_str_int &#125;, &#123; "SO_RCVTIMEO", SOL_SOCKET, SO_RCVTIMEO, sock_str_timeval &#125;, &#123; "SO_SNDTIMEO", SOL_SOCKET, SO_SNDTIMEO, sock_str_timeval &#125;, &#123; "SO_REUSEADDR", SOL_SOCKET, SO_REUSEADDR, sock_str_flag &#125;, &#123; "SO_REUSEPORT", SOL_SOCKET, SO_REUSEPORT, sock_str_flag &#125;, &#123; "SO_TYPE", SOL_SOCKET, SO_TYPE, sock_str_int &#125;, &#123; "IP_TOS", IPPROTO_IP, IP_TOS, sock_str_int &#125;, &#123; "IP_TTL", IPPROTO_IP, IP_TTL, sock_str_int &#125;, &#123; "TCP_MAXSEG", IPPROTO_TCP,TCP_MAXSEG, sock_str_int &#125;, &#123; "TCP_NODELAY", IPPROTO_TCP,TCP_NODELAY, sock_str_flag &#125;, &#123; NULL, 0, 0, NULL &#125;&#125;;int main(int argc, char **argv) &#123; int fd; socklen_t len; struct sock_opts *ptr; for (ptr = sock_opts; ptr-&gt;opt_str != NULL; ptr++) &#123; printf("%s: ", ptr-&gt;opt_str); if (ptr-&gt;opt_val_str == NULL) printf("(undefined)\n"); else &#123; switch (ptr-&gt;opt_level) &#123; case SOL_SOCKET: case IPPROTO_IP: case IPPROTO_TCP: fd = socket(AF_INET, SOCK_STREAM, 0); break; default: error_exit("Can't create fd\n"); &#125; len = sizeof(val); if (getsockopt(fd, ptr-&gt;opt_level, ptr-&gt;opt_name, &amp;val, &amp;len) == -1) error_exit("getsockopt error"); else printf("default = %s\n", (*ptr-&gt;opt_val_str)(&amp;val, len)); close(fd); &#125; &#125; exit(0);&#125;static char strres[128];static char* sock_str_flag(union val *ptr, int len) &#123; if (len != sizeof(int)) snprintf(strres, sizeof(strres), "size (%d) not sizeof(int)", len); else snprintf(strres, sizeof(strres), "%s", (ptr-&gt;i_val == 0) ? "off" : "on"); return(strres);&#125;static char* sock_str_int(union val *ptr, int len) &#123; if (len != sizeof(int)) snprintf(strres, sizeof(strres), "size (%d) not sizeof(int)", len); else snprintf(strres, sizeof(strres), "%d", ptr-&gt;i_val); return(strres);&#125;static char* sock_str_linger(union val *ptr, int len) &#123; struct linger *lptr = &amp;ptr-&gt;linger_val; if (len != sizeof(struct linger)) snprintf(strres, sizeof(strres), "size (%d) not sizeof(struct linger)", len); else snprintf(strres, sizeof(strres), "l_onoff = %d, l_linger = %d", lptr-&gt;l_onoff, lptr-&gt;l_linger); return(strres);&#125;static char* sock_str_timeval(union val *ptr, int len) &#123; struct timeval *tvptr = &amp;ptr-&gt;timeval_val; if (len != sizeof(struct timeval)) snprintf(strres, sizeof(strres), "size (%d) not sizeof(struct timeval)", len); else snprintf(strres, sizeof(strres), "%ld sec, %ld usec", tvptr-&gt;tv_sec, tvptr-&gt;tv_usec); return(strres);&#125; 结果：SO_BROADCAST: default = offSO_DEBUG: default = offSO_DONTROUTE: default = offSO_ERROR: default = 0SO_KEEPALIVE: default = offSO_LINGER: default = l_onoff = 0, l_linger = 0SO_OOBINLINE: default = offSO_RCVBUF: default = 131072SO_SNDBUF: default = 131072SO_RCVLOWAT: default = 1SO_SNDLOWAT: default = 2048SO_RCVTIMEO: default = 0 sec, 140728898420736 usecSO_SNDTIMEO: default = 0 sec, 140728898420736 usecSO_REUSEADDR: default = offSO_REUSEPORT: default = offSO_TYPE: default = 1IP_TOS: default = 0IP_TTL: default = 64TCP_MAXSEG: default = 512TCP_NODELAY: default = off]]></content>
      <categories>
        <category>C语言学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Socket</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UNIX-Socket server和client示例程序]]></title>
    <url>%2F2018%2F03%2F06%2FUNIX-Socket-server%E5%92%8Cclient%E7%A4%BA%E4%BE%8B%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[这篇文章实现了一个unix-socket的服务端和客户端示例程序，用于unix-socket相关基础知识的学习，多个客户端给服务端发送数据，服务器端接受数据并显示，可以看作一个多人聊天室程序的雏形。服务器端程序：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;assert.h&gt;#include &lt;time.h&gt;#include &lt;pthread.h&gt;#include &lt;errno.h&gt;#include &lt;signal.h&gt;#include &lt;sys/time.h&gt;#include &lt;sys/resource.h&gt;#include &lt;net/if.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/tcp.h&gt;#define PORT 6666void *threadprocess(void *arg);int main(int argc, char const *argv[])&#123; int socket_fd,connect_fd;//绑定套接字和连接套接字 struct sockaddr_in servaddr;//服务器绑定地址 pthread_t thread; //创建socket if ((socket_fd=socket(AF_INET,SOCK_STREAM,0))==-1) &#123; //创建套接字失败 printf("create socket error: %s(errno: %d)\n",strerror(errno),errno); exit(0); &#125; //绑定地址 先设置地址在bind memset(&amp;servaddr,0,sizeof(servaddr)); servaddr.sin_family=AF_INET;//设置地址族 servaddr.sin_addr.s_addr=htonl(INADDR_ANY);//自动获取本机的ip servaddr.sin_port=htons(PORT);//设置端口 if (bind(socket_fd,(struct sockaddr*)&amp;servaddr,sizeof(servaddr))==-1) &#123; //绑定失败 printf("bind socket error: %s(errno: %d)\n",strerror(errno),errno); exit(0); &#125; //开启监听 if (listen(socket_fd,10)==-1) &#123; printf("listen socket error: %s(errno: %d)\n",strerror(errno),errno); exit(0); &#125; printf("======waiting for client's request======\n"); while(1)&#123; //接受连接accept if((connect_fd=accept(socket_fd,(struct sockaddr*)NULL,NULL))==-1)&#123; //连接失败，重新等待连接 printf("accept socket error: %s(errno: %d)",strerror(errno),errno); continue; &#125; //开一个线程处理连接 if ((pthread_create(&amp;thread, NULL, threadprocess, (void*)&amp;connect_fd)) == -1) &#123; printf("create thread error!\n"); exit(0); &#125; &#125; return 0;&#125;//线程处理函数，用来与client交互void *threadprocess(void *arg)&#123; int connect_fd=*(int*)arg; int n; char buff[4096]; while(1)&#123; //接受数据并且打印 阻塞知道有数据发送 n = recv(connect_fd, buff, 4096, 0); buff[n]='\0'; printf("%s\n",buff); if(send(connect_fd, "send success\n",14,0) == -1) &#123; perror("send error"); &#125; &#125; pthread_exit("thread exit....");&#125; 客户端程序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;assert.h&gt;#include &lt;time.h&gt;#include &lt;pthread.h&gt;#include &lt;errno.h&gt;#include &lt;signal.h&gt;#include &lt;sys/time.h&gt;#include &lt;sys/resource.h&gt;#include &lt;net/if.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netinet/tcp.h&gt;#include &lt;netinet/in.h&gt; #define PORT 6666int main(int argc, char const *argv[])&#123; int socket_fd,rec_len; char recvline[4096],sendline[4096]; struct sockaddr_in servaddr; //接受数据 ip if( argc != 2)&#123; printf("usage: ./client &lt;ipaddress&gt;\n"); exit(0); &#125; //创建套接字 if ((socket_fd=socket(AF_INET,SOCK_STREAM,0))&lt;0) &#123; //创建套接字错误 printf("create socket error: %s(errno: %d)\n", strerror(errno),errno); exit(0); &#125; //设置要connect的目标地址 memset(&amp;servaddr,0,sizeof(servaddr)); servaddr.sin_family=AF_INET;//设置地址族 servaddr.sin_port=htons(PORT);//设置端口 //设置ip地址 将点分十进制转换为网络二进制 if (inet_pton(AF_INET,argv[1],&amp;servaddr.sin_addr)&lt;=0) &#123; //转换失败 printf("inet_pton error for %s\n",argv[1]); exit(0); &#125; //连接服务器端 if( connect(socket_fd, (struct sockaddr*)&amp;servaddr, sizeof(servaddr)) &lt; 0)&#123; printf("connect error: %s(errno: %d)\n",strerror(errno),errno); exit(0); &#125; //发送数据 printf("send msg to server: \n"); while(1)&#123; fgets(sendline, 4096, stdin);//带发送的数据 if(send(socket_fd,sendline,strlen(sendline),0)==-1)&#123; printf("send msg error: %s(errno: %d)\n", strerror(errno), errno); exit(0); &#125; if((rec_len = recv(socket_fd, recvline, 4096,0)) == -1) &#123; perror("recv error"); exit(1); &#125; recvline[rec_len] = '\0'; printf("Received : %s\n",recvline); &#125; return 0;&#125; 运行结果：客户端1:123456xubindeMacBook-Pro:~ xubin$ /Users/xubin/Desktop/MyNote/socket/client 127.0.0.1send msg to server: 123Received : send success124Received : send success 客户端2:123456xubindeMacBook-Pro:~ xubin$ /Users/xubin/Desktop/MyNote/socket/client 127.0.0.1send msg to server: 哈哈Received : send success嗯Received : send success server端：123456xubindeMacBook-Pro:~ xubin$ /Users/xubin/Desktop/MyNote/socket/server ======waiting for client's request====== 123124哈哈嗯 本程序仅供学习参考，利用socket技术可以做很多有趣的事情。]]></content>
      <categories>
        <category>C语言学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Socket</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UNIX-Socket介绍和常用API]]></title>
    <url>%2F2018%2F01%2F30%2FUNIX-Socket%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%B8%B8%E7%94%A8API%2F</url>
    <content type="text"><![CDATA[Socket通信过程 Server：socket()创建套接字,bind()绑定端口，listen()开始监听端口，调用accept()阻塞等待，直到客户端连接，返回connectfd用来和客户端交互，read()读取客户端发送的消息，write()给客户端发送消息，close()交互完毕断开连接。Client：socket()创建套接字，connect()连接远程主机指定端口，连接成功返回connectfd用来与服务器端交互，调用write(),read()来读写通信数据，close()关闭连接。 Socket APIsocket1.int socket(int protofamily,int type,int protocol);创建套接字，返回描述符，对应于文件IO中的open()函数，同过对文件描述符索引的数据结构进行read(),write()进行IO，不用时调用close()关闭。参数：protofamily：协议族，用来指定套接字的地址类型，可用的协议族有：AF_INET(IPV4)、AF_INET6(IPV6)、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。type：套接字类型，进一步确定通信特征，可用的类型有：SOCK_DGRAM:固定长度，无连接，不可靠的报文传递；SOCK_RAW:IP协议的数据报接口；SOCK_SEQPACKET:固定长度，有序，可靠的面相连接的报文传递；SOCK_STREAM:有序，可靠，双向的面相连接的字节流传递；protocol：传输协议，设为0时为指定协议族和类型下默认的传输协议，存在多种协议可用时可以指定。常用协议有：IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议。 bind2.int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);创建的套接字描述符，仅仅指定传输协议类型，地址类型，并没有指定具体的地址端口，一般服务器端通过bind函数绑定ip和端口，而客户端不需要bind，可以直接通过connect函数连接远程地址，本地随机端口加上自身IP作为通信地址。参数：sockfd：创建的套接字描述符；addr：绑定的地址用结构体sockaddr来存储，包括几种地址格式ipv4，ipv6，local，下面列出具体结构体：123456789101112131415161718192021222324252627//ipv4：struct sockaddr_in &#123; sa_family_t sin_family; /* address family: AF_INET协议族 */ in_port_t sin_port; /* port in network byte order 端口*/ struct in_addr sin_addr; /* internet address ip地址 */&#125;;/* Internet address. */struct in_addr &#123; uint32_t s_addr;/* address in network byte order */&#125;;//ipv6： struct sockaddr_in6 &#123; sa_family_t sin6_family; /* AF_INET6 */ in_port_t sin6_port; /* port number */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* Scope ID (new in 2.4) */ &#125;;struct in6_addr &#123; unsigned char s6_addr[16]; /* IPv6 address */ &#125;;//Unix域： #define UNIX_PATH_MAX 108struct sockaddr_un &#123; sa_family_t sun_family; /* AF_UNIX */ char sun_path[UNIX_PATH_MAX]; /* pathname 绝对路径*/ &#125;; 注意，关于地址格式中几个常用的函数和注意事项：字节序由于系统架构不同，实际的数据存储有大端和小端的区别，为了避免网络字节序与主机字节不同造成的错误，统一设置网络字节序。常用函数如下：12345#include &lt;arpa/inet.h&gt;uint32_t htonl(uint32_t hostint32);//以网络字节序表示32位整数uint16_t htons(uint16_t hostint16); //以网络字节序表示16位整数uint32_t ntohl(uint32_t netint32); //以主机字节序表示32位整数uint16_t ntohs(uint16_t netint16); //以主机字节序表示16位整数 二进制和点分十进制之间转换为了便于查看通常将地址转化为a.b.c.d的形式，常用函数：12345#include &lt;arpe/inet.h&gt;int inet_pton(int family, const char *strptr, void *addrptr); //将点分十进制的ip地址转化为用于网络传输的数值格式,返回值：若成功则为1，若输入不是有效的表达式则为0，若出错则为-1const char * inet_ntop(int family, const void *addrptr, char *strptr, size_t len); //将数值格式转化为点分十进制的ip地址格式,返回值：若成功则为指向结构的指针，若出错则为NULL （1）这两个函数的family参数既可以是AF_INET（ipv4）也可以是AF_INET6（ipv6）。如果，以不被支持的地址族作为family参数，这两个函数都返回一个错误，并将errno置为EAFNOSUPPORT.（2）第一个函数尝试转换由strptr指针所指向的字符串，并通过addrptr指针存放二进制结果，若成功则返回值为1，否则如果所指定的family而言输入字符串不是有效的表达式格式，那么返回值为0.（3）inet_ntop进行相反的转换，从数值格式（addrptr）转换到表达式（strptr）。inet_ntop函数的strptr参数不可以是一个空指针。调用者必须为目标存储单元分配内存并指定其大小，调用成功时，这个指针就是该函数的返回值。len参数是目标存储单元的大小，以免该函数溢出其调用者的缓冲区。如果len太小，不足以容纳表达式结果，那么返回一个空指针，并置为errno为ENOSPC。INET_ADDRSTRLEN和INET6_ADDRSTRLEN定义足够的大小存放Ipv4和Ipv6地址的文本字符串。addrlen：地址长度； listen int listen(int sockfd, int backlog);用于服务器端，将创建的套接字由主动变为被动，开启监听，等待客户端连接。参数：sockfd：被动等待连接的套接字描述符；backlog：监听队列的长度；由于高并发未及时连接的请求加入到监听队列中，3次握手连接完成后退出队列。connect4.int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);客户端连接函数，向指定的地址端口发起连接请求，连接成功放回sockfd用来与服务器端通信。参数：sockfd：发起连接的套接字描述符；addr：目标连接地址；addrlen：目标地址长度；accept int accept(int sockfd, struct sockaddr addr, socklen_t addrlen); //返回连接connect_fd在服务器端socket()-&gt;bind()-&gt;listen()，客户端socket()-&gt;connect()之后，服务器端完成三次握手连接成功之后，客户端信息加入到连接队列中，此时accept()函数从连接队列中返回一个connectfd，用来与客户端通信，connectfd的local地址和监听的sockfd相同，remote地址就是客户端的IP和端口地址。注意accept()为阻塞函数，一直等待直到有客户端连接。并且accept()只是从连接队列中取出一个连接，此时已经完成tcp/ip的连接过程了。参数：sockfd：监听的套接字描述符；addr：结果参数，存储客户端的地址；addrlen：地址长度；write/read6.123#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); 与文件IO相同，用于不同主机间的进程之间的通信。参数：fd：IO的套接字描述符；buf：存储读取的数据或者等待发送的数据；count：发送/接受的数据长度； close7.int close(int fd);关闭套接字连接，只有当fd的引用为0时，才会真正的断开连接。]]></content>
      <categories>
        <category>C语言学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Socket</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zipf分布及程序实现]]></title>
    <url>%2F2018%2F01%2F30%2FZipf%E5%88%86%E5%B8%83%E5%8F%8A%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[zipf分布规律由美国学者G.K.齐普夫1935年提出，在文本中单词出现的次数与它的频率表中排名呈现反比。在分布式存储领域，也可以认为数据块的访问次数与它的访问频率排名呈现反比，大部分访问集中在少部分数据块上，通俗讲就是2/8原则，80%的访问集中个别块上，20%分散在其他大部分块上，在网页访问上也有这样的规则，为了获取实验数据，用c以及java实现了zipf分布。c语言实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;math.h&gt;#include &lt;string.h&gt;double getProbability(int rank,double skew,double bottom)&#123; return (1.0/pow(rank,skew))/bottom;&#125;void zipGenerator(int size,double skew,double* res)&#123; double bottom = 0; int i=1; for (i = 1; i &lt;=size; ++i) &#123; bottom+=(1.0/pow(i,skew)); &#125; for (i = 1; i &lt;= size; ++i) &#123; //printf("%d:%12.11f\n",i,getProbability(i,skew,bottom)); *res=getProbability(i,skew,bottom); res++; &#125;&#125;long predictNtopReqNum(long nreq,int nblk,int ntop,double skew)&#123; double bottom = 0; long res = 0; double rate = 0; int i=1; for (i = 1; i &lt;=nblk; ++i) &#123; bottom+=(1.0/pow(i,skew)); &#125; for (i = 1; i &lt;= ntop; ++i) &#123; rate+=getProbability(i,skew,bottom); &#125; return (long)(rate*nreq);&#125;int predictPtopBlkNum(long nreq,int nblk,double ptop,double skew)&#123; double bottom = 0; double rate = 0; int res=nblk; int i=1; for (i = 1; i &lt;=nblk; ++i) &#123; bottom+=(1.0/pow(i,skew)); &#125; for (i = 1; i &lt;= nblk; ++i) &#123; rate+=getProbability(i,skew,bottom); if(rate&gt;=ptop)&#123; res=i; break; &#125; &#125; return res;&#125;void writeToExcel(double* res,char* filename,int count)&#123; FILE *fp=NULL; fp = fopen(filename,"w"); fprintf(fp, "%s\t%s\n","Rank","Probability"); int i=0; for (i = 0; i &lt; count; i++) &#123; fprintf(fp, "%d\t%12.11f\n",i+1,res[i]); &#125; fclose(fp);&#125;int main(int argc, char const *argv[])&#123; if (argc&lt;4) &#123; printf("%s\n","error by params"); exit(1); &#125; int size = atoi(argv[1]); double skew = atof(argv[2]); //char* filepath = "/Users/xubin/Desktop/res.xls"; char* filepath = argv[3]; double* res = malloc(sizeof(double)*size); zipGenerator(size,skew,res); writeToExcel(res,filepath,size); if (argc&gt;4) &#123; long reqnum = atol(argv[4]); int ntop = atoi(argv[5]); double ptop = atof(argv[6]); printf("reqnum:%ld blknum:%d ntop:%d ptop:%f\n",reqnum,size,ntop,ptop); printf("%ld\n", predictNtopReqNum(reqnum,size,ntop,skew)); printf("%d\n", predictPtopBlkNum(reqnum,size,ptop,skew)); &#125; return 0;&#125; java语言的实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.util.Random; public class ZipfGenerator &#123; private Random rnd = new Random(System.currentTimeMillis()); private int size; private double skew; private double bottom = 0; public ZipfGenerator(int size, double skew) &#123; this.size = size; this.skew = skew; for(int i=1;i &lt; size; i++) &#123; this.bottom += (1/Math.pow(i, this.skew)); &#125; &#125; // the next() method returns an random rank id. // The frequency of returned rank ids are follows Zipf distribution. public int next() &#123; int rank; double friquency = 0; double dice; rank = rnd.nextInt(size); friquency = (1.0d / Math.pow(rank, this.skew)) / this.bottom; dice = rnd.nextDouble(); while(!(dice &lt; friquency)) &#123; rank = rnd.nextInt(size); friquency = (1.0d / Math.pow(rank, this.skew)) / this.bottom; dice = rnd.nextDouble(); &#125; return rank; &#125; // This method returns a probability that the given rank occurs. public double getProbability(int rank) &#123; return (1.0d / Math.pow(rank, this.skew)) / this.bottom; &#125; public static void main(String[] args) &#123; ZipfGenerator zipf = new ZipfGenerator(30,0.99); for(int i=1;i &lt;= 30; i++) System.out.println(i+" "+zipf.getProbability(i)); &#125;&#125; 以下是通过zipf分布函数生成的函数分布图，很清楚的理解zipf分布：]]></content>
      <categories>
        <category>数理统计</category>
      </categories>
      <tags>
        <tag>zipf</tag>
        <tag>分布</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark算子]]></title>
    <url>%2F2018%2F01%2F30%2FSpark%E7%AE%97%E5%AD%90%2F</url>
    <content type="text"><![CDATA[data1为测试所用的文本 Map对每个元素进行指定函数操作然后返回每一个结果构成map算子的结果 结果返回当然是四个数组，每个数组包含每行的所有word flatMap与map不同，flatmap对每个元素进行指定函数操作然后将返回的结果合并成一个数组，如果返回的结果是字符串当成字符数据处理 结果打印出每一行的单词 如果map返回的结果为一个字符串那么flatmap会将每个字符串的字符拆分合并成一个数组 结果为每个字符的集合的输出 distinct作用即去除集合中重复的元素 输出为所有不同的单词 coalesce调整RDD的分区数，可以设置是否进行shuffle，当扩展分区数时，必须进行shuffle操作。 在扩展分片数时要设置shuffle为true repartition设置shuffle为true的coalesce操作 randomSplit按照自定义的weights权重随机分配原来的rdd为多个rdd，权重大的rdd分配到元素的概率大，结果为一个rdd数组。 结果得到四个新的rdd，其中元素随机分配 glom对每个分片中元素组合成一个数组，这样每个分片中只有一个数组元素 一个为所有元素的数组，一个为四个元素数组构成的数组 union合并rdd中的元素，但不去重 结果为rdd1以及rdd2中所有元素集合不去重 intersectionrdd中元素做交集运算 结果为： subtractrdd之间元素集合做异或运算 结果为包含rdd1中元素但不包含rdd2中元素的集合： mapPartitions与map功能相似，但是针对每个分片进行map操作，当有初始化资源之类的耗时操作时，可以通过mapPartition对分片进行map操作，提高效率。 mapPartitionsWithIndex在mapPartition的基础增加一个代表分片index的参数 zip将两个rdd合并成Key/Value的形式，前提是两个rdd的分片数以及分片内元素数目相同 输出为： zipPartitions将多个rdd合并成一个rdd，要求分片数相同，分片中的元素个数没有要求。其中操作函数的参数为rdd的分片中元素迭代器，同样返回一个生成元素组的迭代器。 对三个rdd进行合并，自定义合并的方式，返回合并后的迭代器即可，结果如下： zipWithIndex将一组元素和其相应的index构成map键值对构成新的rdd 结果为键值对构成的rdd，输出为： zipWithUniqueId将一组元素和唯一的id构成键值对，构成新的rdd。id的组成方式为：每个分区中第一个元素的唯一ID值为：该分区索引号，每个分区中第N个元素的唯一ID值为：(前一个元素的唯一ID值) + (该RDD总的分区数) 输出结果为： partitionBy根据新的partitioner函数对rdd进行分区,可以通过继承partitioner自定义分区函数，目前spark有hashpartitoner以及rangerpartitoner来进行分区，只对键值对元素有效。 结果为： mapValue对键值对的value进行map操作 flatmapValue对键值对的value进行flatmap操作 combinByKeydef combineByKeyC =&gt; C,mergeCombiners: (C, C) =&gt; C,partitioner: Partitioner,mapSideCombine: Boolean = true,serializer: Serializer = null)以上为函数原型createCombiner为初始化combiner函数mergeValue用于每个分区内将C和V合并函数mergeCombiners用于分区之间的C和C之间合并函数 foldByKey该函数用于RDD[K,V]根据K将V做折叠、合并处理，其中的参数zeroValue表示先根据映射函数将zeroValue应用于V,进行初始化V,再将映射函数应用于初始化后的V。 groupByKey根据键值对的key将所有的value组成一个迭代器返回 reduceByKey根据键值对的key将所有的value进行reduce操作 reduceByKeyLocally与reduceByKey作用相当，但是返回一个map，而不是rdd cogroupcogroup相当于SQL中的全外关联full outer join，返回左右RDD中的记录，关联不上的为空。 joinjoin相当于SQL中的内关联join，只返回两个RDD根据K可以关联上的结果，join只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可。 leftOuterJoinleftOuterJoin类似于SQL中的左外关联left outer join，返回结果以前面的RDD为主，关联不上的记录为空。只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可。 rightOuterJoinleftOuterJoin类似于SQL中的左外关联left outer join，返回结果以后面的RDD为主，关联不上的记录为空。只能用于两个RDD之间的关联，如果要多个RDD关联，多关联几次即可。 subtractByKey根据key，对键值对进行异或运算 first返回rdd中第一个元素 count返回rdd中元素个数 reduce对rdd中元素进行reduce操作 collect返回rdd中元素的数组 taketake用于获取RDD中从0到num-1下标的元素，不排序。 toptop函数用于从RDD中，按照默认（降序）或者指定的排序规则，返回前num个元素。 takeorderedtakeOrdered和top类似，只不过以和top相反的顺序返回元素。 aggregatedef aggregateU(seqOp: (U, T) ⇒ U, combOp: (U, U) ⇒ U)(implicit arg0: ClassTag[U]): U函数原型，先通过zeroValue以及seqOp初始化分区内的类型，然后分区内使用seqOp进行合并，然后通过zeroValue以及combOp初始化不同分区结果，之后不同分区内使用combOp进行合并 fold同aggregate，只是seqOp和combOp相同，所以以上的可以用fold代替： lookup查询rdd中键值对，返回相应key的所有value的数组 countByKey返回相应key的键值对的个数有key和count组成map foreach循环rdd每个元素进行操作比如输出 foreachpartition循环rdd每个元素进行操作比如输出，但是时按照每个分片进行操作的。 sortBy按照指定的排序函数进行排序 以下均为将rdd数据按照不同格式按照不同压缩方式存储到不同的存储路径中去比如hdfs，hbase，localfs，alluxio等等 saveAsTextFile saveAsObjectFile saveAsSequenceFile saveAsHadoopFile saveAsHadoopDataset saveAsNewAPIHadoopFile saveAsNewAPIHadoopDataset]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alluxio介绍]]></title>
    <url>%2F2018%2F01%2F30%2FAlluxio%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[由于研究生方向是基于内存的纠删码集群研究，并且在OSDI2016上伯克利一篇文章中也是基于Alluxio实现的原型，所以特意了解一下Alluxio，以下是组会分享的PPT以及内容简介，希望对你有所帮助。什么是Alluxio呢？它是一个开源的内存分布式文件系统，之前成为tachyon，由LiYuanHao在伯克利读博期间编写，是发展最快的开源项目之一。Alluxio的用途在哪？1.现有计算框架往往都是直接从分布式文件系统中读写数据，效率比较低，性能消耗比较大2.架构在底层分布式文件系统与上层分布式计算框架之间，以文件的形式在内存中对外提供读写访问服务的话，可以为那些大数据应用提供一个数量级的加速，而且它只要提供通用的数据访问接口，就能很方便的切换底层分布式文件系统。比如spark中减少gc hdfs减少磁盘io。整体框架和Hadoop相似1.主节点为Master，负责管理全局的文件系统元数据，比如文件系统树等；2.从节点为Worker，负责管理本节点数据存储服务；3.还有一个组件为Client，为用户提供统一的文件存取服务接口；应用程序访问Alluxio，通过客户端先与主节点Master通讯，获取对应文件的元数据，再和对应Worker节点通讯，进行文件存取操作。所有的Worker会周期性地发送心跳给Master，维护文件系统元数据信息和确保自己被Master感知扔在集群中正常提供服务，而Master不会主动发起与其他组件的通信，它只是以回复请求的方式与其他组件进行通信。这与HDFS、HBase等分布式系统设计模式是一致的。Alluxio的容错手段，由于内存的紧缺所以不会采用在内存中冗余策略。主要两种手段：1.通过内存数据中血脉关系即通过重新运行计算数据的任务恢复结果2.通过底层持久化文件系统中的备份恢复Alluxio的典型的分层存储，所以可以指定多种读写类型。一、读类型1、CACHE_PROMOTE如果读取的数据在Worker上时，该数据被移动到Worker的最高层。如果该数据不在本地Worker的Alluxio存储中，那么就将一个副本添加到本地Alluxio Worker中，用于每次完整地读取数据快。这是默认的读类型。2、CACHE如果该数据不在本地Worker的Alluxio存储中，那么就将一个副本添加到本地Alluxio Worker中，用于每次完整地读取数据块。3、NO_CACHE不会创建副本。二、写类型1、CACHE_THROUGH数据被同步地写入到Alluxio的Worker和底层存储系统。2、MUST_CACHE数据被同步地写入到Alluxio的Worker。但不会被写入到底层存储系统。这是默认写类型3、THROUGH数据被同步地写入到底层存储系统。但不会被写入到Alluxio的Worker。4、ASYNC_THROUGH数据被同步地写入到Alluxio的Worker，并异步地写入到底层存储系统。处于实验阶段。当数据大小超过内存容量，如何处理？Alluxio不仅仅管理内存，同样可以管理SSD，HDD等系统资源。保证Alluxio可以正常运行。Alluxio提供定位策略，用于确定应该选择哪个Worker来存储文件数据块。用户可以在CreateFileOptions中设置该策略以用于写文件，也可在OpenFileOptions中设置该策略用于向Alluxio中读文件。Alluxio支持自定义定位策略，内置策略包括：1、LocalFirstPolicy 首先返回本地主机，如果本地Worker没有足够的容量容纳一个数据块，那么就会从有效的Worker列表中随机选择一个Worker。这也是默认策略。2、MostAvailableFirstPolicy返回拥有最多可用容量的Worker。3、RoundRobinPolicy以循环的方式选取存储下一个数据块的Worker，如果该Worker没有足够的容量，就将其跳过。4、SpecificHostPolicy返回指定主机名的Worker。该策略不能被设置为默认策略。Alluxio的优势：数据共享在Spark中，如果job2需要Job1运算的数据，Job1首先需要将数据写入到HDFS的block中，会产生硬盘甚至跨网络的读写，同时在HDFS中默认数据需要写三份，因此造成性能的损失。1.内存数据在不同的job和framework中进行分享？Alluxio在HDFS/Amazon S3和计算引擎中间提供了中间层，Spark的Job1不需要写到HDFS中，而只需要写到Alluxio的内存中，Job2可以从内存中读取相应数据。Alluxio的优势：应对cache丢失当计算引擎的进程损坏，Cache丢失，Spark只能重新启动计算，而通过Alluxio存储中间RDD可以不必从头算起。问题1：因为在传统计算引擎中，数据存储在同一个JVM中，而基于Alluxio的中间件将数据存到了不同的JVM中，跨JVM读写会不会影响性能？答：跨JVM读写会影响性能，在Alluxio中，使用了RamDisk来模拟本地文件系统的方式。问题2：如果Alluxio crash，怎么保证数据安全？答：在Alluxio中，数据不是保存在JVM中，而是保存在RamDisk中，RamDisk为独立的进程，因此可以保证数据安全。问题3：Alluxio是否可以支持随机读写？答：可以进行随机读，给定一个offset。新创立的文件一旦关闭，就会变成immutableAlluxio的优势：减少GC由于计算引擎与存储引擎共享同一个进程，而不是放在自己的JVM中，可以减少垃圾回收和数据重复。Alluxio的安装过程较容易，自行查阅资料。]]></content>
      <categories>
        <category>Alluxio</category>
      </categories>
      <tags>
        <tag>Alluxio</tag>
        <tag>内存</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark安装配置]]></title>
    <url>%2F2018%2F01%2F30%2FSpark%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Spark的处理数据可以从hdfs中获取或者通过本地文件等等 可以在其中配置Spark的资源管理可以通过mesos，yarn或者自身的standalone等这里我们搭建一个standalone模式下的单机以及集群环境前提是安装配置了scala，java以及需要的话hdfs和yarn 解压spark安装包 修改env环境配置文件以及/etc/.profile 启动spark 调试example中的SparkPi程序 修改salve文件添加集群中worker然后scp到其他节点 启动集群环境 通过spark-submit调试程序]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop集群-hdfs-yarn配置]]></title>
    <url>%2F2018%2F01%2F30%2FHadoop%E9%9B%86%E7%BE%A4-hdfs-yarn%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[环境ubuntu14.04操作系统Hadoop2.7.4远程上传文件工具yummy ftp用于mac，windows上可用winscp等远程控制台zoc7用于mac，windows上可用xshell检查是否安装openssh-client openssh-server以及openssh-sftp-server执行dpkg –get-selections | grep openssh如果没有安装执行apt-get updateapt-get install openssh-client openssh-server openssh-sftp-server安装需要的软件关闭防火墙执行ufw disable将下载好的软件包上传到master主机上。修改 /etc/ssh/sshd_config文件将PermitRootLogin without-password改为PermitRootLogin yes允许ssh远程用root用户登陆 配置ssh有一个主节点master，三个从节点worker01，worker02，worker03.ip与主机名分别为：172.16.223.129 master172.16.223.131 worker01172.16.223.132 worker02172.16.223.133 worker03先做到各个服务器之间的免密登陆首先修改/etc/hosts文件（删除127.0.1.1）修改/etc/hostname文件更改主机名apt-get install ssh 安装ssh连接软件ssh-keygen –t rsa一路enter生成本机的公钥以及密钥id_rsa.pub以及id_rsassh免密登陆 A机将自己的公钥发给B机，B机接受并且将A的公钥加到authorized_keys文件中，那么就可以通过A机免密ssh访问B机。所以将通过scp指令将id_rsa.pub发到想免密访问的主机，然后呀登陆目标主机，通过cat src&gt;&gt;dst指令将公钥添加到authorized_keys文件中。再通过ssh-add id_rsa添加密钥文件到ssh服务中，即可实现对目标机的ssh免密访问。最终实现各个主机之间都可以相互免密访问。 jdk和hadoop解压下载好的jdk以及hadoop的tar包tar –xvf [path] 解压tar包tar –xzvf [path] 解压tar.gz包然后配置/etc/.profile文件即可gedit /etc/.profilesource /etc/.profile 刷新配置文件java –version环境变量配置完毕，下面就是配置hadoop的配置文件：主要有核心文件，hdfs文件，mapreduce文件，yarn文件，Hadoop-env文件，以及slave文件。 配置文件 修改hadoop-env.sh文件添加：export JAVA_HOME=/root/BigDataSoftware/jdk1.8.0_151export HADOOP_PRIFIX=/root/BigDataSoftware/Hadoop-2.7.4 修改core-site.xml文件1）临时文件的路径，如果不设置这个属性，那么hadoop会默认到/tmp/Hadoop在重启后会删除，必须再次format文件系统。2）配置本机文件系统的名称，相当于在网络中代号。 修改hdfs-site.xml文件指定副本个数为3。 修改mapred-site.xml文件touch 文件名 创建文件mkdir 文件夹名 创建文件夹配置mapreduce的管理框架为yarn配置mapreduce的job.tracker 修改yarn-env.sh文件添加export JAVA_HOME=/root/BigDataSoftware/jdk1.8.0_151 修改yarn-site.xml1) yarn提供的节点管理服务2) yarn的资源管理器节点 配置slaves文件worker01worker02worker03三个从节点作为datanode至此主机master上的环境配置完毕，直接使用scp指令将所有文件夹拷贝过去即可。所有机器配置完毕。如果通信有问题可以关闭iptablesiptables –P INPUT ACCEPTiptables –P OUTPUT ACCEPTiptables –P FORWARD ACCEPT测试下面启动hadoop查看是否配置成功：回到master节点执行hadoop namenode –format 格式化文件系统然后执行start-all.sh或者start-dfs.sh开启hdfs，start-yarn开启yarn资源管理器打开master：50070查看namenode管理界面通过jps指令查看相应的进程是否运行往hdfs中写入本地文件：/bin/hdfs dfs -put /root/text /等hdfs操作指令类似于linux中文件系统指令启动失败可以到master或者worker节点中的logs文件夹下查看日志文件hdfs格式化删除临时文件目录，删除data目录等，然后执行hdfs namenode –formathdfs datanode –format然后star-all.sh即可]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(21)——replication.c篇]]></title>
    <url>%2F2017%2F11%2F22%2Fredis%E6%BA%90%E7%A0%81-21-%E2%80%94%E2%80%94replication-c%E7%AF%87%2F</url>
    <content type="text"><![CDATA[redis副本简介为了防止单点数据库崩溃等意外情况导致数据丢失，所以采用副本机制来提高系统的数据可用性，建立主从服务器机制，允许从服务器获取主服务器的状态，之后成这一过程为同步操作，在redis2.8之后引入了部分同步操作，在此之前当主从连接断开重连之后，需要对主从进行全局同步，可能在断开期间的指令数据很少，所以必定会降低主服务器的性能，部分同步即通过唯一表示的副本操作id来判定，是新的主服务器还是之前断开的服务器，如果是之前的旧主服务器，那么从上次断开的偏移处重新开始同步，在master服务器中有replicationbacklog作为副本缓冲区，在指令传播时，也将指令存储到缓冲物中，但是缓冲区的大小时有限的，所以超过了缓冲区的大小，就必须强制进行全局同步操作。redis的同步操作是异步执行的，所以同步期间可以继续执行其他指令。redis的全局同步分为磁盘同步以及套接字同步，磁盘同步即将rdb文件写入磁盘，然后从磁盘读儒内存，通过套接字发送给从服务器，套接字同步即直接通过套接字发送给从服务器。 replicationCron函数replicationCron函数为时间事件处理函数，在函数中有对master的连接同步，有对slave服务器的同步，以及相应的心跳机制。 与master相关12345678910111213141516171819//复制的时间处理函数每一秒钟被调用一次void replicationCron(void) &#123; static long long replication_cron_loops = 0; //.......超时行为监测程序省略 /* Check if we should connect to a MASTER */ //连接master主机 if (server.repl_state == REPL_STATE_CONNECT) &#123; serverLog(LL_NOTICE,"Connecting to MASTER %s:%d", server.masterhost, server.masterport); if (connectWithMaster() == C_OK) &#123;//连接，创建事件，开始异步的连接以及副本同步 serverLog(LL_NOTICE,"MASTER &lt;-&gt; SLAVE sync started"); &#125; &#125; //......心跳机制 给master发送ack+offset //......心跳机制 监测slave服务器 //......slave的同步操作&#125; 可见检测到slave的状态为REPL_STATE_CONNECT，表示当前服务器已经执行了slaveof指令函数，发起了主从机制建立，所以异步开始连接master服务器，调用connectWithMaster函数。12345678910111213141516171819202122232425//连接master主机int connectWithMaster(void) &#123; int fd; fd = anetTcpNonBlockBestEffortBindConnect(NULL, server.masterhost,server.masterport,NET_FIRST_BIND_ADDR);//建立tcp连接 if (fd == -1) &#123; serverLog(LL_WARNING,"Unable to connect to MASTER: %s", strerror(errno)); return C_ERR; &#125; if (aeCreateFileEvent(server.el,fd,AE_READABLE|AE_WRITABLE,syncWithMaster,NULL) == AE_ERR) &#123;//创建描述符的可读可写事件 处理函数为syncWithMaster 这里开始异步连接，主从服务器之间进行一些信息交换以及连接检测 close(fd); serverLog(LL_WARNING,"Can't create readable event for SYNC"); return C_ERR; &#125; server.repl_transfer_lastio = server.unixtime; server.repl_transfer_s = fd; server.repl_state = REPL_STATE_CONNECTING;//修改同步状态 return C_OK;&#125; 在connectWithMaster函数中，主要就是创建主从之间的tcp连接返回套接字描述符，并且创建一个可读可写事件，为下面的主从通信准备，处理函数为syncWithMaster。 心跳检测12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//不断地传送ack给master，不会定期给不支持PSYNC以及副本偏移的master传送ack if (server.masterhost &amp;&amp; server.master &amp;&amp; !(server.master-&gt;flags &amp; CLIENT_PRE_PSYNC)) replicationSendAck();//发送ack指令 listIter li; listNode *ln; robj *ping_argv[1]; //发送一个ping指令给slaves if ((replication_cron_loops % server.repl_ping_slave_period) == 0 &amp;&amp; listLength(server.slaves)) &#123; ping_argv[0] = createStringObject("PING",4); replicationFeedSlaves(server.slaves, server.slaveseldb, ping_argv, 1); decrRefCount(ping_argv[0]); &#125;//给真在等待rdb或者rdb写完发送指令数据的slave发送一个换行符，更新ack时间，避免超时 listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; int is_presync = (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START || (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_END &amp;&amp; server.rdb_child_type != RDB_CHILD_TYPE_SOCKET)); if (is_presync) &#123; if (write(slave-&gt;fd, "\n", 1) == -1) &#123; /* Don't worry about socket errors, it's just a ping. */ &#125; &#125; &#125; //断开连接超时的slaves if (listLength(server.slaves)) &#123; listIter li; listNode *ln; listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; if (slave-&gt;replstate != SLAVE_STATE_ONLINE) continue; if (slave-&gt;flags &amp; CLIENT_PRE_PSYNC) continue; if ((server.unixtime - slave-&gt;repl_ack_time) &gt; server.repl_timeout) &#123; serverLog(LL_WARNING, "Disconnecting timedout slave: %s", replicationGetSlaveName(slave)); freeClient(slave); &#125; &#125; &#125; 心跳机制分为，master节点给slave节点发送ping指令，并且发送一个换行符，更新ack时间，避免由于等待rdb导致误以为失联；slave节点定期给master节点发送自己的offset；对于主从交互超时的节点断开释放client。 replication-slave流程建立主从机制很简单，三种方式：1.通过运行时通过slaveof masterip masterport指令2.在redis.config配置文件中配置slaveof masterip masterport3.在server启动时在启动指令后面加上—slaveof masterip masterport这是第一步，不断通过哪一种方式slave服务器都会执行slaveofCommand函数；12345678910111213141516171819202122232425262728293031//设置服务器的master服务器ip以及端口仅此而已void slaveofCommand(client *c) &#123; /* 在群集模式中不允许使用主节点的当前地址自动配置复制 */ if (server.cluster_enabled) &#123; addReplyError(c,"SLAVEOF not allowed in cluster mode."); return; &#125; /* 特殊的no one指令将slave变成一个master */ if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"no") &amp;&amp; !strcasecmp(c-&gt;argv[2]-&gt;ptr,"one")) &#123; if (server.masterhost) &#123; replicationUnsetMaster();//解除slave服务器的master //........ &#125; &#125; else &#123; long port; if ((getLongFromObjectOrReply(c, c-&gt;argv[2], &amp;port, NULL) != C_OK)) return; //已经连接上指定的master服务器 if (server.masterhost &amp;&amp; !strcasecmp(server.masterhost,c-&gt;argv[1]-&gt;ptr) &amp;&amp; server.masterport == port) &#123; //......... return; &#125; //之前没有连接过或者连接一个新的master服务器 replicationSetMaster(c-&gt;argv[1]-&gt;ptr, port);//设置服务器的master sds client = catClientInfoString(sdsempty(),c); //........ &#125; addReply(c,shared.ok);&#125; 在slaveof指令实现中，主要就是设置slave的masterip以及masrerport这两个参数，具体看replicationUnsetMaster以及replicationSetMaster函数；123456789101112131415161718192021222324252627282930313233343536/* 设置slave的master服务器的ip以及port*/void replicationSetMaster(char *ip, int port) &#123; int was_master = server.masterhost == NULL; sdsfree(server.masterhost); server.masterhost = sdsnew(ip); server.masterport = port; if (server.master) &#123;//释放原来的client freeClient(server.master); &#125; //断开所有阻塞状态的client disconnectAllBlockedClients(); /* Clients blocked in master, now slave. */ //断开所有的slaves服务器，强制重新同步 disconnectSlaves(); //取消该节点的复制行为 cancelReplicationHandshake(); if (was_master) replicationCacheMasterUsingMyself();//缓存master状态 server.repl_state = REPL_STATE_CONNECT; server.repl_down_since = 0;&#125;/* 取消副本操作，设置自己为master */void replicationUnsetMaster(void) &#123; if (server.masterhost == NULL) return; /* Nothing to do. */ sdsfree(server.masterhost); server.masterhost = NULL; //转换副本id shiftReplicationId(); if (server.master) freeClient(server.master); replicationDiscardCachedMaster();//抛弃master缓存 cancelReplicationHandshake();//取消副本行为 //断开所有slave连接 disconnectSlaves(); server.repl_state = REPL_STATE_NONE; //重置selectid为-1 server.slaveseldb = -1;&#125; 可见上面函数主要工作就是设置新的masterip以及masterport，并且在没有正式连接之前创建master-client并将作为缓存master，以及断开所有的slave重新同步。在设置了masterip以及port之后，server就会异步进行同步操作了，在serverCron中会执行replicationCron函数，作为时间事件循环调用。通过replicationCron函数中主从连接，并且创建的可读可写函数，syncWithMaster函数，于是触发套接字的可写函数，开始主从之间的通信，在开始同步之前，需要进行连接检测以及副本配置信息传递。下面看syncWithMaster函数：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292//当主从连接上后，先触发可写事件，执行该处理函数，之后触发可读函数触发void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) &#123; char tmpfile[256], *err = NULL; int dfd = -1, maxtries = 5; int sockerr = 0, psync_result; socklen_t errlen = sizeof(sockerr); UNUSED(el); UNUSED(privdata); UNUSED(mask); /* If this event fired after the user turned the instance into a master * with SLAVEOF NO ONE we must just return ASAP. */ //如果事件触发在执行SLAVEOF NO ONE之后我们关闭fd，立即返回 if (server.repl_state == REPL_STATE_NONE) &#123; close(fd); return; &#125; /* Check for errors in the socket: after a non blocking connect() we * may find that the socket is in error state. */ //检查网络连接套接字是否错误 if (getsockopt(fd, SOL_SOCKET, SO_ERROR, &amp;sockerr, &amp;errlen) == -1) sockerr = errno; if (sockerr) &#123; serverLog(LL_WARNING,"Error condition on socket for SYNC: %s", strerror(sockerr)); goto error; &#125; /* Send a PING to check the master is able to reply without errors. */ //先发送一个PING检查master是否能够返回没有错误的reply if (server.repl_state == REPL_STATE_CONNECTING) &#123; serverLog(LL_NOTICE,"Non blocking connect for SYNC fired the event."); /* Delete the writable event so that the readable event remains * registered and we can wait for the PONG reply. */ aeDeleteFileEvent(server.el,fd,AE_WRITABLE);//删除可写事件只在第一次触发用到 server.repl_state = REPL_STATE_RECEIVE_PONG;//修改状态为等待接受ping回复 /* Send the PING, don't check for errors at all, we have the timeout * that will take care about this. */ err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"PING",NULL);//发送ping if (err) goto write_error; return; &#125; /* Receive the PONG command. */ //可读事件触发，接受master发回的pong消息 if (server.repl_state == REPL_STATE_RECEIVE_PONG) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL); /* We accept only two replies as valid, a positive +PONG reply * (we just check for "+") or an authentication error. * Note that older versions of Redis replied with "operation not * permitted" instead of using a proper error code, so we test * both. */ if (err[0] != '+' &amp;&amp; strncmp(err,"-NOAUTH",7) != 0 &amp;&amp; strncmp(err,"-ERR operation not permitted",28) != 0) &#123;//检测错误回复 serverLog(LL_WARNING,"Error reply to PING from master: '%s'",err); sdsfree(err); goto error; &#125; else &#123; serverLog(LL_NOTICE, "Master replied to PING, replication can continue..."); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_AUTH;//设置为master认证状态 &#125; /* AUTH with the master if required. */ //如果有需要和master主机认证 if (server.repl_state == REPL_STATE_SEND_AUTH) &#123; if (server.masterauth) &#123;//如果需要认证，发送master的auth信息 err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"AUTH",server.masterauth,NULL); if (err) goto write_error; server.repl_state = REPL_STATE_RECEIVE_AUTH;//修改状态为等待接受认证信息返回 return; &#125; else &#123;//如果不需要认证直接发送端口 server.repl_state = REPL_STATE_SEND_PORT; &#125; &#125; /* Receive AUTH reply. */ //接受auth消息回复 if (server.repl_state == REPL_STATE_RECEIVE_AUTH) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL); if (err[0] == '-') &#123;//认证失败 serverLog(LL_WARNING,"Unable to AUTH to MASTER: %s",err); sdsfree(err); goto error; &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_PORT;//认证成功进入端口发送状态 &#125; /* Set the slave port, so that Master's INFO command can list the * slave listening port correctly. */ //发送slave端口到master，这样master的info指令才能列出slave监听的端口 if (server.repl_state == REPL_STATE_SEND_PORT) &#123; sds port = sdsfromlonglong(server.slave_announce_port ? server.slave_announce_port : server.port); err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"REPLCONF", "listening-port",port, NULL);//发送端口消息给master sdsfree(port); if (err) goto write_error; sdsfree(err); server.repl_state = REPL_STATE_RECEIVE_PORT;//修改状态为等待接受port消息的回复消息 return; &#125; /* Receive REPLCONF listening-port reply. */ //接受REPLCONF listening-port的回复 if (server.repl_state == REPL_STATE_RECEIVE_PORT) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL); /* Ignore the error if any, not all the Redis versions support * REPLCONF listening-port. */ if (err[0] == '-') &#123;//如果错误info，忽略不是所有的redis版本都支持配置监听端口 serverLog(LL_NOTICE,"(Non critical) Master does not understand " "REPLCONF listening-port: %s", err); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_IP; &#125; /* Skip REPLCONF ip-address if there is no slave-announce-ip option set. */ //如果没有slave-announce-ip那么忽略ip发送 if (server.repl_state == REPL_STATE_SEND_IP &amp;&amp; server.slave_announce_ip == NULL) &#123; server.repl_state = REPL_STATE_SEND_CAPA; &#125; /* Set the slave ip, so that Master's INFO command can list the * slave IP address port correctly in case of port forwarding or NAT. */ //发送slave的ip信息 if (server.repl_state == REPL_STATE_SEND_IP) &#123; err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"REPLCONF", "ip-address",server.slave_announce_ip, NULL); if (err) goto write_error; sdsfree(err); server.repl_state = REPL_STATE_RECEIVE_IP; return; &#125; /* Receive REPLCONF ip-address reply. */ //接受REPLCONF ip-address信息的回复 if (server.repl_state == REPL_STATE_RECEIVE_IP) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL); /* Ignore the error if any, not all the Redis versions support * REPLCONF listening-port. */ if (err[0] == '-') &#123;//同样可以忽略 不是所有版本redis都支持 serverLog(LL_NOTICE,"(Non critical) Master does not understand " "REPLCONF ip-address: %s", err); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_CAPA;//发送slave能力 &#125; /* Inform the master of our (slave) capabilities. * * EOF: supports EOF-style RDB transfer for diskless replication. * PSYNC2: supports PSYNC v2, so understands +CONTINUE &lt;new repl ID&gt;. * * The master will ignore capabilities it does not understand. */ //发送slave的能力信息 if (server.repl_state == REPL_STATE_SEND_CAPA) &#123; err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"REPLCONF", "capa","eof","capa","psync2",NULL);//发送两种能力rdb以及部分同步 if (err) goto write_error; sdsfree(err); server.repl_state = REPL_STATE_RECEIVE_CAPA; return; &#125; /* Receive CAPA reply. */ //接受capa的回复信息 if (server.repl_state == REPL_STATE_RECEIVE_CAPA) &#123; err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL); /* Ignore the error if any, not all the Redis versions support * REPLCONF capa. */ if (err[0] == '-') &#123;//同样可以忽略 不是所有版本redis都支持 serverLog(LL_NOTICE,"(Non critical) Master does not understand " "REPLCONF capa: %s", err); &#125; sdsfree(err); server.repl_state = REPL_STATE_SEND_PSYNC;//修改为发送部分同步请求状态 &#125; /* Try a partial resynchonization. If we don't have a cached master * slaveTryPartialResynchronization() will at least try to use PSYNC * to start a full resynchronization so that we get the master run id * and the global offset, to try a partial resync at the next * reconnection attempt. */ //首先尝试部分同步，如果之前没有同步过那么执行全局同步，知道run id以及全局offset之后，在下一次同步Hong进行部分同步。 if (server.repl_state == REPL_STATE_SEND_PSYNC) &#123; if (slaveTryPartialResynchronization(fd,0) == PSYNC_WRITE_ERROR) &#123;//slave尝试部分同步 err = sdsnew("Write error sending the PSYNC command."); goto write_error; &#125; server.repl_state = REPL_STATE_RECEIVE_PSYNC; return; &#125; /* If reached this point, we should be in REPL_STATE_RECEIVE_PSYNC. */ if (server.repl_state != REPL_STATE_RECEIVE_PSYNC) &#123;//到达这里判断，如果不是REPL_STATE_RECEIVE_PSYNC，表示同步错误 serverLog(LL_WARNING,"syncWithMaster(): state machine error, " "state should be RECEIVE_PSYNC but is %d", server.repl_state); goto error; &#125; psync_result = slaveTryPartialResynchronization(fd,1); if (psync_result == PSYNC_WAIT_REPLY) return; /* Try again later... */ /* If the master is in an transient error, we should try to PSYNC * from scratch later, so go to the error path. This happens when * the server is loading the dataset or is not connected with its * master and so forth. */ if (psync_result == PSYNC_TRY_LATER) goto error; /* Note: if PSYNC does not return WAIT_REPLY, it will take care of * uninstalling the read handler from the file descriptor. */ if (psync_result == PSYNC_CONTINUE) &#123; serverLog(LL_NOTICE, "MASTER &lt;-&gt; SLAVE sync: Master accepted a Partial Resynchronization."); return; &#125; /* PSYNC failed or is not supported: we want our slaves to resync with us * as well, if we have any sub-slaves. The master may transfer us an * entirely different data set and we have no way to incrementally feed * our slaves after that. */ disconnectSlaves(); /* Force our slaves to resync with us as well. */ freeReplicationBacklog(); /* Don't allow our chained slaves to PSYNC. */ /* Fall back to SYNC if needed. Otherwise psync_result == PSYNC_FULLRESYNC * and the server.master_replid and master_initial_offset are * already populated. */ if (psync_result == PSYNC_NOT_SUPPORTED) &#123; serverLog(LL_NOTICE,"Retrying with SYNC..."); if (syncWrite(fd,"SYNC\r\n",6,server.repl_syncio_timeout*1000) == -1) &#123; serverLog(LL_WARNING,"I/O error writing to MASTER: %s", strerror(errno)); goto error; &#125; &#125; /* Prepare a suitable temp file for bulk transfer */ while(maxtries--) &#123; snprintf(tmpfile,256, "temp-%d.%ld.rdb",(int)server.unixtime,(long int)getpid()); dfd = open(tmpfile,O_CREAT|O_WRONLY|O_EXCL,0644); if (dfd != -1) break; sleep(1); &#125; if (dfd == -1) &#123; serverLog(LL_WARNING,"Opening the temp file needed for MASTER &lt;-&gt; SLAVE synchronization: %s",strerror(errno)); goto error; &#125; /* Setup the non blocking download of the bulk file. */ if (aeCreateFileEvent(server.el,fd, AE_READABLE,readSyncBulkPayload,NULL) == AE_ERR) &#123; serverLog(LL_WARNING, "Can't create readable event for SYNC: %s (fd=%d)", strerror(errno),fd); goto error; &#125; server.repl_state = REPL_STATE_TRANSFER; server.repl_transfer_size = -1; server.repl_transfer_read = 0; server.repl_transfer_last_fsync_off = 0; server.repl_transfer_fd = dfd; server.repl_transfer_lastio = server.unixtime; server.repl_transfer_tmpfile = zstrdup(tmpfile); return;error: aeDeleteFileEvent(server.el,fd,AE_READABLE|AE_WRITABLE); if (dfd != -1) close(dfd); close(fd); server.repl_transfer_s = -1; server.repl_state = REPL_STATE_CONNECT; return;write_error: /* Handle sendSynchronousCommand(SYNC_CMD_WRITE) errors. */ serverLog(LL_WARNING,"Sending command to master in replication handshake: %s", err); sdsfree(err); goto error;&#125; 在syncWithMaster函数中分为两个部分，一部分是通信部分，一部分是同步部分。通信部分的主要步骤如下：先发送master一个ping指令，master在接到ping指令之后，回应slave消息，如果回应pong进行下一步，否则连接失败，如果需要服务器认证，发送auth+认证消息给master，master检查是否认证通过，返回相应的信息，如果错误连接失败，如果成功下一步，否则直接下一步，发送replconf指令配置port，ip，以及capa，所有完成后状态变为REPL_STATE_SEND_PSYNC，即准备进行同步。即将开始同步首先会执行slaveTryPartialResynchronization函数尝试进行部分同步操作。slaveTryPartialResynchronization函数分为两个部分，读以及写，读就是读取runid以及offset，写就是同步操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160//slave服务器尝试进行部分同步int slaveTryPartialResynchronization(int fd, int read_reply) &#123; char *psync_replid; char psync_offset[32]; sds reply; /* Writing half */ //写入部分当read_reply=0时 if (!read_reply) &#123; /* Initially set master_initial_offset to -1 to mark the current * master run_id and offset as not valid. Later if we'll be able to do * a FULL resync using the PSYNC command we'll set the offset at the * right value, so that this information will be propagated to the * client structure representing the master into server.master. */ //先初始化master_initial_offset以及psync_replid，如果有cache的话，如果没有初始化成特定字符 //下面master可以通过这个状态来判断进行全局同步还是部分同步 server.master_initial_offset = -1; if (server.cached_master) &#123; psync_replid = server.cached_master-&gt;replid; snprintf(psync_offset,sizeof(psync_offset),"%lld", server.cached_master-&gt;reploff+1); serverLog(LL_NOTICE,"Trying a partial resynchronization (request %s:%s).", psync_replid, psync_offset); &#125; else &#123; serverLog(LL_NOTICE,"Partial resynchronization not possible (no cached master)"); psync_replid = "?"; memcpy(psync_offset,"-1",3); &#125; /* Issue the PSYNC command */ //发送同步请求消息 reply = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"PSYNC",psync_replid,psync_offset,NULL); if (reply != NULL) &#123; serverLog(LL_WARNING,"Unable to send PSYNC to master: %s",reply); sdsfree(reply); aeDeleteFileEvent(server.el,fd,AE_READABLE);//副作用删除了可读事件 return PSYNC_WRITE_ERROR; &#125; return PSYNC_WAIT_REPLY;//等待回应 &#125; /* Reading half */ reply = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL); if (sdslen(reply) == 0) &#123;//回复空信息继续等待 /* The master may send empty newlines after it receives PSYNC * and before to reply, just to keep the connection alive. */ sdsfree(reply); return PSYNC_WAIT_REPLY; &#125; aeDeleteFileEvent(server.el,fd,AE_READABLE);//先删除可读事件，接受同步消息 if (!strncmp(reply,"+FULLRESYNC",11)) &#123;//全局同步之前的初始化设置 char *replid = NULL, *offset = NULL; /* FULL RESYNC, parse the reply in order to extract the run id * and the replication offset. */ replid = strchr(reply,' '); if (replid) &#123; replid++; offset = strchr(replid,' '); if (offset) offset++; &#125; if (!replid || !offset || (offset-replid-1) != CONFIG_RUN_ID_SIZE) &#123; serverLog(LL_WARNING,//报告FULLRESYNC信息错误，初始化runid为0，确保下一个PSYNCs失败 "Master replied with wrong +FULLRESYNC syntax."); /* This is an unexpected condition, actually the +FULLRESYNC * reply means that the master supports PSYNC, but the reply * format seems wrong. To stay safe we blank the master * replid to make sure next PSYNCs will fail. */ memset(server.master_replid,0,CONFIG_RUN_ID_SIZE+1); &#125; else &#123; //设置runid以及初始化offset memcpy(server.master_replid, replid, offset-replid-1); server.master_replid[CONFIG_RUN_ID_SIZE] = '\0'; server.master_initial_offset = strtoll(offset,NULL,10); serverLog(LL_NOTICE,"Full resync from master: %s:%lld", server.master_replid, server.master_initial_offset); &#125; /* We are going to full resync, discard the cached master structure. */ replicationDiscardCachedMaster();//开始全局同步了丢弃缓存的master信息 sdsfree(reply); return PSYNC_FULLRESYNC; &#125; if (!strncmp(reply,"+CONTINUE",9)) &#123;//局部同步前的准备 /* Partial resync was accepted. */ serverLog(LL_NOTICE, "Successful partial resynchronization with master."); /* Check the new replication ID advertised by the master. If it * changed, we need to set the new ID as primary ID, and set or * secondary ID as the old master ID up to the current offset, so * that our sub-slaves will be able to PSYNC with us after a * disconnection. */ char *start = reply+10; char *end = reply+9; while(end[0] != '\r' &amp;&amp; end[0] != '\n' &amp;&amp; end[0] != '\0') end++; if (end-start == CONFIG_RUN_ID_SIZE) &#123; char new[CONFIG_RUN_ID_SIZE+1]; memcpy(new,start,CONFIG_RUN_ID_SIZE); new[CONFIG_RUN_ID_SIZE] = '\0'; if (strcmp(new,server.cached_master-&gt;replid)) &#123; /* Master ID changed. */ serverLog(LL_WARNING,"Master replication ID changed to %s",new); /* Set the old ID as our ID2, up to the current offset+1. */ memcpy(server.replid2,server.cached_master-&gt;replid, sizeof(server.replid2)); server.second_replid_offset = server.master_repl_offset+1; /* Update the cached master ID and our own primary ID to the * new one. */ memcpy(server.replid,new,sizeof(server.replid)); memcpy(server.cached_master-&gt;replid,new,sizeof(server.replid)); /* Disconnect all the sub-slaves: they need to be notified. */ //主机换了新的master 断开所有的slaves主机 需要重新通知 disconnectSlaves(); &#125; &#125; /* Setup the replication to continue. */ //设置复制继续 sdsfree(reply); replicationResurrectCachedMaster(fd);//重新设置新的master以及cachemaster return PSYNC_CONTINUE; &#125; /* If we reach this point we received either an error (since the master does * not understand PSYNC or because it is in a special state and cannot * serve our request), or an unexpected reply from the master. * * Return PSYNC_NOT_SUPPORTED on errors we don't understand, otherwise * return PSYNC_TRY_LATER if we believe this is a transient error. */ //如果执行到这里意味着同步失败了 if (!strncmp(reply,"-NOMASTERLINK",13) || !strncmp(reply,"-LOADING",8))//暂时不能同步，稍后尝试 &#123; serverLog(LL_NOTICE, "Master is currently unable to PSYNC " "but should be in the future: %s", reply); sdsfree(reply); return PSYNC_TRY_LATER; &#125; if (strncmp(reply,"-ERR",4)) &#123;//消息错误 /* If it's not an error, log the unexpected event. */ serverLog(LL_WARNING, "Unexpected reply to PSYNC from master: %s", reply); &#125; else &#123;//不支持部分同步 serverLog(LL_NOTICE, "Master does not support PSYNC or is in " "error state (reply: %s)", reply); &#125; sdsfree(reply); replicationDiscardCachedMaster(); return PSYNC_NOT_SUPPORTED;&#125; 在写的部分，首先获取runid以及offset然后发送给master同步指令，进行同步。在master中进行master同步指令操作，然后返回信息fullsync或者continue，在slaveTryPartialResynchronization中的读部分进行判断，做出相应slave端的处理。之后我们在跳到syncWithMaster函数中看看相应的处理。可见在syncWithMaster函数中只有对全局同步的处理，通过添加一个可读函数并且创建了一个rdb的文件来接受master节点发送的rdb信息。那么部分同步的操作其实在slaveTryPartialResynchronization中的replicationResurrectCachedMaster函数中就做了处理。123456789101112131415161718192021222324252627void replicationResurrectCachedMaster(int newfd) &#123; server.master = server.cached_master; server.cached_master = NULL; server.master-&gt;fd = newfd; server.master-&gt;flags &amp;= ~(CLIENT_CLOSE_AFTER_REPLY|CLIENT_CLOSE_ASAP); server.master-&gt;authenticated = 1; server.master-&gt;lastinteraction = server.unixtime; server.repl_state = REPL_STATE_CONNECTED; /* Re-add to the list of clients. */ listAddNodeTail(server.clients,server.master);//添加master到client列表中 if (aeCreateFileEvent(server.el, newfd, AE_READABLE,//添加可读事件,读取master发来的指令 readQueryFromClient, server.master)) &#123; serverLog(LL_WARNING,"Error resurrecting the cached master, impossible to add the readable handler: %s", strerror(errno)); freeClientAsync(server.master); /* Close ASAP. */ &#125; /* We may also need to install the write handler as well if there is * pending data in the write buffers. */ if (clientHasPendingReplies(server.master)) &#123; if (aeCreateFileEvent(server.el, newfd, AE_WRITABLE,//添加可写指令，发送reply给master sendReplyToClient, server.master)) &#123; serverLog(LL_WARNING,"Error resurrecting the cached master, impossible to add the writable handler: %s", strerror(errno)); freeClientAsync(server.master); /* Close ASAP. */ &#125; &#125;&#125; 可见通过置换新的master并且更新状态，然后添加可读可写函数，对master发来的同步指令集执行并且回应消息。至此完成部分同步。至于全局同步创建可读事件的处理函数readSyncBulkPayload，意在读取来自master的rdb文件流然后同步状态。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119//异步读取全局同步来自master的payload文件#define REPL_MAX_WRITTEN_BEFORE_FSYNC (1024*1024*8) /* 8 MB */void readSyncBulkPayload(aeEventLoop *el, int fd, void *privdata, int mask) &#123; char buf[4096]; ssize_t nread, readlen; off_t left; UNUSED(el); UNUSED(privdata); UNUSED(mask); /* Static vars used to hold the EOF mark, and the last bytes received * form the server: when they match, we reached the end of the transfer. */ static char eofmark[CONFIG_RUN_ID_SIZE]; static char lastbytes[CONFIG_RUN_ID_SIZE]; static int usemark = 0; //如果repl_transfer_size=-1 先读取bulklength if (server.repl_transfer_size == -1) &#123; //........省略 读取第一行 有两种形式的数据一种是disk的数据一种是stream数据的处理 //........省略 对格式内容错误的判断 return; &#125; /* Read bulk data */ //..... nread = read(fd,buf,readlen);//从fd中读取数据 //...... /* When a mark is used, we want to detect EOF asap in order to avoid * writing the EOF mark into the file... */ int eof_reached = 0; //..... //更新io事件戳 以及写入接受的数据到创建的rdb临时文件中 server.repl_transfer_lastio = server.unixtime; if (write(server.repl_transfer_fd,buf,nread) != nread) &#123; serverLog(LL_WARNING,"Write error or short write writing to the DB dump file needed for MASTER &lt;-&gt; SLAVE synchronization: %s", strerror(errno)); goto error; &#125; server.repl_transfer_read += nread; //..... //当写入的数据过多时，需要强制将他们从内核刷新到磁盘中 if (server.repl_transfer_read &gt;= server.repl_transfer_last_fsync_off + REPL_MAX_WRITTEN_BEFORE_FSYNC) &#123; off_t sync_size = server.repl_transfer_read - server.repl_transfer_last_fsync_off; rdb_fsync_range(server.repl_transfer_fd,//刷新操作 server.repl_transfer_last_fsync_off, sync_size); server.repl_transfer_last_fsync_off += sync_size; &#125; //..... //如果写入磁盘完毕那么需要进行rdb同步了 if (eof_reached) &#123; int aof_is_enabled = server.aof_state != AOF_OFF; if (rename(server.repl_transfer_tmpfile,server.rdb_filename) == -1) &#123; serverLog(LL_WARNING,"Failed trying to rename the temp DB into dump.rdb in MASTER &lt;-&gt; SLAVE synchronization: %s", strerror(errno)); cancelReplicationHandshake(); return; &#125;//首先修改文件名从临时到正式 serverLog(LL_NOTICE, "MASTER &lt;-&gt; SLAVE sync: Flushing old data"); /* We need to stop any AOFRW fork before flusing and parsing * RDB, otherwise we'll create a copy-on-write disaster. */ if(aof_is_enabled) stopAppendOnly(); signalFlushedDb(-1);//减少事务键 emptyDb(//清空数据库准备进行同步 -1, server.repl_slave_lazy_flush ? EMPTYDB_ASYNC : EMPTYDB_NO_FLAGS, replicationEmptyDbCallback); /* Before loading the DB into memory we need to delete the readable * handler, otherwise it will get called recursively since * rdbLoad() will call the event loop to process events from time to * time for non blocking loading. */ aeDeleteFileEvent(server.el,server.repl_transfer_s,AE_READABLE); serverLog(LL_NOTICE, "MASTER &lt;-&gt; SLAVE sync: Loading DB in memory"); rdbSaveInfo rsi = RDB_SAVE_INFO_INIT; if (rdbLoad(server.rdb_filename,&amp;rsi) != C_OK) &#123;//载入新的rdb文件 serverLog(LL_WARNING,"Failed trying to load the MASTER synchronization DB from disk"); cancelReplicationHandshake(); /* Re-enable the AOF if we disabled it earlier, in order to restore * the original configuration. */ if (aof_is_enabled) restartAOF();//开启刚刚可能闭关的aof return; &#125; /* Final setup of the connected slave &lt;- master link */ zfree(server.repl_transfer_tmpfile); close(server.repl_transfer_fd); replicationCreateMasterClient(server.repl_transfer_s,rsi.repl_stream_db);//设置新的master server.repl_state = REPL_STATE_CONNECTED;//修改连接状态 /* After a full resynchroniziation we use the replication ID and * offset of the master. The secondary ID / offset are cleared since * we are starting a new history. */ memcpy(server.replid,server.master-&gt;replid,sizeof(server.replid)); server.master_repl_offset = server.master-&gt;reploff; clearReplicationId2(); /* Let's create the replication backlog if needed. Slaves need to * accumulate the backlog regardless of the fact they have sub-slaves * or not, in order to behave correctly if they are promoted to * masters after a failover. */ if (server.repl_backlog == NULL) createReplicationBacklog();//创建一个同步缓冲区 serverLog(LL_NOTICE, "MASTER &lt;-&gt; SLAVE sync: Finished with success"); /* Restart the AOF subsystem now that we finished the sync. This * will trigger an AOF rewrite, and when done will start appending * to the new file. */ if (aof_is_enabled) restartAOF(); &#125; return;error: cancelReplicationHandshake(); return;&#125; 在readSyncBulkPayload中主要有读取数据，分为两种类型数据，以及清空数据库，载入rdb文件，还有master的创建设置以及一些状态的更新。 replication-master流程对于master，接受来自slave的sync指令，并且进行同步操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147//同步指令的实现void syncCommand(client *c) &#123; /* ignore SYNC if already slave or in monitor mode */ //自身是一个slave直接退出 if (c-&gt;flags &amp; CLIENT_SLAVE) return; /* Refuse SYNC requests if we are a slave but the link with our master * is not ok... */ //拒绝同步如果用master服务器并且仍然处在连接状态 if (server.masterhost &amp;&amp; server.repl_state != REPL_STATE_CONNECTED) &#123; addReplySds(c,sdsnew("-NOMASTERLINK Can't SYNC while not connected with my master\r\n")); return; &#125; /* SYNC can't be issued when the server has pending data to send to * the client about already issued commands. We need a fresh reply * buffer registering the differences between the BGSAVE and the current * dataset, so that we can copy to other slaves if needed. */ //当请求的c有没有发出的reply，会与同步的消息混淆所以拒绝同步 if (clientHasPendingReplies(c)) &#123; addReplyError(c,"SYNC and PSYNC are invalid with pending output"); return; &#125; serverLog(LL_NOTICE,"Slave %s asks for synchronization", replicationGetSlaveName(c));//答应请求消息 /* Try a partial resynchronization if this is a PSYNC command. * If it fails, we continue with usual full resynchronization, however * when this happens masterTryPartialResynchronization() already * replied with: * * +FULLRESYNC &lt;replid&gt; &lt;offset&gt; * * So the slave knows the new replid and offset to try a PSYNC later * if the connection with the master is lost. */ if (!strcasecmp(c-&gt;argv[0]-&gt;ptr,"psync")) &#123; if (masterTryPartialResynchronization(c) == C_OK) &#123;//尝试进行master端的局部同步 server.stat_sync_partial_ok++;//局部同步成功直接返回 return; /* No full resync needed, return. */ &#125; else &#123; char *master_replid = c-&gt;argv[1]-&gt;ptr; /* Increment stats for failed PSYNCs, but only if the * replid is not "?", as this is used by slaves to force a full * resync on purpose when they are not albe to partially * resync. */ //如果之前没有连接过那么不会让局部同步失败加1 if (master_replid[0] != '?') server.stat_sync_partial_err++; &#125; &#125; else &#123; /* If a slave uses SYNC, we are dealing with an old implementation * of the replication protocol (like redis-cli --slave). Flag the client * so that we don't expect to receive REPLCONF ACK feedbacks. */ c-&gt;flags |= CLIENT_PRE_PSYNC;//使用老版本的实现 &#125; /* Full resynchronization. */ server.stat_sync_full++;//开始全局同步 /* Setup the slave as one waiting for BGSAVE to start. The following code * paths will change the state if we handle the slave differently. */ c-&gt;replstate = SLAVE_STATE_WAIT_BGSAVE_START;//修改slave客户端的状态为SLAVE_STATE_WAIT_BGSAVE_START等待rdb后台开始 if (server.repl_disable_tcp_nodelay) anetDisableTcpNoDelay(NULL, c-&gt;fd); /* Non critical if it fails. */ c-&gt;repldbfd = -1; c-&gt;flags |= CLIENT_SLAVE; listAddNodeTail(server.slaves,c); /* Create the replication backlog if needed. */ //创建master端的复制后台缓冲区并且修改runid if (listLength(server.slaves) == 1 &amp;&amp; server.repl_backlog == NULL) &#123; /* When we create the backlog from scratch, we always use a new * replication ID and clear the ID2, since there is no valid * past history. */ changeReplicationId(); clearReplicationId2(); createReplicationBacklog(); &#125; //下面分为三种情况： //1.有rdb进程并且写入disk //2.有rdb进程并且写入套接字 //3.没有rdb进程 /* CASE 1: BGSAVE is in progress, with disk target. */ if (server.rdb_child_pid != -1 &amp;&amp; server.rdb_child_type == RDB_CHILD_TYPE_DISK) &#123; /* Ok a background save is in progress. Let's check if it is a good * one for replication, i.e. if there is another slave that is * registering differences since the server forked to save. */ client *slave; listNode *ln; listIter li; listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; slave = ln-&gt;value; if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_END) break; &#125; /* To attach this slave, we check that it has at least all the * capabilities of the slave that triggered the current BGSAVE. */ if (ln &amp;&amp; ((c-&gt;slave_capa &amp; slave-&gt;slave_capa) == slave-&gt;slave_capa)) &#123; /* Perfect, the server is already registering differences for * another slave. Set the right state, and copy the buffer. */ copyClientOutputBuffer(c,slave);//重复利用已经准备好的数据 replicationSetupSlaveForFullResync(c,slave-&gt;psync_initial_offset); serverLog(LL_NOTICE,"Waiting for end of BGSAVE for SYNC"); &#125; else &#123; /* No way, we need to wait for the next BGSAVE in order to * register differences. */ serverLog(LL_NOTICE,"Can't attach the slave to the current BGSAVE. Waiting for next BGSAVE for SYNC"); &#125; /* CASE 2: BGSAVE is in progress, with socket target. */ &#125; else if (server.rdb_child_pid != -1 &amp;&amp; server.rdb_child_type == RDB_CHILD_TYPE_SOCKET) &#123; /* There is an RDB child process but it is writing directly to * children sockets. We need to wait for the next BGSAVE * in order to synchronize. */ serverLog(LL_NOTICE,"Current BGSAVE has socket target. Waiting for next BGSAVE for SYNC"); /* CASE 3: There is no BGSAVE is progress. */ &#125; else &#123; if (server.repl_diskless_sync &amp;&amp; (c-&gt;slave_capa &amp; SLAVE_CAPA_EOF)) &#123; /* Diskless replication RDB child is created inside * replicationCron() since we want to delay its start a * few seconds to wait for more slaves to arrive. */ if (server.repl_diskless_sync_delay) serverLog(LL_NOTICE,"Delay next BGSAVE for diskless SYNC"); &#125; else &#123; /* Target is disk (or the slave is not capable of supporting * diskless replication) and we don't have a BGSAVE in progress, * let's start one. */ if (server.aof_child_pid == -1) &#123; startBgsaveForReplication(c-&gt;slave_capa);//开始复制的后台rdb保存 &#125; else &#123; serverLog(LL_NOTICE, "No BGSAVE in progress, but an AOF rewrite is active. " "BGSAVE for replication delayed"); &#125; &#125; &#125; return;&#125; 对于同步函数主要有几部分：首先尝试局部同步如果失败那么进行全局同步，在全局同步中有三种情况1.有rdb进程并且写入disk 利用已经准备好的数据进行同步，复制缓冲区然后开启全局同步调用replicationSetupSlaveForFullResync函数2.有rdb进程并且写入套接字 只有等待下一次bgsave进程3.没有rdb进程 判断是写入disk还是直接套接字传输调用startBgsaveForReplication函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273//开启master对slave全局同步，在rdb文件准备好之后触发int replicationSetupSlaveForFullResync(client *slave, long long offset) &#123; char buf[128]; int buflen; slave-&gt;psync_initial_offset = offset;//修改复制状态 slave-&gt;replstate = SLAVE_STATE_WAIT_BGSAVE_END; server.slaveseldb = -1; if (!(slave-&gt;flags &amp; CLIENT_PRE_PSYNC)) &#123;//如果是老版本的不回复 buflen = snprintf(buf,sizeof(buf),"+FULLRESYNC %s %lld\r\n", server.replid,offset); if (write(slave-&gt;fd,buf,buflen) != buflen) &#123;//写回FULLRESYNC回复 freeClientAsync(slave); return C_ERR; &#125; &#125; return C_OK;&#125;//master端开始复制操作准备rdb文件int startBgsaveForReplication(int mincapa) &#123; int retval; int socket_target = server.repl_diskless_sync &amp;&amp; (mincapa &amp; SLAVE_CAPA_EOF); listIter li; listNode *ln; serverLog(LL_NOTICE,"Starting BGSAVE for SYNC with target: %s", socket_target ? "slaves sockets" : "disk"); rdbSaveInfo rsi = RDB_SAVE_INFO_INIT; if (server.master) rsi.repl_stream_db = server.master-&gt;db-&gt;id; //写入目标是磁盘还是直接进行套接字传输 if (socket_target) retval = rdbSaveToSlavesSockets(&amp;rsi); else retval = rdbSaveBackground(server.rdb_filename,&amp;rsi); if (retval == C_ERR) &#123;//如果bgsave失败，删除client以及修改状态 serverLog(LL_WARNING,"BGSAVE for replication failed"); listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) &#123; slave-&gt;flags &amp;= ~CLIENT_SLAVE; listDelNode(server.slaves,ln); addReplyError(slave, "BGSAVE failed, replication can't continue"); slave-&gt;flags |= CLIENT_CLOSE_AFTER_REPLY; &#125; &#125; return retval; &#125; &#125; //如果已经写到套接字中传输了那么不需要开启同步，并且已经修改了状态 if (!socket_target) &#123; listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) &#123; replicationSetupSlaveForFullResync(slave, getPsyncInitialOffset());//开启全局同步 &#125; &#125; &#125; /* Flush the script cache, since we need that slave differences are * accumulated without requiring slaves to match our cached scripts. */ if (retval == C_OK) replicationScriptCacheFlush(); return retval;&#125; bgsave完成之后都需要调用replicationSetupSlaveForFullResync函数来开启全局同步，并且在该函数中其实并没有做什么相关的触发包括函数调用以及添加文件事件，所以必然是在serverCron中开始全局同步。调用关系如下：serverCron()-&gt;backgroundSaveDoneHandler()-&gt;backgroundSaveDoneHandlerDisk()-&gt;updateSlavesWaitingBgsave()在updateSlavesWaitingBgsave函数中主要就是根据发送的两种方式，来设置slave的client的状态，如果是通过disk来同步，那么设置可写事件，往slave中传输数据，开始同步。可写事件的处理函数为sendBulkToSlave，当然是来传输数据的了。在该函数中主要就是读rdb文件，将文件被容传送给slave，传送完毕后删除可写事件，然后调用了putSlaveOnline函数。在putSlaveOnline函数中，主要就是修改slave状态为online表示传送完毕，然后创建可写事件用来回应slave服务器。下面看一下尝试进行局部同步的函数：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//master尝试进行局部同步操作返回ERR表示局部同步失败进行全局同步int masterTryPartialResynchronization(client *c) &#123; long long psync_offset, psync_len; char *master_replid = c-&gt;argv[1]-&gt;ptr; char buf[128]; int buflen; //解析psync_offset，如果错误进行全局同步 if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;psync_offset,NULL) != C_OK) goto need_full_resync; //检查replid是否匹配，如果replid不为“？” if (strcasecmp(master_replid, server.replid) &amp;&amp; (strcasecmp(master_replid, server.replid2) || psync_offset &gt; server.second_replid_offset)) &#123; //根据具体情况报告相应的原因 if (master_replid[0] != '?') &#123; if (strcasecmp(master_replid, server.replid) &amp;&amp; strcasecmp(master_replid, server.replid2)) &#123; serverLog(LL_NOTICE,"Partial resynchronization not accepted: " "Replication ID mismatch (Slave asked for '%s', my " "replication IDs are '%s' and '%s')", master_replid, server.replid, server.replid2); &#125; else &#123; serverLog(LL_NOTICE,"Partial resynchronization not accepted: " "Requested offset for second ID was %lld, but I can reply " "up to %lld", psync_offset, server.second_replid_offset); &#125; &#125; else &#123; serverLog(LL_NOTICE,"Full resync requested by slave %s", replicationGetSlaveName(c)); &#125; goto need_full_resync; &#125; //如果进行局部同步，那么检查我们是够还有slave需要的数据 if (!server.repl_backlog || psync_offset &lt; server.repl_backlog_off || psync_offset &gt; (server.repl_backlog_off + server.repl_backlog_histlen)) &#123; serverLog(LL_NOTICE, "Unable to partial resync with slave %s for lack of backlog (Slave request was: %lld).", replicationGetSlaveName(c), psync_offset); if (psync_offset &gt; server.master_repl_offset) &#123; serverLog(LL_WARNING, "Warning: slave %s tried to PSYNC with an offset that is greater than the master replication offset.", replicationGetSlaveName(c)); &#125; goto need_full_resync; &#125; //开始局部同步 c-&gt;flags |= CLIENT_SLAVE; c-&gt;replstate = SLAVE_STATE_ONLINE;//设置为online状态 c-&gt;repl_ack_time = server.unixtime;//跟新ack事件 c-&gt;repl_put_online_on_ack = 0; listAddNodeTail(server.slaves,c);//添加到slave链表中 //发送reply信息 if (c-&gt;slave_capa &amp; SLAVE_CAPA_PSYNC2) &#123; buflen = snprintf(buf,sizeof(buf),"+CONTINUE %s\r\n", server.replid); &#125; else &#123; buflen = snprintf(buf,sizeof(buf),"+CONTINUE\r\n"); &#125; if (write(c-&gt;fd,buf,buflen) != buflen) &#123; freeClientAsync(c); return C_OK; &#125; //从复制缓冲区中将数据发送给slave psync_len = addReplyReplicationBacklog(c,psync_offset); serverLog(LL_NOTICE, "Partial resynchronization request from %s accepted. Sending %lld bytes of backlog starting from offset %lld.", replicationGetSlaveName(c), psync_len, psync_offset); refreshGoodSlavesCount(); return C_OK; need_full_resync: return C_ERR;&#125; 检查replid以及reploff判断是否可以进行局部同步，如果可以进行局部同步，那么检查复制缓冲区中是否有断开连接遗漏的指令数据，如果有那么可以调用addReplyReplicationBacklog函数将数据发送给slave，并且返回continue的reply。在主从同步完成之后，不管是局部同步还是全局同步，之后都通过propagate函数来传播指令了，每一次master执行写指令，那么通过传播函数将指令传给slave。123456789//指令传播函数 一般用于主从服务器的状态同步void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc, int flags)&#123; if (server.aof_state != AOF_OFF &amp;&amp; flags &amp; PROPAGATE_AOF) feedAppendOnlyFile(cmd,dbid,argv,argc); if (flags &amp; PROPAGATE_REPL) replicationFeedSlaves(server.slaves,dbid,argv,argc);&#125; 可见传播有两种方式aof传播就是将指令写到aof文件中去，以及主从传播，主从传播调用函数replicationFeedSlaves。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//主节点给slaves节点发送指令副本void replicationFeedSlaves(list *slaves, int dictid, robj **argv, int argc) &#123; listNode *ln; listIter li; int j, len; char llstr[LONG_STR_SIZE]; //确保是top-master server if (server.masterhost != NULL) return; //如果没有副本缓冲区并且没有slave表示从来没有进行过主从同步，直接退出 if (server.repl_backlog == NULL &amp;&amp; listLength(slaves) == 0) return; /* We can't have slaves attached and no backlog. */ serverAssert(!(listLength(slaves) != 0 &amp;&amp; server.repl_backlog == NULL)); //需要的情况下发送select指令 if (server.slaveseldb != dictid) &#123; robj *selectcmd; //共享selectdb指令 if (dictid &gt;= 0 &amp;&amp; dictid &lt; PROTO_SHARED_SELECT_CMDS) &#123; selectcmd = shared.select[dictid]; &#125; else &#123; int dictid_len; dictid_len = ll2string(llstr,sizeof(llstr),dictid); selectcmd = createObject(OBJ_STRING, sdscatprintf(sdsempty(), "*2\r\n$6\r\nSELECT\r\n$%d\r\n%s\r\n", dictid_len, llstr)); &#125; //将指令添加到缓冲区中 if (server.repl_backlog) feedReplicationBacklogWithObject(selectcmd); //给slaves服务器发送指令 listRewind(slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) continue; addReply(slave,selectcmd); &#125; if (dictid &lt; 0 || dictid &gt;= PROTO_SHARED_SELECT_CMDS) decrRefCount(selectcmd); &#125; server.slaveseldb = dictid; /* Write the command to the replication backlog if any. */ //将指令写到缓冲区中 if (server.repl_backlog) &#123; char aux[LONG_STR_SIZE+3]; /* Add the multi bulk reply length. */ aux[0] = '*'; len = ll2string(aux+1,sizeof(aux)-1,argc); aux[len+1] = '\r'; aux[len+2] = '\n'; feedReplicationBacklog(aux,len+3); for (j = 0; j &lt; argc; j++) &#123; long objlen = stringObjectLen(argv[j]); /* We need to feed the buffer with the object as a bulk reply * not just as a plain string, so create the $..CRLF payload len * and add the final CRLF */ aux[0] = '$'; len = ll2string(aux+1,sizeof(aux)-1,objlen); aux[len+1] = '\r'; aux[len+2] = '\n'; feedReplicationBacklog(aux,len+3); feedReplicationBacklogWithObject(argv[j]); feedReplicationBacklog(aux+len+1,2); &#125; &#125; //将指令传播给slave服务器 listRewind(slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; client *slave = ln-&gt;value; /* Don't feed slaves that are still waiting for BGSAVE to start */ if (slave-&gt;replstate == SLAVE_STATE_WAIT_BGSAVE_START) continue; /* Feed slaves that are waiting for the initial SYNC (so these commands * are queued in the output buffer until the initial SYNC completes), * or are already in sync with the master. */ /* Add the multi bulk length. */ addReplyMultiBulkLen(slave,argc); /* Finally any additional argument that was not stored inside the * static buffer if any (from j to argc). */ for (j = 0; j &lt; argc; j++) addReplyBulk(slave,argv[j]); &#125;&#125; 可见replicationFeedSlaves函数将master的指令先写入到复制缓冲区中，然后将指令写入到slave的输出缓冲区中，在master完成全局操作后创建的可写事件在这里就会触发了，在rdb还在保存期间不需要写入缓冲区，指令回保存到rdb文件中，因为rdb的bgsave会保存期间执行的指令。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Install]]></title>
    <url>%2F2017%2F11%2F21%2FDocker-Install%2F</url>
    <content type="text"><![CDATA[Docker分为ce和ee分别是社区版本和企业版本，只是用的仓库url不同而已。系统配置ubuntu14.04 删除之前的版本sudo apt-get remove docker docker-engine docker.io 尽量使用aufssudo apt-get updatesudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual 安装仓库sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates curl software-properties-common //允许apt使用https仓库 添加GPG-keycurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 确认key的序列码sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &#100;&#111;&#x63;&#x6b;&#x65;&#x72;&#x40;&#x64;&#x6f;&#99;&#107;&#x65;&#114;&#x2e;&#99;&#111;&#109;sub 4096R/F273FCD8 2017-02-22 设置稳定仓库urlsudo add-apt-repository “deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable” 安装最新版本dockersudo apt-get updatesudo apt-get install docker-ce 列出docker版本listapt-cache madsion docker-ce 安装特定版本dockersudo apt-get install docker-ce= 测试是否安装成功，一般需要重启系统sudo docker run hello-world 更新dockersudo apt-get updaterepeat the abow installing steps12卸载docker，以及删除docker相关文件sudo apt-get purge docker-cesudo rm –rf /var/lib/docker 参考网址：https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#uninstall-docker-ce]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What is Docker?]]></title>
    <url>%2F2017%2F11%2F21%2FWhat-is-Docker%2F</url>
    <content type="text"><![CDATA[什么是DockerDocker是一个能够把开发的应用程序自动部署到容器上的开源引擎。与其他容器不同，Docker在虚拟执行环境下增加了一个程序部署引擎，可以快速将开发程序打包部署到容器内，用于测试和生产，实现一处打包到处运行。特点：1） 提供一个简单轻量的建模模式，即操作简单2） 职责的逻辑分离，减少开发与运维人员的交互3） 快速高效的开发周期4） 鼓励使用面向服务的架构，即一个容器运行一个应用，即一个环境提供一个服务 Docker组件1） Docker客户端和服务器Docker提供典型的C/S模式服务，在宿主机（服务器）上运行的Docker守护进程（Docker引擎），接受来自本机或远程的Client（客户端）的请求，完成操作，并且管理宿主机中的Docker容器们。2） Docker镜像Docker镜像相当于Docker容器的源代码，通过镜像可以构建一个配置完毕的运行环境，相当于操作系统的iso，但是Docker中的镜像轻便短小。3） Docker Registry用来保存用户的镜像，可以公开或私有，官方提供的Registry中，有很多已经配置完毕的镜像，包括数据库的容器镜像，Web程序的容器镜像等。4） Docker容器Docker容器就是一个虚拟的运行环境，一个服务器可以有多个容器，一个容器可以运行多个程序，互不干扰，容器相当软件的集装箱，通过容器的运输，可减少出现测试通过，但在实际生产环境Bug的情况。 Docker技术组件1） 一个原生的Linux容器2） Linux的内核命名空间namespace3） 每个容器有自己的root目录4） 每个容器运行在自己的进程环境下5） 每个容器间的IP相互隔离6） cpu与内存资源也相互独立7） 日志，容器的标准输入输出会写入log，用于排错8） 每个容器提供一个伪tty，提供交互shell Docker的管理Docker的管理，不同于操作系统镜像的管理，复杂多变，Docker镜像可以实现自身的迭代，并且镜像短小轻便，销毁重建的投入也不多。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(20)——networking.c篇]]></title>
    <url>%2F2017%2F11%2F13%2Fredis%E6%BA%90%E7%A0%81-20-%E2%80%94%E2%80%94networking-c%E7%AF%87%2F</url>
    <content type="text"><![CDATA[networking文件简介前面讲过的anet文件是对底层的网络操作的函数的包装，networking文件中则是涉及到逻辑层的网络部分，利用之前包装过的函数加上逻辑实现，主要实现的功能有客户端的创建释放，以及接受客户端连接的请求处理函数，还有接受客户端的请求并处理，以及回应客户端的请求。其中客户端连接创建一个可读事件，回应客户端请求创建一个可写事件，接受客户端请求创建可读事件。 客户端的连接处理在server文件的main函数中会创建客户端的连接事件，为server的网络端口文件描述符创建可读事件，用来监听客户端的连接，在networking中有连接事件的处理函数，连接分为tcp连接和本地连接：acceptTcpHandler和acceptUnixHandler。下面就是这两个函数：123456789101112131415161718192021222324252627282930313233343536373839//接收tcp连接的处理函数void acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask) &#123; int cport, cfd, max = MAX_ACCEPTS_PER_CALL; //每次call的最大连接数 char cip[NET_IP_STR_LEN];//连接的ip地址 UNUSED(el); UNUSED(mask); UNUSED(privdata); while(max--) &#123; cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), &amp;cport);//返回用于通信的描述符 if (cfd == ANET_ERR) &#123; if (errno != EWOULDBLOCK) serverLog(LL_WARNING, "Accepting client connection: %s", server.neterr); return; &#125; serverLog(LL_VERBOSE,"Accepted %s:%d", cip, cport); acceptCommonHandler(cfd,0,cip);//连接的通常处理函数 &#125;&#125;//接收本地连接的处理函数void acceptUnixHandler(aeEventLoop *el, int fd, void *privdata, int mask) &#123; int cfd, max = MAX_ACCEPTS_PER_CALL;//每次call的最大连接数 UNUSED(el); UNUSED(mask); UNUSED(privdata); while(max--) &#123; cfd = anetUnixAccept(server.neterr, fd);//本地连接返回进程fd if (cfd == ANET_ERR) &#123; if (errno != EWOULDBLOCK) serverLog(LL_WARNING, "Accepting client connection: %s", server.neterr); return; &#125; serverLog(LL_VERBOSE,"Accepted connection to %s", server.unixsocket); acceptCommonHandler(cfd,CLIENT_UNIX_SOCKET,NULL);//连接的通常处理函数 &#125;&#125; 可以看到一个常规处理函数acceptCommonHandler，用来在server中创建client数据结构，保存ip地址，port端口，数据缓冲区buf等通信信息。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//接收连接处理函数...static void acceptCommonHandler(int fd, int flags, char *ip) &#123; client *c; if ((c = createClient(fd)) == NULL) &#123;//创建client客户端 serverLog(LL_WARNING, "Error registering fd event for the new client: %s (fd=%d)", strerror(errno),fd); close(fd); /* May be already closed, just ignore errors */ return; &#125; /* If maxclient directive is set and this is one client more... close the * connection. Note that we create the client instead to check before * for this condition, since now the socket is already set in non-blocking * mode and we can send an error for free using the Kernel I/O */ if (listLength(server.clients) &gt; server.maxclients) &#123;//检查是否超过最大client连接数 char *err = "-ERR max number of clients reached\r\n"; /* That's a best effort error message, don't check write errors */ if (write(c-&gt;fd,err,strlen(err)) == -1) &#123;//传回错误信息 /* Nothing to do, Just to avoid the warning... */ &#125; server.stat_rejected_conn++;//拒绝连接数加一 freeClient(c);//释放创建的客户端 return; &#125; /* If the server is running in protected mode (the default) and there * is no password set, nor a specific interface is bound, we don't accept * requests from non loopback interfaces. Instead we try to explain the * user what to do to fix it if needed. */ //如果在保护状态加上没有密码认证，那么不接受本地回环接口 if (server.protected_mode &amp;&amp; server.bindaddr_count == 0 &amp;&amp; server.requirepass == NULL &amp;&amp; !(flags &amp; CLIENT_UNIX_SOCKET) &amp;&amp; ip != NULL) &#123; if (strcmp(ip,"127.0.0.1") &amp;&amp; strcmp(ip,"::1")) &#123; char *err = "-DENIED Redis is running in protected mode because protected " "mode is enabled, no bind address was specified, no " "authentication password is requested to clients. In this mode " "connections are only accepted from the loopback interface. " "If you want to connect from external computers to Redis you " "may adopt one of the following solutions: " "1) Just disable protected mode sending the command " "'CONFIG SET protected-mode no' from the loopback interface " "by connecting to Redis from the same host the server is " "running, however MAKE SURE Redis is not publicly accessible " "from internet if you do so. Use CONFIG REWRITE to make this " "change permanent. " "2) Alternatively you can just disable the protected mode by " "editing the Redis configuration file, and setting the protected " "mode option to 'no', and then restarting the server. " "3) If you started the server manually just for testing, restart " "it with the '--protected-mode no' option. " "4) Setup a bind address or an authentication password. " "NOTE: You only need to do one of the above things in order for " "the server to start accepting connections from the outside.\r\n"; if (write(c-&gt;fd,err,strlen(err)) == -1) &#123;//发送错误信息 /* Nothing to do, Just to avoid the warning... */ &#125; server.stat_rejected_conn++; freeClient(c); return; &#125; &#125; server.stat_numconnections++;//增加连接数 c-&gt;flags |= flags;//设置连接的属性&#125; 客户端的创建释放在上面接受客户端的连接请求处理中， 需要创建client保存信息，那么就有创建client以及释放client函数：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//！！！！创建一个客户端client *createClient(int fd) &#123; client *c = zmalloc(sizeof(client)); /* passing -1 as fd it is possible to create a non connected client. * This is useful since all the commands needs to be executed * in the context of a client. When commands are executed in other * contexts (for instance a Lua script) we need a non connected client. */ //所有的指令都需要在一个client上下文下执行，这样我们可以创建一个不需要连接的伪终端来执行指令脚本 if (fd != -1) &#123; anetNonBlock(NULL,fd);//使套接字非阻塞 anetEnableTcpNoDelay(NULL,fd);//设置nodelay防止两种算法互相干扰导致延迟 if (server.tcpkeepalive)//设置keepalive检测对方服务器是否奔溃退出连接 anetKeepAlive(NULL,fd,server.tcpkeepalive); if (aeCreateFileEvent(server.el,fd,AE_READABLE, readQueryFromClient, c) == AE_ERR) //创建一个套接字的读事件，读取来自客户端的指令 &#123; close(fd); zfree(c); return NULL; &#125; &#125; //初始化变量 selectDb(c,0);//选择默认数据库 c-&gt;id = server.next_client_id++;//设置client的id c-&gt;fd = fd;//设置通信文件描述符 c-&gt;name = NULL;//client名字 c-&gt;bufpos = 0;//请求缓冲区偏移 c-&gt;querybuf = sdsempty();//初始化请求缓冲区 c-&gt;querybuf_peak = 0;//请求缓冲区大小峰值 c-&gt;reqtype = 0;//请求类型 c-&gt;argc = 0;//参数个数 c-&gt;argv = NULL; //参数指针 c-&gt;cmd = c-&gt;lastcmd = NULL;//当前以及最后一次的指令名称 c-&gt;multibulklen = 0;//设置未读指令的数目 c-&gt;bulklen = -1;//读入参数的长度 c-&gt;sentlen = 0;//reply信息的总长度 c-&gt;flags = 0;//client状态 c-&gt;ctime = c-&gt;lastinteraction = server.unixtime;//最近一次交互事件 c-&gt;authenticated = 0;//是否认证 c-&gt;replstate = REPL_STATE_NONE;//副本状态 c-&gt;repl_put_online_on_ack = 0;//副本在线回馈信息 c-&gt;reploff = 0;//副本偏移 c-&gt;repl_ack_off = 0;//通过ack命令接收到的偏移量 c-&gt;repl_ack_time = 0;//通过ack命令接收到的偏移量所用的时间 c-&gt;slave_listening_port = 0;//从节点的端口号 c-&gt;slave_ip[0] = '\0';//从节点ip c-&gt;slave_capa = SLAVE_CAPA_NONE;//从节点的功能 c-&gt;reply = listCreate();//创建回复链表 c-&gt;reply_bytes = 0;//回复链表的字节数 c-&gt;obuf_soft_limit_reached_time = 0;//回复缓冲区的内存大小软限制 listSetFreeMethod(c-&gt;reply,freeClientReplyValue);//设置释放函数 listSetDupMethod(c-&gt;reply,dupClientReplyValue);//设置复制函数 c-&gt;btype = BLOCKED_NONE;//阻塞类型 c-&gt;bpop.timeout = 0;//阻塞时限 c-&gt;bpop.keys = dictCreate(&amp;objectKeyPointerValueDictType,NULL);//初始化造成阻塞的字典 c-&gt;bpop.target = NULL;//阻塞中，用于push目标key c-&gt;bpop.numreplicas = 0;//阻塞状态 c-&gt;bpop.reploffset = 0;//要达到的复制偏移量 c-&gt;woff = 0;//全局偏移 c-&gt;watched_keys = listCreate();//监视的key链表 c-&gt;pubsub_channels = dictCreate(&amp;objectKeyPointerValueDictType,NULL);//订阅的频道 c-&gt;pubsub_patterns = listCreate();//订阅的模式 c-&gt;peerid = NULL;//记录对方的ip：port listSetFreeMethod(c-&gt;pubsub_patterns,decrRefCountVoid);//设置模式链表释放方法 listSetMatchMethod(c-&gt;pubsub_patterns,listMatchObjects);//设置模式链表匹配方法 if (fd != -1) listAddNodeTail(server.clients,c);//如果不是伪client，将正真的客户端放入服务器客户端列表中 initClientMultiState(c);//初始化事务状态 return c;&#125; 下面是释放客户端，释放客户端分为解除客户端所有的引用以及释放所有客户端的空间，释放分为立即释放和异步释放，立即释放即调用函数就释放空间，而异步释放将client放入即将释放链表中，在serverCon循环中会调用函数将空间释放。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156//移除服务器上关于特定的客户端的所有可见的引用不包括Pub/Sub channelsvoid unlinkClient(client *c) &#123; listNode *ln; /* If this is marked as current client unset it. */ if (server.current_client == c) server.current_client = NULL;//如果是当前client，移除当前client /* Certain operations must be done only if the client has an active socket. * If the client was already unlinked or if it's a "fake client" the * fd is already set to -1. */ if (c-&gt;fd != -1) &#123; /* Remove from the list of active clients. */ //删除服务器中客户端链表中的client ln = listSearchKey(server.clients,c); serverAssert(ln != NULL); listDelNode(server.clients,ln); /* Unregister async I/O handlers and close the socket. */ //移除关于client的事件 aeDeleteFileEvent(server.el,c-&gt;fd,AE_READABLE); aeDeleteFileEvent(server.el,c-&gt;fd,AE_WRITABLE); close(c-&gt;fd); c-&gt;fd = -1; &#125; /* Remove from the list of pending writes if needed. */ if (c-&gt;flags &amp; CLIENT_PENDING_WRITE) &#123; //如果需要从待写的队列中删除client ln = listSearchKey(server.clients_pending_write,c); serverAssert(ln != NULL); listDelNode(server.clients_pending_write,ln); c-&gt;flags &amp;= ~CLIENT_PENDING_WRITE; &#125; /* When client was just unblocked because of a blocking operation, * remove it from the list of unblocked clients. */ if (c-&gt;flags &amp; CLIENT_UNBLOCKED) &#123;//从阻塞列表中删除client ln = listSearchKey(server.unblocked_clients,c); serverAssert(ln != NULL); listDelNode(server.unblocked_clients,ln); c-&gt;flags &amp;= ~CLIENT_UNBLOCKED; &#125;&#125;//立即释放客户端空间void freeClient(client *c) &#123; listNode *ln; //如果是连接的master服务器那么需要检查客户端的状态 if (server.master &amp;&amp; c-&gt;flags &amp; CLIENT_MASTER) &#123; serverLog(LL_WARNING,"Connection with master lost."); if (!(c-&gt;flags &amp; (CLIENT_CLOSE_AFTER_REPLY| CLIENT_CLOSE_ASAP| CLIENT_BLOCKED| CLIENT_UNBLOCKED))) &#123;//暂时不释放空间 replicationCacheMaster(c);//处理master主机断开连接 return; &#125; &#125; /* Log link disconnection with slave */ //日志打印slave服务器的断开 if ((c-&gt;flags &amp; CLIENT_SLAVE) &amp;&amp; !(c-&gt;flags &amp; CLIENT_MONITOR)) &#123; serverLog(LL_WARNING,"Connection with slave %s lost.", replicationGetSlaveName(c)); &#125; /* Free the query buffer */ sdsfree(c-&gt;querybuf);//释放查询语句缓冲区 c-&gt;querybuf = NULL; /* Deallocate structures used to block on blocking ops. */ if (c-&gt;flags &amp; CLIENT_BLOCKED) unblockClient(c);//解开阻塞 dictRelease(c-&gt;bpop.keys);//释放关于阻塞的字典空间 /* UNWATCH all the keys */ unwatchAllKeys(c);//unwatch所有的key listRelease(c-&gt;watched_keys); /* Unsubscribe from all the pubsub channels */ //退订所有的频道以及模式 pubsubUnsubscribeAllChannels(c,0); pubsubUnsubscribeAllPatterns(c,0); dictRelease(c-&gt;pubsub_channels); listRelease(c-&gt;pubsub_patterns); /* Free data structures. */ //释放reply数据结构 listRelease(c-&gt;reply); freeClientArgv(c); /* Unlink the client: this will close the socket, remove the I/O * handlers, and remove references of the client from different * places where active clients may be referenced. */ //移除所有的引用 unlinkClient(c); /* Master/slave cleanup Case 1: * we lost the connection with a slave. */ //解决一个从服务器的客户端断开连接 if (c-&gt;flags &amp; CLIENT_SLAVE) &#123; if (c-&gt;replstate == SLAVE_STATE_SEND_BULK) &#123; if (c-&gt;repldbfd != -1) close(c-&gt;repldbfd); if (c-&gt;replpreamble) sdsfree(c-&gt;replpreamble); &#125; list *l = (c-&gt;flags &amp; CLIENT_MONITOR) ? server.monitors : server.slaves; ln = listSearchKey(l,c); serverAssert(ln != NULL); listDelNode(l,ln); /* We need to remember the time when we started to have zero * attached slaves, as after some time we'll free the replication * backlog. */ if (c-&gt;flags &amp; CLIENT_SLAVE &amp;&amp; listLength(server.slaves) == 0) server.repl_no_slaves_since = server.unixtime; refreshGoodSlavesCount();//跟新存活的slave数目 &#125; /* Master/slave cleanup Case 2: * we lost the connection with the master. */ //如果是一个主服务器的客户端断开连接 if (c-&gt;flags &amp; CLIENT_MASTER) replicationHandleMasterDisconnection(); /* If this client was scheduled for async freeing we need to remove it * from the queue. */ //加入到异步释放队列了 if (c-&gt;flags &amp; CLIENT_CLOSE_ASAP) &#123; ln = listSearchKey(server.clients_to_close,c); serverAssert(ln != NULL); listDelNode(server.clients_to_close,ln); &#125; /* Release other dynamically allocated client structure fields, * and finally release the client structure itself. */ //释放一些其他的数据结构空间 if (c-&gt;name) decrRefCount(c-&gt;name); zfree(c-&gt;argv); freeClientMultiState(c); sdsfree(c-&gt;peerid); zfree(c);&#125;//异步释放客户端，异步释放防止正在往客户端写数据这样释放客户端不安全，每一次服务器loop都会处理这些clientsvoid freeClientAsync(client *c) &#123; if (c-&gt;flags &amp; CLIENT_CLOSE_ASAP || c-&gt;flags &amp; CLIENT_LUA) return;//已经即将释放状态或者是伪客户端不存在不安全问题 c-&gt;flags |= CLIENT_CLOSE_ASAP; listAddNodeTail(server.clients_to_close,c);&#125;//强制从即将释放客户端列表中即可释放所有客户端void freeClientsInAsyncFreeQueue(void) &#123; while (listLength(server.clients_to_close)) &#123;//遍历即将释放客户端列表 listNode *ln = listFirst(server.clients_to_close); client *c = listNodeValue(ln); c-&gt;flags &amp;= ~CLIENT_CLOSE_ASAP; freeClient(c);//即可释放客户端 listDelNode(server.clients_to_close,ln);//从列表中删除 &#125;&#125; 接受客户端请求追寻客户端的请求，可以看到在创建client时，有添加一个客户端fd的可读事件，在client发送指令后，server通过可读事件读取指令到缓冲区，下面我们看这个可读事件的处理函数readQueryFromClient：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//从客户端读取查询语句 存放在缓冲区中待处理void readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask) &#123; client *c = (client*) privdata; int nread, readlen; size_t qblen; UNUSED(el); UNUSED(mask); readlen = PROTO_IOBUF_LEN; //16k的io缓冲区大小 /* If this is a multi bulk request, and we are processing a bulk reply * that is large enough, try to maximize the probability that the query * buffer contains exactly the SDS string representing the object, even * at the risk of requiring more read(2) calls. This way the function * processMultiBulkBuffer() can avoid copying buffers to create the * Redis Object representing the argument. */ //如果是多条指令的根据请求的要求确定读取的长度 if (c-&gt;reqtype == PROTO_REQ_MULTIBULK &amp;&amp; c-&gt;multibulklen &amp;&amp; c-&gt;bulklen != -1 &amp;&amp; c-&gt;bulklen &gt;= PROTO_MBULK_BIG_ARG) &#123; int remaining = (unsigned)(c-&gt;bulklen+2)-sdslen(c-&gt;querybuf); if (remaining &lt; readlen) readlen = remaining; &#125; qblen = sdslen(c-&gt;querybuf); if (c-&gt;querybuf_peak &lt; qblen) c-&gt;querybuf_peak = qblen;//更新peak长度 c-&gt;querybuf = sdsMakeRoomFor(c-&gt;querybuf, readlen);//为querybuf开辟空间 nread = read(fd, c-&gt;querybuf+qblen, readlen);//读取数据到querybuf if (nread == -1) &#123;//出错处理 if (errno == EAGAIN) &#123; return; &#125; else &#123; serverLog(LL_VERBOSE, "Reading from client: %s",strerror(errno)); freeClient(c); return; &#125; &#125; else if (nread == 0) &#123; serverLog(LL_VERBOSE, "Client closed connection"); freeClient(c); return; &#125; sdsIncrLen(c-&gt;querybuf,nread);//增加querybuf长度 c-&gt;lastinteraction = server.unixtime;//跟新交互时间 //下面是replication部分 if (c-&gt;flags &amp; CLIENT_MASTER) &#123; c-&gt;reploff += nread; //传递来自master的信息到subslave replicationFeedSlavesFromMasterStream(server.slaves, c-&gt;querybuf+qblen,nread); &#125; server.stat_net_input_bytes += nread; if (sdslen(c-&gt;querybuf) &gt; server.client_max_querybuf_len) &#123;//超出最大长度 sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); bytes = sdscatrepr(bytes,c-&gt;querybuf,64); //将客户信息以及查询语句保存打印 serverLog(LL_WARNING,"Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)", ci, bytes); sdsfree(ci); sdsfree(bytes); freeClient(c); return; &#125; //处理输入缓冲区的语句 processInputBuffer(c);&#125; 在processInputBuffer函数中，对缓冲区中的指令进行解析，redis中有两种请求，一种是通过telent一种的redis-cli，所以有两种指令协议，当然也有两种协议解析，函数分别是processMultibulkBuffer和processInlineBuffer，两个函数都是将指令解析后存入到argc和args中，等待执行，下面看processInputBuffer函数。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//处理querybuffer中的指令 分两种协议void processInputBuffer(client *c) &#123; server.current_client = c; /* Keep processing while there is something in the input buffer */ while(sdslen(c-&gt;querybuf)) &#123; /* Return if clients are paused. */ //cilent停止 if (!(c-&gt;flags &amp; CLIENT_SLAVE) &amp;&amp; clientsArePaused()) break; /* Immediately abort if the client is in the middle of something. */ //client阻塞状态 if (c-&gt;flags &amp; CLIENT_BLOCKED) break; /* CLIENT_CLOSE_AFTER_REPLY closes the connection once the reply is * written to the client. Make sure to not let the reply grow after * this flag has been set (i.e. don't process more commands). * * The same applies for clients we want to terminate ASAP. */ //即将关闭 if (c-&gt;flags &amp; (CLIENT_CLOSE_AFTER_REPLY|CLIENT_CLOSE_ASAP)) break; /* Determine request type when unknown. */ //决定是哪一种协议请求 if (!c-&gt;reqtype) &#123; if (c-&gt;querybuf[0] == '*') &#123; c-&gt;reqtype = PROTO_REQ_MULTIBULK; &#125; else &#123; c-&gt;reqtype = PROTO_REQ_INLINE; &#125; &#125; //处理argc以及argv if (c-&gt;reqtype == PROTO_REQ_INLINE) &#123; //内连协议请求 处理来自telnet的请求 if (processInlineBuffer(c) != C_OK) break; &#125; else if (c-&gt;reqtype == PROTO_REQ_MULTIBULK) &#123; //处理多条请求 if (processMultibulkBuffer(c) != C_OK) break; &#125; else &#123; serverPanic("Unknown request type"); &#125; /* Multibulk processing could see a &lt;= 0 length. */ if (c-&gt;argc == 0) &#123; resetClient(c);//重置client进行下一个指令 &#125; else &#123; /* Only reset the client when the command was executed. */ if (processCommand(c) == C_OK)//处理指令 resetClient(c);//完成后重置client /* freeMemoryIfNeeded may flush slave output buffers. This may result * into a slave, that may be the active client, to be freed. */ if (server.current_client == NULL) break; &#125; &#125; server.current_client = NULL;&#125; 可见在解析完指令后执行了processCommand来执行指令。 回应客户端在每次serverCon的循环中就会调用handleClientsWithPendingWrites函数，查看是否有需要回复的client，如果存在那么增加client的fd的可写事件，在事件处理时就会触发事件，写入缓冲区或者list中的reply。123456789101112131415161718192021222324252627int handleClientsWithPendingWrites(void) &#123; listIter li; listNode *ln; int processed = listLength(server.clients_pending_write); listRewind(server.clients_pending_write,&amp;li); //循环等待回应的client列表 while((ln = listNext(&amp;li))) &#123; client *c = listNodeValue(ln); c-&gt;flags &amp;= ~CLIENT_PENDING_WRITE; listDelNode(server.clients_pending_write,ln); /* Try to write buffers to the client socket. */ if (writeToClient(c-&gt;fd,c,0) == C_ERR) continue;//回复client /* If there is nothing left, do nothing. Otherwise install * the write handler. */ //如果没有回复了不做事，否则增加可写事件 if (clientHasPendingReplies(c) &amp;&amp; aeCreateFileEvent(server.el, c-&gt;fd, AE_WRITABLE, sendReplyToClient, c) == AE_ERR) &#123; freeClientAsync(c); &#125; &#125; return processed;&#125; 可见writeToClient函数就是往clients发送reply，在sendReplyToClient中，是为了在处理writeToClient时又有新的数据加入缓冲区中没有及时入里所以添加可写事件。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091//写事件的处理器 当有回复的数据时创建这个事件，然后当套接字可写时调用该函数 进行数据写到相关的clientvoid sendReplyToClient(aeEventLoop *el, int fd, void *privdata, int mask) &#123; UNUSED(el); UNUSED(mask); writeToClient(fd,privdata,1);//往套接字中写信息&#125;//将output中的数据写给客户端，返回ok表示client任然有效 返回错误表示client已经释放了int writeToClient(int fd, client *c, int handler_installed) &#123; ssize_t nwritten = 0, totwritten = 0; size_t objlen; sds o; while(clientHasPendingReplies(c)) &#123;//直到没有待发送的reply信息 if (c-&gt;bufpos &gt; 0) &#123; nwritten = write(fd,c-&gt;buf+c-&gt;sentlen,c-&gt;bufpos-c-&gt;sentlen);//发送信息 if (nwritten &lt;= 0) break;//发送失败 c-&gt;sentlen += nwritten; totwritten += nwritten; /* If the buffer was sent, set bufpos to zero to continue with * the remainder of the reply. */ //发送完毕了 if ((int)c-&gt;sentlen == c-&gt;bufpos) &#123; c-&gt;bufpos = 0; c-&gt;sentlen = 0; &#125; &#125; else &#123; o = listNodeValue(listFirst(c-&gt;reply)); objlen = sdslen(o); if (objlen == 0) &#123;//如果长度为0直接删除 listDelNode(c-&gt;reply,listFirst(c-&gt;reply)); continue; &#125; nwritten = write(fd, o + c-&gt;sentlen, objlen - c-&gt;sentlen);//发送reply信息 if (nwritten &lt;= 0) break; c-&gt;sentlen += nwritten; totwritten += nwritten; /* If we fully sent the object on head go to the next one */ if (c-&gt;sentlen == objlen) &#123;//表示一个节点的reply发送完毕 listDelNode(c-&gt;reply,listFirst(c-&gt;reply)); c-&gt;sentlen = 0; c-&gt;reply_bytes -= objlen; &#125; &#125; /* Note that we avoid to send more than NET_MAX_WRITES_PER_EVENT * bytes, in a single threaded server it's a good idea to serve * other clients as well, even if a very large request comes from * super fast link that is always able to accept data (in real world * scenario think about 'KEYS *' against the loopback interface). * * However if we are over the maxmemory limit we ignore that and * just deliver as much data as it is possible to deliver. */ server.stat_net_output_bytes += totwritten; if (totwritten &gt; NET_MAX_WRITES_PER_EVENT &amp;&amp;//发送信息的总体大小限制 (server.maxmemory == 0 || zmalloc_used_memory() &lt; server.maxmemory)) break; &#125; if (nwritten == -1) &#123; if (errno == EAGAIN) &#123; nwritten = 0; &#125; else &#123; serverLog(LL_VERBOSE, "Error writing to client: %s", strerror(errno)); freeClient(c); return C_ERR; &#125; &#125; if (totwritten &gt; 0) &#123; /* For clients representing masters we don't count sending data * as an interaction, since we always send REPLCONF ACK commands * that take some time to just fill the socket output buffer. * We just rely on data / pings received for timeout detection. */ //更新交互时间 注意来自master的传递不算是交互 if (!(c-&gt;flags &amp; CLIENT_MASTER)) c-&gt;lastinteraction = server.unixtime; &#125; if (!clientHasPendingReplies(c)) &#123; c-&gt;sentlen = 0; //是否删除这个可写事件 if (handler_installed) aeDeleteFileEvent(server.el,c-&gt;fd,AE_WRITABLE); /* Close connection after entire reply has been sent. */ if (c-&gt;flags &amp; CLIENT_CLOSE_AFTER_REPLY) &#123; freeClient(c); return C_ERR; &#125; &#125; return C_OK;&#125; 在每次指令执行完毕都会有相应的addReply函数来将指令添加到client的回复缓冲区中，在调用底层的reply函数时需要调用prepareClientToWrite函数来做一些状态检查以及将client添加到待写入信息的list中。12345678910111213141516171819202122232425262728293031323334353637383940414243//准备好向客户端的套接字写入数据//每一次客户端的回复创建完毕后都要调用，在往客户端输出端添加数据之前，如果函数返回错误那么不应该append数据了int prepareClientToWrite(client *c) &#123; /* If it's the Lua client we always return ok without installing any * handler since there is no socket at all. */ //如果是脚本客户端没有套接字直接返回ok if (c-&gt;flags &amp; (CLIENT_LUA|CLIENT_MODULE)) return C_OK; /* CLIENT REPLY OFF / SKIP handling: don't send replies. */ //如果客户端关闭回复或者忽略回复直接返回错误 if (c-&gt;flags &amp; (CLIENT_REPLY_OFF|CLIENT_REPLY_SKIP)) return C_ERR; /* Masters don't receive replies, unless CLIENT_MASTER_FORCE_REPLY flag * is set. */ //master客户端并且不强制接收回复那么返回错误 if ((c-&gt;flags &amp; CLIENT_MASTER) &amp;&amp; !(c-&gt;flags &amp; CLIENT_MASTER_FORCE_REPLY)) return C_ERR; //aof虚拟客户端 不接受回复 if (c-&gt;fd &lt;= 0) return C_ERR; /* Fake client for AOF loading. */ /* Schedule the client to write the output buffers to the socket only * if not already done (there were no pending writes already and the client * was yet not flagged), and, for slaves, if the slave can actually * receive writes at this stage. */ //如果客户端没有待传输的回复并且没有 if (!clientHasPendingReplies(c) &amp;&amp; !(c-&gt;flags &amp; CLIENT_PENDING_WRITE) &amp;&amp; (c-&gt;replstate == REPL_STATE_NONE || (c-&gt;replstate == SLAVE_STATE_ONLINE &amp;&amp; !c-&gt;repl_put_online_on_ack))) &#123; /* Here instead of installing the write handler, we just flag the * client and put it into a list of clients that have something * to write to the socket. This way before re-entering the event * loop, we can try to directly write to the client sockets avoiding * a system call. We'll only really install the write handler if * we'll not be able to write the whole reply at once. */ c-&gt;flags |= CLIENT_PENDING_WRITE; listAddNodeHead(server.clients_pending_write,c); &#125; /* Authorize the caller to queue in the output buffer of this client. */ return C_OK;&#125; 在回复缓冲的信息大小达到限制后就会忘reply_list中写入信息，在往list中写入信息的函数最后都要执行asyncCloseClientOnOutputBufferLimitReached函数来检查总体回复的大小是否达到限制。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//异步的关闭client当输出缓冲区限制达到时void asyncCloseClientOnOutputBufferLimitReached(client *c) &#123; serverAssert(c-&gt;reply_bytes &lt; SIZE_MAX-(1024*64)); if (c-&gt;reply_bytes == 0 || c-&gt;flags &amp; CLIENT_CLOSE_ASAP) return;//如果reply的list中信息大小为0或者即将异步关闭直接返回 if (checkClientOutputBufferLimits(c)) &#123;//如果缓冲区达到限制大小 sds client = catClientInfoString(sdsempty(),c); freeClientAsync(c);//异步释放client serverLog(LL_WARNING,"Client %s scheduled to be closed ASAP for overcoming of output buffer limits.", client); sdsfree(client); &#125;&#125;//如果client达到一个软或硬的限制返回非0，否则返回0，同时会跟新检测soft限制的状态int checkClientOutputBufferLimits(client *c) &#123; int soft = 0, hard = 0, class; unsigned long used_mem = getClientOutputBufferMemoryUsage(c); class = getClientType(c); /* For the purpose of output buffer limiting, masters are handled * like normal clients. */ //如果client是master那么当作normal来处理 if (class == CLIENT_TYPE_MASTER) class = CLIENT_TYPE_NORMAL; //判断soft以及hard的限制是否达到 if (server.client_obuf_limits[class].hard_limit_bytes &amp;&amp; used_mem &gt;= server.client_obuf_limits[class].hard_limit_bytes) hard = 1; if (server.client_obuf_limits[class].soft_limit_bytes &amp;&amp; used_mem &gt;= server.client_obuf_limits[class].soft_limit_bytes) soft = 1; /* We need to check if the soft limit is reached continuously for the * specified amount of seconds. */ //如果soft达标，检查是否是第一次或者不是第一次但是距离上次限制在限制时间内，那么不记录这次达标 if (soft) &#123; if (c-&gt;obuf_soft_limit_reached_time == 0) &#123; c-&gt;obuf_soft_limit_reached_time = server.unixtime; soft = 0; /* First time we see the soft limit reached */ &#125; else &#123; time_t elapsed = server.unixtime - c-&gt;obuf_soft_limit_reached_time; if (elapsed &lt;= server.client_obuf_limits[class].soft_limit_seconds) &#123; soft = 0; /* The client still did not reached the max number of seconds for the soft limit to be considered reached. */ &#125; &#125; &#125; else &#123; c-&gt;obuf_soft_limit_reached_time = 0; &#125; return soft || hard;&#125; 可见client缓冲区溢出的软机制，即当超出限制但是距离上次溢出时间较短，那么会给它一定时间来处理reply，而不是直接释放client。 关于客户端命令client指令：CLIENT KILL [ip:port] [ID client-id] [TYPE normal|master|slave|pubsub] [ADDR ip:port] [SKIPME yes/no]CLIENT GETNAMECLIENT LISTCLIENT PAUSE timeoutCLIENT REPLY ON|OFF|SKIPCLIENT SETNAME connection-name下面参照源码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196// client 命令的实现void clientCommand(client *c) &#123; listNode *ln; listIter li; client *client; // CLIENT LIST 的实现 if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"list") &amp;&amp; c-&gt;argc == 2) &#123; /* CLIENT LIST */ // 获取所有的client信息 sds o = getAllClientsInfoString(); // 添加到到输入缓冲区中 addReplyBulkCBuffer(c,o,sdslen(o)); sdsfree(o); // CLIENT REPLY ON|OFF|SKIP 命令实现 &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"reply") &amp;&amp; c-&gt;argc == 3) &#123; /* CLIENT REPLY ON|OFF|SKIP */ // 如果是 ON if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,"on")) &#123; // 取消 off 和 skip 的标志 c-&gt;flags &amp;= ~(CLIENT_REPLY_SKIP|CLIENT_REPLY_OFF); // 回复 +OK addReply(c,shared.ok); // 如果是 OFF &#125; else if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,"off")) &#123; // 打开 OFF标志 c-&gt;flags |= CLIENT_REPLY_OFF; // 如果是 SKIP &#125; else if (!strcasecmp(c-&gt;argv[2]-&gt;ptr,"skip")) &#123; // 没有设置 OFF 则设置 SKIP 标志 if (!(c-&gt;flags &amp; CLIENT_REPLY_OFF)) c-&gt;flags |= CLIENT_REPLY_SKIP_NEXT; &#125; else &#123; addReply(c,shared.syntaxerr); return; &#125; // CLIENT KILL [ip:port] [ID client-id] [TYPE normal | master | slave | pubsub] [ADDR ip:port] [SKIPME yes / no] &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"kill")) &#123; /* CLIENT KILL &lt;ip:port&gt; * CLIENT KILL &lt;option&gt; [value] ... &lt;option&gt; [value] */ char *addr = NULL; int type = -1; uint64_t id = 0; int skipme = 1; int killed = 0, close_this_client = 0; // CLIENT KILL addr:port只能通过地址杀死client，旧版本兼容 if (c-&gt;argc == 3) &#123; /* Old style syntax: CLIENT KILL &lt;addr&gt; */ addr = c-&gt;argv[2]-&gt;ptr; skipme = 0; /* With the old form, you can kill yourself. */ // 新版本可以根据[ID client-id] [master|normal|slave|pubsub] [ADDR ip:port] [SKIPME yes/no]杀死client &#125; else if (c-&gt;argc &gt; 3) &#123; int i = 2; /* Next option index. */ /* New style syntax: parse options. */ // 解析语法 while(i &lt; c-&gt;argc) &#123; int moreargs = c-&gt;argc &gt; i+1; // CLIENT KILL [ID client-id] if (!strcasecmp(c-&gt;argv[i]-&gt;ptr,"id") &amp;&amp; moreargs) &#123; long long tmp; // 获取client的ID if (getLongLongFromObjectOrReply(c,c-&gt;argv[i+1],&amp;tmp,NULL) != C_OK) return; id = tmp; // CLIENT KILL TYPE type, 这里的 type 可以是 [master|normal|slave|pubsub] &#125; else if (!strcasecmp(c-&gt;argv[i]-&gt;ptr,"type") &amp;&amp; moreargs) &#123; // 获取client的类型，[master|normal|slave|pubsub]四种之一 type = getClientTypeByName(c-&gt;argv[i+1]-&gt;ptr); if (type == -1) &#123; addReplyErrorFormat(c,"Unknown client type '%s'", (char*) c-&gt;argv[i+1]-&gt;ptr); return; &#125; // CLIENT KILL [ADDR ip:port] &#125; else if (!strcasecmp(c-&gt;argv[i]-&gt;ptr,"addr") &amp;&amp; moreargs) &#123; // 获取ip:port addr = c-&gt;argv[i+1]-&gt;ptr; // CLIENT KILL [SKIPME yes/no] &#125; else if (!strcasecmp(c-&gt;argv[i]-&gt;ptr,"skipme") &amp;&amp; moreargs) &#123; // 如果是yes，设置设置skipme，调用该命令的客户端将不会被杀死 if (!strcasecmp(c-&gt;argv[i+1]-&gt;ptr,"yes")) &#123; skipme = 1; // 设置为no会影响到还会杀死调用该命令的客户端。 &#125; else if (!strcasecmp(c-&gt;argv[i+1]-&gt;ptr,"no")) &#123; skipme = 0; &#125; else &#123; addReply(c,shared.syntaxerr); return; &#125; &#125; else &#123; addReply(c,shared.syntaxerr); return; &#125; i += 2; &#125; &#125; else &#123; addReply(c,shared.syntaxerr); return; &#125; /* Iterate clients killing all the matching clients. */ listRewind(server.clients,&amp;li); // 迭代所有的client节点 while ((ln = listNext(&amp;li)) != NULL) &#123; client = listNodeValue(ln); // 比较当前client和这四类信息，如果有一个不符合就跳过本层循环，否则就比较下一个信息 if (addr &amp;&amp; strcmp(getClientPeerId(client),addr) != 0) continue; if (type != -1 &amp;&amp; getClientType(client) != type) continue; if (id != 0 &amp;&amp; client-&gt;id != id) continue; if (c == client &amp;&amp; skipme) continue; /* Kill it. */ // 杀死当前的client if (c == client) &#123; close_this_client = 1; &#125; else &#123; freeClient(client); &#125; // 计算杀死client的个数 killed++; &#125; /* Reply according to old/new format. */ // 回复client信息 if (c-&gt;argc == 3) &#123; // 没找到符合信息的 if (killed == 0) addReplyError(c,"No such client"); else addReply(c,shared.ok); &#125; else &#123; // 发送杀死的个数 addReplyLongLong(c,killed); &#125; /* If this client has to be closed, flag it as CLOSE_AFTER_REPLY * only after we queued the reply to its output buffers. */ if (close_this_client) c-&gt;flags |= CLIENT_CLOSE_AFTER_REPLY; // CLIENT SETNAME connection-name &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"setname") &amp;&amp; c-&gt;argc == 3) &#123; int j, len = sdslen(c-&gt;argv[2]-&gt;ptr); char *p = c-&gt;argv[2]-&gt;ptr; /* Setting the client name to an empty string actually removes * the current name. */ // 设置名字为空 if (len == 0) &#123; // 先释放掉原来的名字 if (c-&gt;name) decrRefCount(c-&gt;name); c-&gt;name = NULL; addReply(c,shared.ok); return; &#125; /* Otherwise check if the charset is ok. We need to do this otherwise * CLIENT LIST format will break. You should always be able to * split by space to get the different fields. */ // 检查名字格式是否正确 for (j = 0; j &lt; len; j++) &#123; if (p[j] &lt; '!' || p[j] &gt; '~') &#123; /* ASCII is assumed. */ addReplyError(c, "Client names cannot contain spaces, " "newlines or special characters."); return; &#125; &#125; // 释放原来的名字 if (c-&gt;name) decrRefCount(c-&gt;name); // 设置新名字 c-&gt;name = c-&gt;argv[2]; incrRefCount(c-&gt;name); addReply(c,shared.ok); // CLIENT GETNAME &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"getname") &amp;&amp; c-&gt;argc == 2) &#123; // 回复名字 if (c-&gt;name) addReplyBulk(c,c-&gt;name); else addReply(c,shared.nullbulk); // CLIENT PAUSE timeout &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"pause") &amp;&amp; c-&gt;argc == 3) &#123; long long duration; // 以毫秒为单位将等待时间保存在duration中 if (getTimeoutFromObjectOrReply(c,c-&gt;argv[2],&amp;duration,UNIT_MILLISECONDS) != C_OK) return; // 暂停client pauseClients(duration); addReply(c,shared.ok); &#125; else &#123; addReplyError(c, "Syntax error, try CLIENT (LIST | KILL | GETNAME | SETNAME | PAUSE | REPLY)"); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(19)——ae篇]]></title>
    <url>%2F2017%2F10%2F31%2Fredis%E6%BA%90%E7%A0%81-19-%E2%80%94%E2%80%94ae%E7%AF%87%2F</url>
    <content type="text"><![CDATA[事件简介在unixc中，有熟悉的信号机制，当进程接受到来自硬件或者软件发出的信号，就会中断当前程序，进行中断处理程序，然后在回到原来程序执行的位置，可以用信号机制来做事件机制的解决方案，但是触发信号是unix实现定义的，只有几个用于用户自定义信号，以及处理事件。redis是事件驱动的，分为时间事件以及文件事件，时间事件就是一段时间后或者每隔一段时间后执行特定的时间处理程序，文件事件分为读文件以及写文件事件，即文件的描述符可写或者可读时，触发相应的事件处理程序，redis中存在众多的事件，所以不会用自定义信号机制来实现，redis中采用多路复用技术，来实现文件事件，时间事件采用系统计时实现，所谓的多路复用即用一个多路选择器来管理多个文件描述符，每次选择都会从中自动选出准备好的描述符集合返回。文件描述符在添加到选择器时，可以定义输入输出即可读可写以及其他属性，根据系统以及实现的不同多路复用的实现有epoll，select，evport，kqueue，redis中有以上四种实现，其中epoll最优，redis会根据运行的系统选择合适的实现，也可以在redis的conf文件中设置实现手段。1234567891011121314// IO复用的选择，性能依次下降，Linux支持 "ae_epoll.c" 和 "ae_select.c"#ifdef HAVE_EVPORT#include "ae_evport.c"#else #ifdef HAVE_EPOLL #include "ae_epoll.c" #else #ifdef HAVE_KQUEUE #include "ae_kqueue.c" #else #include "ae_select.c" #endif #endif#endif 事件数据结构redis中事件分为时间事件以及文件事件，当然为了管理这些事件，redis还有一个统一的事件状态数据结构，下面是数据结构：12345678910111213141516171819202122232425262728293031323334353637383940414243/* File event structure *///文件事件数据结构typedef struct aeFileEvent &#123; //文件事件标记 写事件还是读事件 int mask; /* one of AE_(READABLE|WRITABLE) */ aeFileProc *rfileProc;//读文件的处理函数 aeFileProc *wfileProc;//写文件的处理函数 void *clientData; //保存客户的私有文件&#125; aeFileEvent;/* Time event structure *///时间事件数据结构，可见时间事件通过尾指针链接typedef struct aeTimeEvent &#123; long long id; /* time event identifier. 时间事件标记id*/ long when_sec; /* seconds 绝对时间单位秒*/ long when_ms; /* milliseconds 绝对时间单位毫秒*/ aeTimeProc *timeProc;//时间事件处理函数 aeEventFinalizerProc *finalizerProc;//该时间事件删除的处理函数 void *clientData;//保存客户的私有文件 struct aeTimeEvent *next; //下一个时间事件&#125; aeTimeEvent;/* A fired event *///准备好的事件结构体typedef struct aeFiredEvent &#123; int fd; int mask;&#125; aeFiredEvent;/* State of an event based program *///记录以及管理redis中的所有的事件以及事件状态结构体typedef struct aeEventLoop &#123; int maxfd; /* highest file descriptor currently registered 当前记录的最大的文件描述符*/ int setsize; /* max number of file descriptors tracked 跟踪的文件描述符最大数目*/ long long timeEventNextId;//下一个时间事件id time_t lastTime; /* Used to detect system clock skew 用来检测系统时钟错误*/ aeFileEvent *events; /* Registered events 注册的文件事件*/ aeFiredEvent *fired; /* Fired events 准备好的事件*/ aeTimeEvent *timeEventHead;//注册的时间事件头指针 int stop;//是否停止 void *apidata; /* This is used for polling API specific data 用来存储io多路复用的特殊数据*/ aeBeforeSleepProc *beforesleep;//在事件循环sleep之前执行函数&#125; aeEventLoop; 在文件事件中有mask代表事件是可读还是可写或者都有，以及可写以及可读处理函数，时间事件中有计时处理函数以及当改时间事件删除时处理函数。aeFiredEvent用来记录准备好的文件事件，aeEventLoop中当然记录redis中所有的事件状态，包括文件事件数组，触发文件事件数组，时间事件头指针，apidata是用来存储多路复用的选择器以及文件描述符事件的特殊数据结构的指针，aeBeforeSleepProc是每次检查事件循环sleep之前的处理函数。下面是各处理函数的原型：123456789//函数原型定义//文件时间处理函数typedef void aeFileProc(struct aeEventLoop *eventLoop, int fd, void *clientData, int mask);//时间时间处理函数typedef int aeTimeProc(struct aeEventLoop *eventLoop, long long id, void *clientData);//时间时间删除时的处理函数typedef void aeEventFinalizerProc(struct aeEventLoop *eventLoop, void *clientData);//每一次事件处理循环开始之前执行该函数typedef void aeBeforeSleepProc(struct aeEventLoop *eventLoop); 在epoll实现中apidata存储的数据结构为：1234typedef struct aeApiState &#123; int epfd;//epoll多路复用选择器分配的描述符 struct epoll_event *events;//所有选择器中等待的文件描述符事件&#125; aeApiState; 其实通过epoll的实现文件可以发现，其中都有对关于事件的包装，比如事件的添加删除等待等等，在redis的ae.c中也有这些函数，那么redis其实就是针对两种类型事件，以及考虑多路复用的不同实现，对事件处理进行了自己的封装。下面是ae的函数定义：123456789101112131415161718aeEventLoop *aeCreateEventLoop(int setsize);//创建redis的事件状态存储结构体void aeDeleteEventLoop(aeEventLoop *eventLoop);//删除redis的事件状态存储结构体void aeStop(aeEventLoop *eventLoop);//停止事件处理int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, aeFileProc *proc, void *clientData);//创建一个redis文件事件void aeDeleteFileEvent(aeEventLoop *eventLoop, int fd, int mask);//删除一个redis文件事件int aeGetFileEvents(aeEventLoop *eventLoop, int fd);//通过文件描述符查找一个文件事件long long aeCreateTimeEvent(aeEventLoop *eventLoop, long long milliseconds, aeTimeProc *proc, void *clientData, aeEventFinalizerProc *finalizerProc);//创建一个redis时间事件int aeDeleteTimeEvent(aeEventLoop *eventLoop, long long id);//删除一个redis时间事件int aeProcessEvents(aeEventLoop *eventLoop, int flags);//处理redis的aeEventLoop记录的事件int aeWait(int fd, int mask, long long milliseconds);//等待fd描述的文件milliseconds直到为可读或可写void aeMain(aeEventLoop *eventLoop);//事件主函数char *aeGetApiName(void);//获得多路复用底层实现名称void aeSetBeforeSleepProc(aeEventLoop *eventLoop, aeBeforeSleepProc *beforesleep);//设置aeBeforeSleepProc处理函数int aeGetSetSize(aeEventLoop *eventLoop);//获取eventLoop中setsizeint aeResizeSetSize(aeEventLoop *eventLoop, int setsize);//调整eventLoop中setsize 底层epoll多路复用多路复用的实现有select，poll，epoll，前两个作为老版本，有需要重复传参，轮询检测效率低的缺点，epoll更像是信号机制，通过回调函数，将触发的文件描述符事件添加到底层链表中，所以我们这里查看epoll的实现，但是可以看到，在每一个实现中对于多路复用的函数定义都一致，便于在上层调用屏蔽下层的实现。主要函数有创建或删除多路复用选择器，添加或删除检测的文件描述符，以及最重要的获取触发的事件。所涉及的epoll函数有：epoll_create：创建管理文件描述符的选择器，返回系统分配的管理器fd。epoll_ctl：通过fd对管理进行操作，有修改添加删除文件描述符操作。epoll_wait：等待fd的管理器中触发的文件描述符，返回所有触发的描述符数目，事件用指针参数获得。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107//创建一个epoll的api其也有一个文件描述符static int aeApiCreate(aeEventLoop *eventLoop) &#123; aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; //给epoll的事件分配空间 state-&gt;events = zmalloc(sizeof(struct epoll_event)*eventLoop-&gt;setsize); if (!state-&gt;events) &#123; zfree(state); return -1; &#125; //epoll管理的文件描述符 state-&gt;epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */ if (state-&gt;epfd == -1) &#123; zfree(state-&gt;events); zfree(state); return -1; &#125; eventLoop-&gt;apidata = state; return 0;&#125;//修改aeApiState中的sizestatic int aeApiResize(aeEventLoop *eventLoop, int setsize) &#123; aeApiState *state = eventLoop-&gt;apidata; //修改epoll_event空间 state-&gt;events = zrealloc(state-&gt;events, sizeof(struct epoll_event)*setsize); return 0;&#125;//释放aeApiState的空间static void aeApiFree(aeEventLoop *eventLoop) &#123; aeApiState *state = eventLoop-&gt;apidata; close(state-&gt;epfd);//关闭epoll的描述符 zfree(state-&gt;events); zfree(state);&#125;//epoll中添加一个事件static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) &#123; aeApiState *state = eventLoop-&gt;apidata; struct epoll_event ee = &#123;0&#125;; /* avoid valgrind warning 防止未初始化变量警告*/ /* If the fd was already monitored for some event, we need a MOD * operation. Otherwise we need an ADD operation. */ //判断是对该事件添加还是修改操作 int op = eventLoop-&gt;events[fd].mask == AE_NONE ? EPOLL_CTL_ADD : EPOLL_CTL_MOD; ee.events = 0; mask |= eventLoop-&gt;events[fd].mask; /* Merge old events 合并旧的mask*/ //更新事件的属性输出或输入 if (mask &amp; AE_READABLE) ee.events |= EPOLLIN; if (mask &amp; AE_WRITABLE) ee.events |= EPOLLOUT; //设置事件的描述符 ee.data.fd = fd; //epoll操作添加或修改事件 if (epoll_ctl(state-&gt;epfd,op,fd,&amp;ee) == -1) return -1; return 0;&#125;//epoll中删除一个事件static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int delmask) &#123; aeApiState *state = eventLoop-&gt;apidata; struct epoll_event ee = &#123;0&#125;; /* avoid valgrind warning */ int mask = eventLoop-&gt;events[fd].mask &amp; (~delmask);//修改mask ee.events = 0; //更新epoll中事件属性 if (mask &amp; AE_READABLE) ee.events |= EPOLLIN; if (mask &amp; AE_WRITABLE) ee.events |= EPOLLOUT; ee.data.fd = fd;//设置fd //根据具体mask的情况 修改还是删除epoll中的事件 if (mask != AE_NONE) &#123; epoll_ctl(state-&gt;epfd,EPOLL_CTL_MOD,fd,&amp;ee); &#125; else &#123; /* Note, Kernel &lt; 2.6.9 requires a non null event pointer even for * EPOLL_CTL_DEL. */ epoll_ctl(state-&gt;epfd,EPOLL_CTL_DEL,fd,&amp;ee); &#125;&#125;//epoll等待事件触发，得到所有触发事件的epoll_event，并在eventLoop中记载static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) &#123; aeApiState *state = eventLoop-&gt;apidata; int retval, numevents = 0; retval = epoll_wait(state-&gt;epfd,state-&gt;events,eventLoop-&gt;setsize, tvp ? (tvp-&gt;tv_sec*1000 + tvp-&gt;tv_usec/1000) : -1);//如果没有那么等待一定时间，否则获取触发的文件描述符 if (retval &gt; 0) &#123; int j; numevents = retval; //遍历所有准备好的描述符，添加到eventLoop的fired数组中 for (j = 0; j &lt; numevents; j++) &#123; int mask = 0; struct epoll_event *e = state-&gt;events+j; if (e-&gt;events &amp; EPOLLIN) mask |= AE_READABLE; if (e-&gt;events &amp; EPOLLOUT) mask |= AE_WRITABLE; if (e-&gt;events &amp; EPOLLERR) mask |= AE_WRITABLE; if (e-&gt;events &amp; EPOLLHUP) mask |= AE_WRITABLE; eventLoop-&gt;fired[j].fd = e-&gt;data.fd; eventLoop-&gt;fired[j].mask = mask; &#125; &#125; return numevents;&#125;//返回api的namestatic char *aeApiName(void) &#123; return "epoll";&#125; 事件操作函数ae的实现redisd的事件处理从aeMain函数开始：1234567891011//事件机制主函数void aeMain(aeEventLoop *eventLoop) &#123; eventLoop-&gt;stop = 0;//开启事件机制 //开启循环不停检测 while (!eventLoop-&gt;stop) &#123; if (eventLoop-&gt;beforesleep != NULL) eventLoop-&gt;beforesleep(eventLoop);//在处理事件之前执行处理函数 //处理redis中所有准备好的事件 aeProcessEvents(eventLoop, AE_ALL_EVENTS); &#125;&#125; 可见在循环事件没有停止时，redis中不断循环检测准备好的事件，并执行相应的处理函数，aeProcessEvents函数用来处理redis中所有的事件。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//处理redis中所有事件//flags代表处理事件的类型或者处理行为//flags=0 什么都不做直接退出//flags有AE_ALL_EVENTS，处理所有的事件//flags有AE_FILE_EVENTS，处理文件事件//flags有AE_TIME_EVENTS，处理时间事件//flags有AE_DONT_WAIT，不会等待文件事件int aeProcessEvents(aeEventLoop *eventLoop, int flags)&#123; int processed = 0, numevents; /* Nothing to do? return ASAP */ //两种事件都不处理直接返回 if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0; //如果需要等待的话，会等待直到有时间事件准备好 if (eventLoop-&gt;maxfd != -1 || ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) &#123; //如果处理时间事件并且阻塞等待文件事件或者处理文件事件 int j; aeTimeEvent *shortest = NULL; struct timeval tv, *tvp; if (flags &amp; AE_TIME_EVENTS &amp;&amp; !(flags &amp; AE_DONT_WAIT))//如果处理时间事件并且阻塞等待文件事件 shortest = aeSearchNearestTimer(eventLoop);//查找最近的时间事件 if (shortest) &#123;//如果有最近的时间事件，那么文件事件将等待最长时间为最近的时间事件触发，如果没有文件事件就先执行时间事件 long now_sec, now_ms; aeGetTime(&amp;now_sec, &amp;now_ms); tvp = &amp;tv; /* How many milliseconds we need to wait for the next * time event to fire? */ long long ms = (shortest-&gt;when_sec - now_sec)*1000 + shortest-&gt;when_ms - now_ms; if (ms &gt; 0) &#123;//设置等待时间 tvp-&gt;tv_sec = ms/1000; tvp-&gt;tv_usec = (ms % 1000)*1000; &#125; else &#123;//已经触发，不等待 tvp-&gt;tv_sec = 0; tvp-&gt;tv_usec = 0; &#125; &#125; else &#123; /* If we have to check for events but need to return * ASAP because of AE_DONT_WAIT we need to set the timeout * to zero */ //如果没有最近的时间事件 if (flags &amp; AE_DONT_WAIT) &#123; //不等待设为0ms tv.tv_sec = tv.tv_usec = 0; tvp = &amp;tv; &#125; else &#123;//否则永久等待 /* Otherwise we can block */ tvp = NULL; /* wait forever */ &#125; &#125; numevents = aeApiPoll(eventLoop, tvp);//等待文件事件 for (j = 0; j &lt; numevents; j++) &#123; aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd]; int mask = eventLoop-&gt;fired[j].mask; int fd = eventLoop-&gt;fired[j].fd; int rfired = 0; //处理文件事件 if (fe-&gt;mask &amp; mask &amp; AE_READABLE) &#123; rfired = 1; fe-&gt;rfileProc(eventLoop,fd,fe-&gt;clientData,mask); &#125; if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) &#123; if (!rfired || fe-&gt;wfileProc != fe-&gt;rfileProc) fe-&gt;wfileProc(eventLoop,fd,fe-&gt;clientData,mask); &#125; processed++; &#125; &#125; /* Check time events */ //处理事件事件 if (flags &amp; AE_TIME_EVENTS) processed += processTimeEvents(eventLoop); return processed; //返回处理的事件总数&#125; 在处理事件的函数中，如果flags包含等待阻塞的话，那么会搜索最近的时间事件，等待直到该时间事件触发，如果已经有触发的时间事件那么就相当于不等待，如果不存在时间事件，那么意味着会一直等待文件时间阻塞进程。如果flags包含不阻塞的等待的情况下，不会等待文件事件，如果当前没有文件事件，之间处理时间事件。所以在有两种事件都有的情况下，一般会先处理文件事件再处理时间事件。下面是处理时间事件函数processTimeEvents：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//处理时间事件 遍历一次时间事件列表 删除以及软删除的事件 并且处理触发的事件static int processTimeEvents(aeEventLoop *eventLoop) &#123; int processed = 0; aeTimeEvent *te, *prev; long long maxId; time_t now = time(NULL); /* If the system clock is moved to the future, and then set back to the * right value, time events may be delayed in a random way. Often this * means that scheduled operations will not be performed soon enough. * * Here we try to detect system clock skews, and force all the time * events to be processed ASAP when this happens: the idea is that * processing events earlier is less dangerous than delaying them * indefinitely, and practice suggests it is. */ //当eventLoop中时间错误定位到未来时间时，强行将所有时间事件提前执行 if (now &lt; eventLoop-&gt;lastTime) &#123; te = eventLoop-&gt;timeEventHead; while(te) &#123; te-&gt;when_sec = 0; te = te-&gt;next; &#125; &#125; eventLoop-&gt;lastTime = now;//重置时间 prev = NULL; te = eventLoop-&gt;timeEventHead; maxId = eventLoop-&gt;timeEventNextId-1;//最大时间事件的id while(te) &#123; long now_sec, now_ms; long long id; /* Remove events scheduled for deletion. */ //从链表中将之前软删除的时间事件删除 if (te-&gt;id == AE_DELETED_EVENT_ID) &#123; aeTimeEvent *next = te-&gt;next; if (prev == NULL) eventLoop-&gt;timeEventHead = te-&gt;next; else prev-&gt;next = te-&gt;next; if (te-&gt;finalizerProc) //执行删除函数 te-&gt;finalizerProc(eventLoop, te-&gt;clientData); zfree(te); te = next; continue; &#125; /* Make sure we don't process time events created by time events in * this iteration. Note that this check is currently useless: we always * add new timers on the head, however if we change the implementation * detail, this check may be useful again: we keep it here for future * defense. */ //确保我们不会处理在这个迭代中创建的事件 if (te-&gt;id &gt; maxId) &#123; te = te-&gt;next; continue; &#125; aeGetTime(&amp;now_sec, &amp;now_ms);//获取当前事件 if (now_sec &gt; te-&gt;when_sec || (now_sec == te-&gt;when_sec &amp;&amp; now_ms &gt;= te-&gt;when_ms))//判断时间事件是否触发 &#123; int retval; id = te-&gt;id; retval = te-&gt;timeProc(eventLoop, id, te-&gt;clientData);//触发函数 processed++; if (retval != AE_NOMORE) &#123; //如果返回不是-1 不删除该事件 再次设置触发时间 aeAddMillisecondsToNow(retval,&amp;te-&gt;when_sec,&amp;te-&gt;when_ms); &#125; else &#123; te-&gt;id = AE_DELETED_EVENT_ID; &#125; &#125; prev = te; te = te-&gt;next; &#125; return processed;&#125; 如果时间事件的处理函数返回非-1的值，代表用新的值重置时间事件，否则从eventloop中删除该完成的时间事件，删除后执行finalizerProc处理函数。自此ae的主要实现阅读完毕，其他函数包括增加删除事件，这里的增加删除也包括增加删除同一个事件的可读或可写事件，以及创建释放eventloop等相对简单自行阅读。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(18)——anet篇]]></title>
    <url>%2F2017%2F10%2F31%2Fredis%E6%BA%90%E7%A0%81-18-%E2%80%94%E2%80%94anet%E7%AF%87%2F</url>
    <content type="text"><![CDATA[anet简介anet文件主要就是对tcp套接字操作的封装，使它更加符合redis的系统逻辑，同时便于修改。包含socket的bind绑定本地地址，connect连接远程主机ip地址，listen开启监听函数，accept接受远程主机的连接请求，以及write和read对套接字描述符进行读写操作等socket函数。函数定义如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//tcp连接没有特殊要求 连接是阻塞的int anetTcpConnect(char *err, char *addr, int port);//tcp非阻塞连接int anetTcpNonBlockConnect(char *err, char *addr, int port);//tcp服务器的bind非阻塞连接int anetTcpNonBlockBindConnect(char *err, char *addr, int port, char *source_addr);//tcp服务器的bind非阻塞连接并且会失败重连int anetTcpNonBlockBestEffortBindConnect(char *err, char *addr, int port, char *source_addr);//本地套接字阻塞连接int anetUnixConnect(char *err, char *path);//本地套接字非阻塞连接int anetUnixNonBlockConnect(char *err, char *path);//从套接字中读取count个字节的数据除非遇到文件尾部了int anetRead(int fd, char *buf, int count);//处理所有主机地址为名称或是ipint anetResolve(char *err, char *host, char *ipbuf, size_t ipbuf_len);//只处理主机地址为ipint anetResolveIP(char *err, char *host, char *ipbuf, size_t ipbuf_len);//tcp中ipv4或ipv6的IP协议服务器套接字处理int anetTcpServer(char *err, int port, char *bindaddr, int backlog);//tcp中ipv6的IP协议服务器套接字处理int anetTcp6Server(char *err, int port, char *bindaddr, int backlog);//unix本地文件服务器套接字处理int anetUnixServer(char *err, char *path, mode_t perm, int backlog);//tcp套接字服务器端接收客户端的连接int anetTcpAccept(char *err, int serversock, char *ip, size_t ip_len, int *port);//本地服务器的接收连接函数 对连接的客户端信息没有存储要求int anetUnixAccept(char *err, int serversock);//往套接字中写入count字节的数据，直到写完或者写满count个字节int anetWrite(int fd, char *buf, int count);//设置用于通信的描述符的状态 阻塞还是非阻塞int anetNonBlock(char *err, int fd);int anetBlock(char *err, int fd);//设置网络链接nodelay属性 是否关闭Nagle算法int anetEnableTcpNoDelay(char *err, int fd);int anetDisableTcpNoDelay(char *err, int fd);//开启tcp的SO_KEEPALIVEint anetTcpKeepAlive(char *err, int fd);//设置数据传送时限int anetSendTimeout(char *err, int fd, long long ms);//根据套接字的描述符获取对方的ip地址以及端口号int anetPeerToString(int fd, char *ip, size_t ip_len, int *port);//设置tcp链接为keep alive去检测对方主机是否崩溃int anetKeepAlive(char *err, int fd, int interval);//根据套接字的描述符获取自己的ip地址以及端口号int anetSockName(int fd, char *ip, size_t ip_len, int *port);//格式化地址以及端口输出int anetFormatAddr(char *fmt, size_t fmt_len, char *ip, int port);//传入套接字描述符，返回对方套接字格式化的端口以及地址字符串int anetFormatPeer(int fd, char *fmt, size_t fmt_len);//根据套接字的描述符获取自己的ip地址以及端口号int anetFormatSock(int fd, char *fmt, size_t fmt_len); connect以及bind相关代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#define ANET_CONNECT_NONE 0 //默认套接字阻塞#define ANET_CONNECT_NONBLOCK 1//创建非阻塞套接字#define ANET_CONNECT_BE_BINDING 2 /* Best effort binding. 优先绑定本地地址，失败后连接远程地址*///套接字远程tcp连接static int anetTcpGenericConnect(char *err, char *addr, int port, char *source_addr, int flags)&#123; int s = ANET_ERR, rv; char portstr[6]; /* strlen("65535") + 1; */ struct addrinfo hints, *servinfo, *bservinfo, *p, *b; snprintf(portstr,sizeof(portstr),"%d",port); memset(&amp;hints,0,sizeof(hints)); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; //获取连接的目标地址端口的类型 创建本地的套接字 if ((rv = getaddrinfo(addr,portstr,&amp;hints,&amp;servinfo)) != 0) &#123; anetSetError(err, "%s", gai_strerror(rv)); return ANET_ERR; &#125; for (p = servinfo; p != NULL; p = p-&gt;ai_next) &#123; /* Try to create the socket and to connect it. * If we fail in the socket() call, or on connect(), we retry with * the next entry in servinfo. */ //尝试创建本地套接字并连接 如果成功则退出 否则尝试下一个目标套接字实体 if ((s = socket(p-&gt;ai_family,p-&gt;ai_socktype,p-&gt;ai_protocol)) == -1)//创建本地套接字 continue; if (anetSetReuseAddr(err,s) == ANET_ERR) goto error;//设置reuse以便及时打开以及关闭 if (flags &amp; ANET_CONNECT_NONBLOCK &amp;&amp; anetNonBlock(err,s) != ANET_OK)//设置非阻塞 goto error; if (source_addr) &#123;//如果有源地址代表是服务器则需要bind本地地址 int bound = 0; /* Using getaddrinfo saves us from self-determining IPv4 vs IPv6 */ if ((rv = getaddrinfo(source_addr, NULL, &amp;hints, &amp;bservinfo)) != 0) &#123; anetSetError(err, "%s", gai_strerror(rv)); goto error; &#125; for (b = bservinfo; b != NULL; b = b-&gt;ai_next) &#123; if (bind(s,b-&gt;ai_addr,b-&gt;ai_addrlen) != -1) &#123;//绑定本地地址 bound = 1; break; &#125; &#125; freeaddrinfo(bservinfo); if (!bound) &#123; anetSetError(err, "bind: %s", strerror(errno)); goto error; &#125; &#125; if (connect(s,p-&gt;ai_addr,p-&gt;ai_addrlen) == -1) &#123;//连接目标地址端口 /* If the socket is non-blocking, it is ok for connect() to * return an EINPROGRESS error here. */ //如果套接字非阻塞并且连接返回EINPROGRESS，返回当前占用的套接字 if (errno == EINPROGRESS &amp;&amp; flags &amp; ANET_CONNECT_NONBLOCK) goto end; close(s); s = ANET_ERR; continue; &#125; /* If we ended an iteration of the for loop without errors, we * have a connected socket. Let's return to the caller. */ //连接成功可以退出了 goto end; &#125; if (p == NULL) anetSetError(err, "creating socket: %s", strerror(errno));error: if (s != ANET_ERR) &#123; close(s); s = ANET_ERR; &#125;end: freeaddrinfo(servinfo); /* Handle best effort binding: if a binding address was used, but it is * not possible to create a socket, try again without a binding address. */ //处理best effort binding，如果一个绑定地址被占用，但是不可能创建一个套接字，不用bind地址再次尝试 if (s == ANET_ERR &amp;&amp; source_addr &amp;&amp; (flags &amp; ANET_CONNECT_BE_BINDING)) &#123; return anetTcpGenericConnect(err,addr,port,NULL,flags); &#125; else &#123; return s; &#125;&#125;//tcp连接没有特殊要求 连接是阻塞的int anetTcpConnect(char *err, char *addr, int port)&#123; return anetTcpGenericConnect(err,addr,port,NULL,ANET_CONNECT_NONE);&#125;//tcp非阻塞连接int anetTcpNonBlockConnect(char *err, char *addr, int port)&#123; return anetTcpGenericConnect(err,addr,port,NULL,ANET_CONNECT_NONBLOCK);&#125;//tcp服务器的bind非阻塞连接int anetTcpNonBlockBindConnect(char *err, char *addr, int port, char *source_addr)&#123; return anetTcpGenericConnect(err,addr,port,source_addr, ANET_CONNECT_NONBLOCK);&#125;//tcp服务器的bind非阻塞连接并且会失败重连int anetTcpNonBlockBestEffortBindConnect(char *err, char *addr, int port, char *source_addr)&#123; return anetTcpGenericConnect(err,addr,port,source_addr, ANET_CONNECT_NONBLOCK|ANET_CONNECT_BE_BINDING);&#125;//本地套接字连接int anetUnixGenericConnect(char *err, char *path, int flags)&#123; int s; struct sockaddr_un sa; //创建一个流数据的本地套接字 用于进程之间的数据交换 if ((s = anetCreateSocket(err,AF_LOCAL)) == ANET_ERR) return ANET_ERR; sa.sun_family = AF_LOCAL; strncpy(sa.sun_path,path,sizeof(sa.sun_path)-1); if (flags &amp; ANET_CONNECT_NONBLOCK) &#123;//设置是否非阻塞 if (anetNonBlock(err,s) != ANET_OK) return ANET_ERR; &#125; if (connect(s,(struct sockaddr*)&amp;sa,sizeof(sa)) == -1) &#123;//套接字连接 if (errno == EINPROGRESS &amp;&amp; flags &amp; ANET_CONNECT_NONBLOCK)//如果连接非阻塞并且失败了 返回当前正在被占用的s return s; anetSetError(err, "connect: %s", strerror(errno)); close(s); return ANET_ERR; &#125; return s;&#125;//本地套接字阻塞连接int anetUnixConnect(char *err, char *path)&#123; return anetUnixGenericConnect(err,path,ANET_CONNECT_NONE);&#125;//本地套接字非阻塞连接int anetUnixNonBlockConnect(char *err, char *path)&#123; return anetUnixGenericConnect(err,path,ANET_CONNECT_NONBLOCK);&#125; accept//接收连接的处理函数static int anetGenericAccept(char err, int s, struct sockaddr sa, socklen_t len) { int fd; while(1) { fd = accept(s,sa,len);//接收连接 if (fd == -1) { if (errno == EINTR)//被中断继续接收 continue; else { //没有连接或者超时 anetSetError(err, “accept: %s”, strerror(errno)); return ANET_ERR; } } break; } return fd;}//tcp套接字服务器端接收客户端的连接int anetTcpAccept(char err, int s, char ip, size_t ip_len, int port) { int fd; struct sockaddr_storage sa;//用来存储客户端的地址消息 socklen_t salen = sizeof(sa); if ((fd = anetGenericAccept(err,s,(struct sockaddr*)&amp;sa,&amp;salen)) == -1)//接收客户端连接 return ANET_ERR; if (sa.ss_family == AF_INET) { struct sockaddr_in *s = (struct sockaddr_in *)&amp;sa; if (ip) inet_ntop(AF_INET,(void*)&amp;(s-&gt;sin_addr),ip,ip_len);//转换地址消息存储到ip指针数组中 if (port) *port = ntohs(s-&gt;sin_port);//转换端口到port中 } else { struct sockaddr_in6 *s = (struct sockaddr_in6 *)&amp;sa; if (ip) inet_ntop(AF_INET6,(void*)&amp;(s-&gt;sin6_addr),ip,ip_len); if (port) *port = ntohs(s-&gt;sin6_port); } return fd; }//本地服务器的接收连接函数 对连接的客户端信息没有存储要求int anetUnixAccept(char err, int s) { int fd; struct sockaddr_un sa; socklen_t salen = sizeof(sa); if ((fd = anetGenericAccept(err,s,(struct sockaddr)&amp;sa,&amp;salen)) == -1) return ANET_ERR; return fd; } write以及read12345678910111213141516171819202122232425262728293031/* Like read(2) but make sure 'count' is read before to return * (unless error or EOF condition is encountered) *///从套接字中读取count个字节的数据除非遇到文件尾部了int anetRead(int fd, char *buf, int count)&#123; ssize_t nread, totlen = 0; while(totlen != count) &#123; nread = read(fd,buf,count-totlen); if (nread == 0) return totlen;//文件读完了 if (nread == -1) return -1;//读取错误 totlen += nread; buf += nread; &#125; return totlen;&#125;/* Like write(2) but make sure 'count' is written before to return * (unless error is encountered) *///往套接字中写入count字节的数据，直到写完或者写满count个字节int anetWrite(int fd, char *buf, int count)&#123; ssize_t nwritten, totlen = 0; while(totlen != count) &#123; nwritten = write(fd,buf,count-totlen); if (nwritten == 0) return totlen;//数据全部写入 if (nwritten == -1) return -1;//数据写入错误 totlen += nwritten; buf += nwritten; &#125; return totlen;&#125; 套接字相关属性设置12345678910//设置网络链接nodelay属性 是否关闭Nagle算法static int anetSetTcpNoDelay(char *err, int fd, int val)&#123; if (setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &amp;val, sizeof(val)) == -1) &#123; anetSetError(err, "setsockopt TCP_NODELAY: %s", strerror(errno)); return ANET_ERR; &#125; return ANET_OK;&#125; 在这里讲一下一个套接字首发的处理算法Nagle，发送端会累积很多个小的数据块之后才发送，或者收到来自接收端的ack发送，这样做的目的是为减少网络两端的传送次数，减少网络负载。然而默认网络节点还采用另一种算法Delay算法，即接受端不会立即发送ack，而是累积到足够多的ack或者数据后一起发送给发送端。这样两个算法相互作用，当执行write-write-read的操作时就会出现发送端延迟第二个write的情况，导致read被阻塞，默认的阻塞时间为40ms，所以设置nodelay属性取消算法Nagle，使得服务器可以及时响应。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//设置tcp链接为keep alive去检测对方主机是否崩溃int anetKeepAlive(char *err, int fd, int interval)&#123; int val = 1; //开启SO_KEEPALIVE if (setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &amp;val, sizeof(val)) == -1) &#123; anetSetError(err, "setsockopt SO_KEEPALIVE: %s", strerror(errno)); return ANET_ERR; &#125;#ifdef __linux__ /* Default settings are more or less garbage, with the keepalive time * set to 7200 by default on Linux. Modify settings to make the feature * actually useful. */ /* Send first probe after interval. */ //如果是linux系统那么设置一些特殊的属性 //tcp_keepalive_intval，保活探测消息的发送频率。默认值为75s。 //发送频率tcp_keepalive_intvl乘以发送次数tcp_keepalive_probes，就得到了从开始探测直到放弃探测确定连接断开的时间，大约为11min。 //tcp_keepalive_probes，TCP发送保活探测消息以确定连接是否已断开的次数。默认值为9（次）。 //注意：只有设置了SO_KEEPALIVE套接口选项后才会发送保活探测消息。 //tcp_keepalive_time，在TCP保活打开的情况下，最后一次数据交换到TCP发送第一个保活探测消息的时间，即允许的持续空闲时间。默认值为7200s（2h）。 val = interval; if (setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &amp;val, sizeof(val)) &lt; 0) &#123; anetSetError(err, "setsockopt TCP_KEEPIDLE: %s\n", strerror(errno)); return ANET_ERR; &#125; /* Send next probes after the specified interval. Note that we set the * delay as interval / 3, as we send three probes before detecting * an error (see the next setsockopt call). */ val = interval/3; if (val == 0) val = 1; if (setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &amp;val, sizeof(val)) &lt; 0) &#123; anetSetError(err, "setsockopt TCP_KEEPINTVL: %s\n", strerror(errno)); return ANET_ERR; &#125; /* Consider the socket in error state after three we send three ACK * probes without getting a reply. */ val = 3; if (setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &amp;val, sizeof(val)) &lt; 0) &#123; anetSetError(err, "setsockopt TCP_KEEPCNT: %s\n", strerror(errno)); return ANET_ERR; &#125;#else ((void) interval); /* Avoid unused var warning for non Linux systems. */#endif return ANET_OK;&#125;开启监听对方主机，检测是否奔溃，TCP_KEEPIDLE为第一次发送probe的时间延迟，之后每个TCP_KEEPINTVL的时长发送一次probe，发送TCP_KEEPCNT次probe后任然没有回应，确定对方已经奔溃断开连接，如果之前得到一次回应，重新检测。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(17)——aof篇]]></title>
    <url>%2F2017%2F10%2F21%2Fredis%E6%BA%90%E7%A0%81-17-%E2%80%94%E2%80%94aof%E7%AF%87%2F</url>
    <content type="text"><![CDATA[aof简介redis对内存的持久化手段之一aof，在配置文件设置appendonly为yes即可开启aof持久化手段，它将系统的每一条指令按照协议写入到磁盘文件中，当系统重启时，如果开启aof，就不用rdb载入，打开aof文件执行每一条指令即可回复数据库状态，相对于rdb持久化手段，aof有着存储粒度小的特点，可以将时间间隔缩小到秒级，但是不断的指令会导致aof文件过大，载入时间过长，所以系统采用aof文件重写策略解决这个问题。 aof持久化实现aof开启后，每一次导致数据库状态变化的指令将会通过feedAppendOnlyFile函数转换为真确的协议格式，存储到服务器的aof缓冲区中，feedAppendOnlyFile函数中细分为两个处理函数分别是catAppendOnlyGenericCommand函数以及catAppendOnlyExpireAtCommand函数，分别用来处理处理一般的指令以及包含了过期时间的指令。在每一次处理完文件事件以及时间事件后在servercon函数（一个服务器的函数，在循环中不断调用）中都要进行flushAppendOnlyFile函数，对aof缓冲区的数据进行写入文件操作，再根据相关的同步策略，对文件内核缓冲区进行同步：有三种同步策略如下：AOF_FSYNC_ALWAYS 命令写入aof_buf后调用系统fsync和操作同步到AOF文件，fsync完成后进程程返回AOF_FSYNC_EVERYSEC 命令写入aof_buf后调用系统write操作，write完成后线程返回。fsync同步文件操作由进程每秒调用一次，并且这个操作由一个子进程来完成，调用aof_background_fsync函数创建该任务AOF_FSYNC_NO 命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步，同步硬盘操作由操作系统负责此外，在运行时通过command打开关闭aof功能时，会调用stopAppendOnly以及startAppendOnly函数做初始化以及关闭操作。下面是相关函数的注解：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295//根据传入的指令 转换为写入aof文件的协议格式sds catAppendOnlyGenericCommand(sds dst, int argc, robj **argv) &#123; char buf[32]; int len, j; robj *o; // 格式："*&lt;argc&gt;\r\n" buf[0] = '*'; len = 1+ll2string(buf+1,sizeof(buf)-1,argc);//指令参数个数 buf[len++] = '\r'; buf[len++] = '\n'; dst = sdscatlen(dst,buf,len);//拼接到原来sds之后 // 遍历所有的参数，建立命令的格式：$&lt;command_len&gt;\r\n&lt;command&gt;\r\n for (j = 0; j &lt; argc; j++) &#123; o = getDecodedObject(argv[j]); buf[0] = '$'; len = 1+ll2string(buf+1,sizeof(buf)-1,sdslen(o-&gt;ptr));//每个参数的长度 buf[len++] = '\r'; buf[len++] = '\n'; dst = sdscatlen(dst,buf,len); dst = sdscatlen(dst,o-&gt;ptr,sdslen(o-&gt;ptr)); dst = sdscatlen(dst,"\r\n",2); decrRefCount(o); &#125; return dst; //返回处理完之后的sds&#125;//对于有时间期限的指令进行转换 主要是将秒转换为毫秒sds catAppendOnlyExpireAtCommand(sds buf, struct redisCommand *cmd, robj *key, robj *seconds) &#123; long long when; robj *argv[3]; /* Make sure we can use strtoll */ seconds = getDecodedObject(seconds); when = strtoll(seconds-&gt;ptr,NULL,10); //转换时间单位为毫秒 EXPIRE, SETEX, EXPIREAT if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == setexCommand || cmd-&gt;proc == expireatCommand) &#123; when *= 1000; &#125; //转化为绝对的过期时间用于载入时候判断键是否过期 对于指令EXPIRE, PEXPIRE, SETEX, PSETEX if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == pexpireCommand || cmd-&gt;proc == setexCommand || cmd-&gt;proc == psetexCommand) &#123; when += mstime(); &#125; decrRefCount(seconds); //将所有的指令都转化为PEXPIREAT argv[0] = createStringObject("PEXPIREAT",9); argv[1] = key; argv[2] = createStringObjectFromLongLong(when); buf = catAppendOnlyGenericCommand(buf, 3, argv); decrRefCount(argv[0]); decrRefCount(argv[2]); return buf;&#125;//调用上面两种aof指令转换，将符合协议的指令加入到缓冲区中，根据相关的策略进行同步void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) &#123; sds buf = sdsempty(); robj *tmpargv[3]; /* The DB this command was targeting is not the same as the last command * we appended. To issue a SELECT command is needed. */ //先选择数据库 if (dictid != server.aof_selected_db) &#123; char seldb[64]; snprintf(seldb,sizeof(seldb),"%d",dictid); buf = sdscatprintf(buf,"*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n", (unsigned long)strlen(seldb),seldb); server.aof_selected_db = dictid; &#125; //针对不同的指令采用上面两种处理方式或者混合使用 if (cmd-&gt;proc == expireCommand || cmd-&gt;proc == pexpireCommand || cmd-&gt;proc == expireatCommand) &#123; /* Translate EXPIRE/PEXPIRE/EXPIREAT into PEXPIREAT */ buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);//转换为PEXPIREAT然后存储到缓冲区 &#125; else if (cmd-&gt;proc == setexCommand || cmd-&gt;proc == psetexCommand) &#123; /* Translate SETEX/PSETEX to SET and PEXPIREAT */ tmpargv[0] = createStringObject("SET",3);//对于SETEX/PSETEX指令转换为Set以及PEXPIREAT然后处理并存储到缓冲区 tmpargv[1] = argv[1]; tmpargv[2] = argv[3]; buf = catAppendOnlyGenericCommand(buf,3,tmpargv); decrRefCount(tmpargv[0]); buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]); &#125; else &#123; /* All the other commands don't need translation or need the * same translation already operated in the command vector * for the replication itself. */ //对于其他的指令直接使用普通的指令处理即可 buf = catAppendOnlyGenericCommand(buf,argc,argv); &#125; /* Append to the AOF buffer. This will be flushed on disk just before * of re-entering the event loop, so before the client will get a * positive reply about the operation performed. */ //如果aof处于打开状态，那么添加指令到缓冲区 if (server.aof_state == AOF_ON) server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf)); /* If a background append only file rewriting is in progress we want to * accumulate the differences between the child DB and the current one * in a buffer, so that when the child process will do its work we * can append the differences to the new append only file. */ //如果有aof重写子进程那么需要将指令加入到重写缓冲区中，在子进程完成后，append到aof文件尾部，或者子进程失败那么写入到原有的aof缓冲区中，这些在重写完毕处理函数中执行 if (server.aof_child_pid != -1) aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf)); sdsfree(buf);&#125;//刷新aof缓冲区数据到磁盘中#define AOF_WRITE_LOG_ERROR_RATE 30 /* Seconds between errors logging. */void flushAppendOnlyFile(int force) &#123; ssize_t nwritten; int sync_in_progress = 0; mstime_t latency; if (sdslen(server.aof_buf) == 0) return;//缓冲区无数据直接退出 //每秒钟同步一次 if (server.aof_fsync == AOF_FSYNC_EVERYSEC) //aof同步操作是否在后台运行 sync_in_progress = bioPendingJobsOfType(BIO_AOF_FSYNC) != 0; //没秒同步一次并且不强制写 if (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; !force) &#123; /* With this append fsync policy we do background fsyncing. * If the fsync is still in progress we can try to delay * the write for a couple of seconds. */ //在后台真在进行刷新操作的时候可以延迟写操作2秒钟 if (sync_in_progress) &#123; if (server.aof_flush_postponed_start == 0) &#123; /* No previous write postponing, remember that we are * postponing the flush and return. */ //之前没有延迟 记录延迟开始时间 server.aof_flush_postponed_start = server.unixtime; return; &#125; else if (server.unixtime - server.aof_flush_postponed_start &lt; 2) &#123; /* We were already waiting for fsync to finish, but for less * than two seconds this is still ok. Postpone again. */ //延迟时间间隔2秒中之内，直接跳过此次写 return; &#125; /* Otherwise fall trough, and go write since we can't wait * over two seconds. */ //延迟间隔超过2秒钟 延迟同步记录次数的全局变量加1 执行下面的写操作 但可能被同步操作阻塞 server.aof_delayed_fsync++; serverLog(LL_NOTICE,"Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis."); &#125; &#125; /* We want to perform a single write. This should be guaranteed atomic * at least if the filesystem we are writing is a real physical one. * While this will save us against the server being killed I don't think * there is much to do about the whole server stopping for power problems * or alike */ //执行aof文件的写入操作 记录延迟 latencyStartMonitor(latency); nwritten = write(server.aof_fd,server.aof_buf,sdslen(server.aof_buf)); latencyEndMonitor(latency); /* We want to capture different events for delayed writes: * when the delay happens with a pending fsync, or with a saving child * active, and when the above two conditions are missing. * We also use an additional event name to save all samples which is * useful for graphing / monitoring purposes. */ //记录下因为什么原因造成的延迟 if (sync_in_progress) &#123; latencyAddSampleIfNeeded("aof-write-pending-fsync",latency); &#125; else if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) &#123; latencyAddSampleIfNeeded("aof-write-active-child",latency); &#125; else &#123; latencyAddSampleIfNeeded("aof-write-alone",latency); &#125; latencyAddSampleIfNeeded("aof-write",latency); /* We performed the write so reset the postponed flush sentinel to zero. */ //在写入aof缓冲区数据后 跟新延迟开始时间为0 server.aof_flush_postponed_start = 0; //如果写入的长度与实际的缓冲区长度不符 if (nwritten != (signed)sdslen(server.aof_buf)) &#123; static time_t last_write_error_log = 0; int can_log = 0; /* Limit logging rate to 1 line per AOF_WRITE_LOG_ERROR_RATE seconds. */ //限制log的速率为每30秒一行 if ((server.unixtime - last_write_error_log) &gt; AOF_WRITE_LOG_ERROR_RATE) &#123; can_log = 1; last_write_error_log = server.unixtime; &#125; /* Log the AOF write error and record the error code. */ if (nwritten == -1) &#123; //报告aof文件写入错误 if (can_log) &#123; serverLog(LL_WARNING,"Error writing to the AOF file: %s", strerror(errno)); server.aof_last_write_errno = errno; &#125; &#125; else &#123; //没有将所有的缓冲区数据写入到aof文件中 报告short write if (can_log) &#123; serverLog(LL_WARNING,"Short write while writing to " "the AOF file: (nwritten=%lld, " "expected=%lld)", (long long)nwritten, (long long)sdslen(server.aof_buf)); &#125; if (ftruncate(server.aof_fd, server.aof_current_size) == -1) &#123; //恢复原有的数据长度 if (can_log) &#123; serverLog(LL_WARNING, "Could not remove short write " "from the append-only file. Redis may refuse " "to load the AOF the next time it starts. " "ftruncate: %s", strerror(errno)); &#125; &#125; else &#123; /* If the ftruncate() succeeded we can set nwritten to * -1 since there is no longer partial data into the AOF. */ //如果恢复成功 等同于这次aof文件失败 nwritten = -1; &#125; server.aof_last_write_errno = ENOSPC; &#125; /* Handle the AOF write error. */ //处理aof文件写入失败 if (server.aof_fsync == AOF_FSYNC_ALWAYS) &#123; //当同步策略时立即同步时，立即退出 /* We can't recover when the fsync policy is ALWAYS since the * reply for the client is already in the output buffers, and we * have the contract with the user that on acknowledged write data * is synced on disk. */ serverLog(LL_WARNING,"Can't recover from AOF write error when the AOF fsync policy is 'always'. Exiting..."); exit(1); &#125; else &#123; /* Recover from failed write leaving data into the buffer. However * set an error to stop accepting writes as long as the error * condition is not cleared. */ server.aof_last_write_status = C_ERR; /* Trim the sds buffer if there was a partial write, and there * was no way to undo it with ftruncate(2). */ if (nwritten &gt; 0) &#123; //跟新写入一部分后的缓冲区 server.aof_current_size += nwritten; sdsrange(server.aof_buf,nwritten,-1); &#125; return; /* We'll try again on the next call... */ &#125; &#125; else &#123; /* Successful write(2). If AOF was in error state, restore the * OK state and log the event. */ if (server.aof_last_write_status == C_ERR) &#123; //修改aof写入状态 serverLog(LL_WARNING, "AOF write error looks solved, Redis can write again."); server.aof_last_write_status = C_OK; &#125; &#125; server.aof_current_size += nwritten; /* Re-use AOF buffer when it is small enough. The maximum comes from the * arena size of 4k minus some overhead (but is otherwise arbitrary). */ //如果aof_buf的大小很小那么可以进行内存复用 if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) &lt; 4000) &#123; sdsclear(server.aof_buf); &#125; else &#123; sdsfree(server.aof_buf); server.aof_buf = sdsempty(); &#125; /* Don't fsync if no-appendfsync-on-rewrite is set to yes and there are * children doing I/O in the background. */ //在有子进程执行并且设置了重写不同步时直接返回不同步 if (server.aof_no_fsync_on_rewrite &amp;&amp; (server.aof_child_pid != -1 || server.rdb_child_pid != -1)) return; /* Perform the fsync if needed. */ if (server.aof_fsync == AOF_FSYNC_ALWAYS) &#123; /* aof_fsync is defined as fdatasync() for Linux in order to avoid * flushing metadata. */ //如果是每次写入后直接同步 那么记录延迟 同步文件 latencyStartMonitor(latency); aof_fsync(server.aof_fd); /* Let's try to get this data on the disk */ latencyEndMonitor(latency); latencyAddSampleIfNeeded("aof-fsync-always",latency); server.aof_last_fsync = server.unixtime; &#125; else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; server.unixtime &gt; server.aof_last_fsync)) &#123; if (!sync_in_progress) aof_background_fsync(server.aof_fd); server.aof_last_fsync = server.unixtime; &#125;&#125; aof文件重写将每一条指令都通过协议转换后存入aof文件，必然会导致文件的大小不断变大，从而导致在载入aof文件时，需要花费大量的时间，所以需要对aof文件进行重写，去除不必要的指令，合并多条指令，过期的键指令可以省略，这样aof重写就是根据目前数据库的状态来重写指令指令。aof重写操作可以有手动触发或者自动触发：手动触发通过指令BGREWRITEAOF；自己触发的条件定义在配置文件中：auto-aof-rewrite-percentage 100：当前AOF的文件空间(aof_current_size)和上一次重写后AOF文件空间(aof_base_size)的比值。auto-aof-rewrite-min-size 64mb：表示运行AOF重写时文件最小的体积。自动触发时机 = (aof_current_size &gt; auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size) / aof_base_size &gt;= auto-aof-rewrite-percentage)从指令实现的函数出发可以知道，通过调用rewriteAppendOnlyFileBackground函数，在后台创建子进程来进行aof重写操作，同时创建了许多管道用于父进程与子进程之间的通信，后面会讲到这些管道的用处，在子进程中通过调用rewriteAppendOnlyFile函数进行对aof文件重写，在rewriteAppendOnlyFileRio函数有具体的对每个redis对象的重写函数实现，重写完成之后调用backgroundRewriteDoneHandler函数，完成重写后的处理。在子进程进行aof重写的过程中，父进程还要不断的接收来client的命令，可能会对数据库状态造成变化，所以在服务端通过aofrwblock数据结构的链表来存储这些指令，同时也将它们存储在aof_buf缓冲区中，当重写完成后如果成功，在aof文件尾加上重写时执行指令集，如果失败也不会丢失这些指令，因为在aof_buf中也存储了指令。这里不得不说的redis4.0对于aof重写的两个优化：1.重写时，子进程中处理父进程中的指令，减少父进程中写磁盘的操作，优化重写时间，上面创建的管道就是为了实现父子进程之间的通信，避免了重写完毕后才对重写期间的指令进行append。下面讲一下关于父子进程之间的各管道的作用：server.aof_pipe_write_data_to_child 父进程写数据到子进程描述符server.aof_pipe_read_data_from_parent 子进程接受父进程数据描述符server.aof_pipe_write_ack_to_parent 子进程写ack到父进程描述符server.aof_pipe_read_ack_from_child 父进程读子进程ack描述符server.aof_pipe_write_ack_to_child 父进程写ack到子进程描述符server.aof_pipe_read_ack_from_parent 子进程读父进程ack描述符前两个是非阻塞的，用于传递重写时执行的指令，后面四个用于父子进程之间握手协议，用来停止父进程到子进程的数据传递。下面说一下重写过程中，进程之间的工作流程：子进程：1）创建用于通信的管道，注册aof_pipe_read_ack_from_child的可读事件，设置aof_stop_sending_diff=0开启diff传输。2）创建子进程进行aof重写，重写过程中每增长10k，就从父进程读取diff。3）等待20m来自父进程的数据，读取来自父进程的数据，添加到aof_child_diff中，直到1000ms停止。4）子进程发送“!”给父进程。5）10s内接受父进程的回应“!”，没有接受到错误退出，否则停止父进程的传输。6）接受管道中遗留的数据，将aof_child_diff中数据append到新的aof文件中。父进程：1）处理指令为协议格式，存储到aof_buf中，存储到aof_rewrite_buf_blocks中。2）如果没有创建aof_pipe_write_data_to_child的可写事件。3）不断的将aof_rewrite_buf_blocks的数据通过aof_pipe_write_data_to_child发送给子进程。4）如果没有数据或者aof_stop_sending_diff=1了删除可写事件，并退出。5）重写完毕后父进程还要将aof_rewrite_buf_block中剩余的数据写入新aof文件。2.重写时的混合持久化手段，当设置了RDB_SAVE_AOF_PREAMBLE时，先用rdb手段将数据库状态保存然后之后append指令，进一步加快重写以及载入时间。相关函数：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567// bgrewriteaof命令的实现，进行后台aof文件重写void bgrewriteaofCommand(client *c) &#123; if (server.aof_child_pid != -1) &#123; // 正在进行aof重写拒绝此次命令 addReplyError(c,"Background append only file rewriting already in progress"); &#125; else if (server.rdb_child_pid != -1) &#123; //正在进行rdb后台保存，将aof重写提上日程 server.aof_rewrite_scheduled = 1; addReplyStatus(c,"Background append only file rewriting scheduled"); &#125; else if (rewriteAppendOnlyFileBackground() == C_OK) &#123; //进行后台aof重写，返回结果 addReplyStatus(c,"Background append only file rewriting started"); &#125; else &#123; addReply(c,shared.err); &#125;&#125;//后台实现aof重写逻辑int rewriteAppendOnlyFileBackground(void) &#123; pid_t childpid; long long start; //如果存在aof或rdb子进程那么直接退出 if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) return C_ERR; if (aofCreatePipes() != C_OK) return C_ERR; //创建aof进程之间通信的管道 openChildInfoPipe(); //开启子进程消息通信管道 start = ustime(); if ((childpid = fork()) == 0) &#123; char tmpfile[256]; /* Child */ //关闭套接字监听 closeListeningSockets(0); redisSetProcTitle("redis-aof-rewrite");//设置进程标题 snprintf(tmpfile,256,"temp-rewriteaof-bg-%d.aof", (int) getpid());//设置临时oaf文件名 if (rewriteAppendOnlyFile(tmpfile) == C_OK) &#123;//进行aof重写 size_t private_dirty = zmalloc_get_private_dirty(-1);1 //获取重写时脏数据，并传递给父进程 if (private_dirty) &#123; serverLog(LL_NOTICE, "AOF rewrite: %zu MB of memory used by copy-on-write", private_dirty/(1024*1024)); &#125; server.child_info_data.cow_size = private_dirty; sendChildInfo(CHILD_INFO_TYPE_AOF); exitFromChild(0); &#125; else &#123; exitFromChild(1); &#125; &#125; else &#123; /* Parent */ //计算fork时间 以及fork速率 server.stat_fork_time = ustime()-start; server.stat_fork_rate = (double) zmalloc_used_memory() * 1000000 / server.stat_fork_time / (1024*1024*1024); /* GB per second. */ latencyAddSampleIfNeeded("fork",server.stat_fork_time/1000);//在超过阈值时添加延迟案例 if (childpid == -1) &#123;//aof子进程开启失败 closeChildInfoPipe(); serverLog(LL_WARNING, "Can't rewrite append only file in background: fork: %s", strerror(errno)); aofClosePipes(); return C_ERR; &#125; serverLog(LL_NOTICE, "Background append only file rewriting started by pid %d",childpid); server.aof_rewrite_scheduled = 0; server.aof_rewrite_time_start = time(NULL); server.aof_child_pid = childpid; updateDictResizePolicy(); /* We set appendseldb to -1 in order to force the next call to the * feedAppendOnlyFile() to issue a SELECT command, so the differences * accumulated by the parent into server.aof_rewrite_buf will start * with a SELECT statement and it will be safe to merge. */ //强迫下一次命令先写入数据选择命令，达到安全合并的目的 server.aof_selected_db = -1; replicationScriptCacheFlush();//刷新副本 return C_OK; &#125; return C_OK; /* unreached */&#125;//通过一串指令完全的重建数据库，写入到aof文件中//为了最小化指令数目，我们尽量使用指令RPUSH, SADD ZADD，同时也要注意一条指令最大的item，这时可以用多条指令代替即可int rewriteAppendOnlyFile(char *filename) &#123; rio aof; FILE *fp; char tmpfile[256]; char byte; /* Note that we have to use a different temp name here compared to the * one used by rewriteAppendOnlyFileBackground() function. */ snprintf(tmpfile,256,"temp-rewriteaof-%d.aof", (int) getpid()); //创建临时aof文件 注意这里的文件与调用的文件名不同 fp = fopen(tmpfile,"w"); if (!fp) &#123; serverLog(LL_WARNING, "Opening the temp file for AOF rewrite in rewriteAppendOnlyFile(): %s", strerror(errno)); return C_ERR; &#125; server.aof_child_diff = sdsempty(); rioInitWithFile(&amp;aof,fp); //设置aof重写文件流同步 if (server.aof_rewrite_incremental_fsync) rioSetAutoSync(&amp;aof,AOF_AUTOSYNC_BYTES); //混合持久化 将rdb写在aof文件的开头 if (server.aof_use_rdb_preamble) &#123; int error; if (rdbSaveRio(&amp;aof,&amp;error,RDB_SAVE_AOF_PREAMBLE,NULL) == C_ERR) &#123; errno = error; goto werr; &#125; &#125; else &#123; //没有开启混合持久化 直接开始aof重写 if (rewriteAppendOnlyFileRio(&amp;aof) == C_ERR) goto werr; &#125; /* Do an initial slow fsync here while the parent is still sending * data, in order to make the next final fsync faster. */ if (fflush(fp) == EOF) goto werr; if (fsync(fileno(fp)) == -1) goto werr; /* Read again a few times to get more data from the parent. * We can't read forever (the server may receive data from clients * faster than it is able to send data to the child), so we try to read * some more data in a loop as soon as there is a good chance more data * will come. If it looks like we are wasting time, we abort (this * happens after 20 ms without new data). */ int nodata = 0; mstime_t start = mstime(); while(mstime()-start &lt; 1000 &amp;&amp; nodata &lt; 20) &#123; if (aeWait(server.aof_pipe_read_data_from_parent, AE_READABLE, 1) &lt;= 0) &#123; nodata++; continue; &#125; nodata = 0; /* Start counting from zero, we stop on N *contiguous* timeouts. */ aofReadDiffFromParent(); &#125; /* Ask the master to stop sending diffs. */ //停止从父进程接受新的指令 if (write(server.aof_pipe_write_ack_to_parent,"!",1) != 1) goto werr; if (anetNonBlock(NULL,server.aof_pipe_read_ack_from_parent) != ANET_OK) goto werr; /* We read the ACK from the server using a 10 seconds timeout. Normally * it should reply ASAP, but just in case we lose its reply, we are sure * the child will eventually get terminated. */ //接收父进程的回应 if (syncRead(server.aof_pipe_read_ack_from_parent,&amp;byte,1,5000) != 1 || byte != '!') goto werr; serverLog(LL_NOTICE,"Parent agreed to stop sending diffs. Finalizing AOF..."); /* Read the final diff if any. */ //读取最后的新的指令 aofReadDiffFromParent(); /* Write the received diff to the file. */ serverLog(LL_NOTICE, "Concatenating %.2f MB of AOF diff received from parent.", (double) sdslen(server.aof_child_diff) / (1024*1024)); //将来自父进程的差异写入到aof文件中 if (rioWrite(&amp;aof,server.aof_child_diff,sdslen(server.aof_child_diff)) == 0) goto werr; /* Make sure data will not remain on the OS's output buffers */ //强制刷新缓冲流 if (fflush(fp) == EOF) goto werr; if (fsync(fileno(fp)) == -1) goto werr; if (fclose(fp) == EOF) goto werr; /* Use RENAME to make sure the DB file is changed atomically only * if the generate DB file is ok. */ //替换文件名 if (rename(tmpfile,filename) == -1) &#123; serverLog(LL_WARNING,"Error moving temp append only file on the final destination: %s", strerror(errno)); unlink(tmpfile); return C_ERR; &#125; serverLog(LL_NOTICE,"SYNC append only file rewrite performed"); return C_OK;werr: serverLog(LL_WARNING,"Write error writing append only file on disk: %s", strerror(errno)); fclose(fp); unlink(tmpfile); return C_ERR;&#125;//用于在aof重写时存储父进程接受的指令的数据结构typedef struct aofrwblock &#123; unsigned long used, free; char buf[AOF_RW_BUF_BLOCK_SIZE];&#125; aofrwblock;/* This function free the old AOF rewrite buffer if needed, and initialize * a fresh new one. It tests for server.aof_rewrite_buf_blocks equal to NULL * so can be used for the first initialization as well. *///在需要的情况下释放旧的aof重写缓冲区，初始化一个新的void aofRewriteBufferReset(void) &#123; if (server.aof_rewrite_buf_blocks) listRelease(server.aof_rewrite_buf_blocks); server.aof_rewrite_buf_blocks = listCreate(); listSetFreeMethod(server.aof_rewrite_buf_blocks,zfree);&#125;/* Return the current size of the AOF rewrite buffer. *///返回当前aof重写缓冲区的sizeunsigned long aofRewriteBufferSize(void) &#123; listNode *ln; listIter li; unsigned long size = 0; listRewind(server.aof_rewrite_buf_blocks,&amp;li); while((ln = listNext(&amp;li))) &#123; aofrwblock *block = listNodeValue(ln); size += block-&gt;used; &#125; return size;&#125;/* Event handler used to send data to the child process doing the AOF * rewrite. We send pieces of our AOF differences buffer so that the final * write when the child finishes the rewrite will be small. *///aof重写缓冲区发送给子进程的触发事件void aofChildWriteDiffData(aeEventLoop *el, int fd, void *privdata, int mask) &#123; listNode *ln; aofrwblock *block; ssize_t nwritten; UNUSED(el); UNUSED(fd); UNUSED(privdata); UNUSED(mask); while(1) &#123; ln = listFirst(server.aof_rewrite_buf_blocks); block = ln ? ln-&gt;value : NULL; if (server.aof_stop_sending_diff || !block) &#123; aeDeleteFileEvent(server.el,server.aof_pipe_write_data_to_child, AE_WRITABLE); return; &#125; if (block-&gt;used &gt; 0) &#123; nwritten = write(server.aof_pipe_write_data_to_child, block-&gt;buf,block-&gt;used); if (nwritten &lt;= 0) return; memmove(block-&gt;buf,block-&gt;buf+nwritten,block-&gt;used-nwritten); block-&gt;used -= nwritten; &#125; if (block-&gt;used == 0) listDelNode(server.aof_rewrite_buf_blocks,ln); &#125;&#125;/* Append data to the AOF rewrite buffer, allocating new blocks if needed. *///往aof重写缓冲区中添加数据 在需要的时候分配新的数据块void aofRewriteBufferAppend(unsigned char *s, unsigned long len) &#123; listNode *ln = listLast(server.aof_rewrite_buf_blocks); aofrwblock *block = ln ? ln-&gt;value : NULL; while(len) &#123; /* If we already got at least an allocated block, try appending * at least some piece into it. */ if (block) &#123; unsigned long thislen = (block-&gt;free &lt; len) ? block-&gt;free : len; if (thislen) &#123; /* The current block is not already full. */ memcpy(block-&gt;buf+block-&gt;used, s, thislen); block-&gt;used += thislen; block-&gt;free -= thislen; s += thislen; len -= thislen; &#125; &#125; if (len) &#123; /* First block to allocate, or need another block. */ int numblocks; block = zmalloc(sizeof(*block)); block-&gt;free = AOF_RW_BUF_BLOCK_SIZE; block-&gt;used = 0; listAddNodeTail(server.aof_rewrite_buf_blocks,block); /* Log every time we cross more 10 or 100 blocks, respectively * as a notice or warning. */ numblocks = listLength(server.aof_rewrite_buf_blocks); if (((numblocks+1) % 10) == 0) &#123; int level = ((numblocks+1) % 100) == 0 ? LL_WARNING : LL_NOTICE; serverLog(level,"Background AOF buffer size: %lu MB", aofRewriteBufferSize()/(1024*1024)); &#125; &#125; &#125; /* Install a file event to send data to the rewrite child if there is * not one already. */ if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) &#123; aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child, AE_WRITABLE, aofChildWriteDiffData, NULL); &#125;&#125;/* Write the buffer (possibly composed of multiple blocks) into the specified * fd. If a short write or any other error happens -1 is returned, * otherwise the number of bytes written is returned. *///将aof缓冲区的指令写入到aof文件中ssize_t aofRewriteBufferWrite(int fd) &#123; listNode *ln; listIter li; ssize_t count = 0; listRewind(server.aof_rewrite_buf_blocks,&amp;li); while((ln = listNext(&amp;li))) &#123; aofrwblock *block = listNodeValue(ln); ssize_t nwritten; if (block-&gt;used) &#123; nwritten = write(fd,block-&gt;buf,block-&gt;used); if (nwritten != (ssize_t)block-&gt;used) &#123; if (nwritten == 0) errno = EIO; return -1; &#125; count += nwritten; &#125; &#125; return count;&#125;//这个函数被aof重写子进程调用来读取父进程积累的差异到服务器缓冲区中，函数出现在重写的尾部ssize_t aofReadDiffFromParent(void) &#123; char buf[65536]; /* Default pipe buffer size on most Linux systems. */ ssize_t nread, total = 0; while ((nread = read(server.aof_pipe_read_data_from_parent,buf,sizeof(buf))) &gt; 0) &#123; server.aof_child_diff = sdscatlen(server.aof_child_diff,buf,nread); total += nread; &#125; return total;&#125;void aofChildPipeReadable(aeEventLoop *el, int fd, void *privdata, int mask) &#123; char byte; UNUSED(el); UNUSED(privdata); UNUSED(mask); if (read(fd,&amp;byte,1) == 1 &amp;&amp; byte == '!') &#123; serverLog(LL_NOTICE,"AOF rewrite child asks to stop sending diffs."); server.aof_stop_sending_diff = 1; if (write(server.aof_pipe_write_ack_to_child,"!",1) != 1) &#123; //向子进程发送同样的符号作为回应 /* If we can't send the ack, inform the user, but don't try again * since in the other side the children will use a timeout if the * kernel can't buffer our write, or, the children was * terminated. */ serverLog(LL_WARNING,"Can't send ACK to AOF child: %s", strerror(errno)); &#125; &#125; /* Remove the handler since this can be called only one time during a * rewrite. */ //移除这个触发事件 aeDeleteFileEvent(server.el,server.aof_pipe_read_ack_from_child,AE_READABLE);&#125;/* Create the pipes used for parent - child process IPC during rewrite. * We have a data pipe used to send AOF incremental diffs to the child, * and two other pipes used by the children to signal it finished with * the rewrite so no more data should be written, and another for the * parent to acknowledge it understood this new condition. *///创建rewirteaof父子进程之间的ipc管道//我们有一个数据管道用来传输aof增加的差异给子进程，还有另外的两个管道用来表示完成aof重写没有其他数据要被写入，还有一个用于父进程去表示它明白了现在的状况int aofCreatePipes(void) &#123; int fds[6] = &#123;-1, -1, -1, -1, -1, -1&#125;; int j; if (pipe(fds) == -1) goto error; /* parent -&gt; children data. */ if (pipe(fds+2) == -1) goto error; /* children -&gt; parent ack. */ if (pipe(fds+4) == -1) goto error; /* children -&gt; parent ack. */ /* Parent -&gt; children data is non blocking. */ //父子进程之间的数据是不阻塞的 if (anetNonBlock(NULL,fds[0]) != ANET_OK) goto error; if (anetNonBlock(NULL,fds[1]) != ANET_OK) goto error //创建一个来自子进程读端的触发事件 if (aeCreateFileEvent(server.el, fds[2], AE_READABLE, aofChildPipeReadable, NULL) == AE_ERR) goto error; //赋值全局变量 server.aof_pipe_write_data_to_child = fds[1]; server.aof_pipe_read_data_from_parent = fds[0]; server.aof_pipe_write_ack_to_parent = fds[3]; server.aof_pipe_read_ack_from_child = fds[2]; server.aof_pipe_write_ack_to_child = fds[5]; server.aof_pipe_read_ack_from_parent = fds[4]; server.aof_stop_sending_diff = 0; return C_OK;error: serverLog(LL_WARNING,"Error opening /setting AOF rewrite IPC pipes: %s", strerror(errno)); for (j = 0; j &lt; 6; j++) if(fds[j] != -1) close(fds[j]); return C_ERR;&#125;//关闭aof重写创建的通信管道void aofClosePipes(void) &#123; aeDeleteFileEvent(server.el,server.aof_pipe_read_ack_from_child,AE_READABLE); aeDeleteFileEvent(server.el,server.aof_pipe_write_data_to_child,AE_WRITABLE); close(server.aof_pipe_write_data_to_child); close(server.aof_pipe_read_data_from_parent); close(server.aof_pipe_write_ack_to_parent); close(server.aof_pipe_read_ack_from_child); close(server.aof_pipe_write_ack_to_child); close(server.aof_pipe_read_ack_from_parent);&#125;//后台aof重写功能完成后的执行的处理函数void backgroundRewriteDoneHandler(int exitcode, int bysignal) &#123; if (!bysignal &amp;&amp; exitcode == 0) &#123; int newfd, oldfd; char tmpfile[256]; long long now = ustime(); mstime_t latency; serverLog(LL_NOTICE, "Background AOF rewrite terminated with success"); /* Flush the differences accumulated by the parent to the * rewritten AOF. */ //打开临时aof文件 同步重写时父进程累计的diffs latencyStartMonitor(latency); snprintf(tmpfile,256,"temp-rewriteaof-bg-%d.aof", (int)server.aof_child_pid); newfd = open(tmpfile,O_WRONLY|O_APPEND); if (newfd == -1) &#123; serverLog(LL_WARNING, "Unable to open the temporary AOF produced by the child: %s", strerror(errno)); goto cleanup; &#125; //写入重写过程中产生的diffs if (aofRewriteBufferWrite(newfd) == -1) &#123; serverLog(LL_WARNING, "Error trying to flush the parent diff to the rewritten AOF: %s", strerror(errno)); close(newfd); goto cleanup; &#125; latencyEndMonitor(latency); latencyAddSampleIfNeeded("aof-rewrite-diff-write",latency); serverLog(LL_NOTICE, "Residual parent diff successfully flushed to the rewritten AOF (%.2f MB)", (double) aofRewriteBufferSize() / (1024*1024)); /* The only remaining thing to do is to rename the temporary file to * the configured file and switch the file descriptor used to do AOF * writes. We don't want close(2) or rename(2) calls to block the * server on old file deletion. * * There are two possible scenarios: * * 1) AOF is DISABLED and this was a one time rewrite. The temporary * file will be renamed to the configured file. When this file already * exists, it will be unlinked, which may block the server. * * 2) AOF is ENABLED and the rewritten AOF will immediately start * receiving writes. After the temporary file is renamed to the * configured file, the original AOF file descriptor will be closed. * Since this will be the last reference to that file, closing it * causes the underlying file to be unlinked, which may block the * server. * * To mitigate the blocking effect of the unlink operation (either * caused by rename(2) in scenario 1, or by close(2) in scenario 2), we * use a background thread to take care of this. First, we * make scenario 1 identical to scenario 2 by opening the target file * when it exists. The unlink operation after the rename(2) will then * be executed upon calling close(2) for its descriptor. Everything to * guarantee atomicity for this switch has already happened by then, so * we don't care what the outcome or duration of that close operation * is, as long as the file descriptor is released again. */ if (server.aof_fd == -1) &#123; /* AOF disabled */ /* Don't care if this fails: oldfd will be -1 and we handle that. * One notable case of -1 return is if the old file does * not exist. */ oldfd = open(server.aof_filename,O_RDONLY|O_NONBLOCK); &#125; else &#123; /* AOF enabled */ oldfd = -1; /* We'll set this to the current AOF filedes later. */ &#125; /* Rename the temporary file. This will not unlink the target file if * it exists, because we reference it with "oldfd". */ latencyStartMonitor(latency); //重命名临时文件 if (rename(tmpfile,server.aof_filename) == -1) &#123; serverLog(LL_WARNING, "Error trying to rename the temporary AOF file %s into %s: %s", tmpfile, server.aof_filename, strerror(errno)); close(newfd); if (oldfd != -1) close(oldfd); goto cleanup; &#125; latencyEndMonitor(latency); latencyAddSampleIfNeeded("aof-rename",latency); if (server.aof_fd == -1) &#123; /* AOF disabled, we don't need to set the AOF file descriptor * to this new file, so we can close it. */ //aof关闭不要对aof_fd赋值 close(newfd); &#125; else &#123; /* AOF enabled, replace the old fd with the new one. */ //用新的aof文件fd代替旧的 oldfd = server.aof_fd; server.aof_fd = newfd; //修改之后做一次同步操作 if (server.aof_fsync == AOF_FSYNC_ALWAYS) aof_fsync(newfd); else if (server.aof_fsync == AOF_FSYNC_EVERYSEC) aof_background_fsync(newfd); server.aof_selected_db = -1; /* Make sure SELECT is re-issued */ aofUpdateCurrentSize(); server.aof_rewrite_base_size = server.aof_current_size; /* Clear regular AOF buffer since its contents was just written to * the new AOF from the background rewrite buffer. */ sdsfree(server.aof_buf); server.aof_buf = sdsempty(); &#125; server.aof_lastbgrewrite_status = C_OK; serverLog(LL_NOTICE, "Background AOF rewrite finished successfully"); /* Change state from WAIT_REWRITE to ON if needed */ if (server.aof_state == AOF_WAIT_REWRITE) server.aof_state = AOF_ON; /* Asynchronously close the overwritten AOF. */ //异步删除旧的aof文件 if (oldfd != -1) bioCreateBackgroundJob(BIO_CLOSE_FILE,(void*)(long)oldfd,NULL,NULL); serverLog(LL_VERBOSE, "Background AOF rewrite signal handler took %lldus", ustime()-now); &#125; else if (!bysignal &amp;&amp; exitcode != 0) &#123; /* SIGUSR1 is whitelisted, so we have a way to kill a child without * tirggering an error conditon. */ if (bysignal != SIGUSR1) server.aof_lastbgrewrite_status = C_ERR; serverLog(LL_WARNING, "Background AOF rewrite terminated with error"); &#125; else &#123; server.aof_lastbgrewrite_status = C_ERR; serverLog(LL_WARNING, "Background AOF rewrite terminated by signal %d", bysignal); &#125;cleanup: aofClosePipes(); aofRewriteBufferReset(); aofRemoveTempFile(server.aof_child_pid); server.aof_child_pid = -1; server.aof_rewrite_time_last = time(NULL)-server.aof_rewrite_time_start; server.aof_rewrite_time_start = -1; /* Schedule a new rewrite if we are waiting for it to switch the AOF ON. */ if (server.aof_state == AOF_WAIT_REWRITE) server.aof_rewrite_scheduled = 1;&#125; aof文件载入aof文件载入发生在系统启动时，由于在redis中执行命令都需要一个client，所以创建一个伪客户端用来执行aof文件中的指令，以恢复数据库状态。下面是相关函数的注解：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197//重载aof文件恢复数据库状态， 成功时返回C_OK，没有致命错误的情况下返回C_ERR，在致命错误发生时打印错误信息并退出程序int loadAppendOnlyFile(char *filename) &#123; struct client *fakeClient; FILE *fp = fopen(filename,"r");//打开aof文件 struct redis_stat sb; int old_aof_state = server.aof_state; long loops = 0; off_t valid_up_to = 0; /* Offset of latest well-formed command loaded. */ if (fp == NULL) &#123; //不能打开aof文件 直接退出程序 serverLog(LL_WARNING,"Fatal error: can't open the append log file for reading: %s",strerror(errno)); exit(1); &#125; /* Handle a zero-length AOF file as a special case. An emtpy AOF file * is a valid AOF because an empty server with AOF enabled will create * a zero length file at startup, that will remain like that if no write * operation is received. */ //处理一个空aof文件的特殊情况，这种情况在一个空服务器开启aof启动后生成一个aof空文件，之后在没有写入的情况下保持为空 if (fp &amp;&amp; redis_fstat(fileno(fp),&amp;sb) != -1 &amp;&amp; sb.st_size == 0) &#123; //更新aof文件的size 关闭文件并返回 server.aof_current_size = 0; fclose(fp); return C_ERR; &#125; /* Temporarily disable AOF, to prevent EXEC from feeding a MULTI * to the same file we're about to read. */ //暂时关闭aof功能 防止脚本操作读取我们将要读的文件 server.aof_state = AOF_OFF; fakeClient = createFakeClient();//创建虚拟客户端 startLoading(fp);//开始loading /* Check if this AOF file has an RDB preamble. In that case we need to * load the RDB file and later continue loading the AOF tail. */ //检测是否有一个混合持久化措施，存在的话就需要先载入rdb数据再载入尾部的aof数据 char sig[5]; /* "REDIS" */ if (fread(sig,1,5,fp) != 5 || memcmp(sig,"REDIS",5) != 0) &#123; //不存在混合持久化 将文件指针移回原位 /* No RDB preamble, seek back at 0 offset. */ if (fseek(fp,0,SEEK_SET) == -1) goto readerr; &#125; else &#123; //进行rdb载入 /* RDB preamble. Pass loading the RDB functions. */ rio rdb; serverLog(LL_NOTICE,"Reading RDB preamble from AOF file..."); if (fseek(fp,0,SEEK_SET) == -1) goto readerr; rioInitWithFile(&amp;rdb,fp); //初始化rio对象，开始载入 if (rdbLoadRio(&amp;rdb,NULL) != C_OK) &#123; serverLog(LL_WARNING,"Error reading the RDB preamble of the AOF file, AOF loading aborted"); goto readerr; &#125; else &#123; serverLog(LL_NOTICE,"Reading the remaining AOF tail..."); &#125; &#125; /* Read the actual AOF file, in REPL format, command by command. */ //读取aof文件中的指令以repl的形式执行 while(1) &#123; int argc, j; unsigned long len; robj **argv; char buf[128]; sds argsds; struct redisCommand *cmd; /* Serve the clients from time to time */ //每隔1000个指令调用一次更新一些全局变量 if (!(loops++ % 1000)) &#123; loadingProgress(ftello(fp)); processEventsWhileBlocked(); &#125; //下面是读取aof文件 解析指令并执行了 if (fgets(buf,sizeof(buf),fp) == NULL) &#123; if (feof(fp)) break; else goto readerr; &#125; if (buf[0] != '*') goto fmterr; if (buf[1] == '\0') goto readerr; argc = atoi(buf+1); if (argc &lt; 1) goto fmterr; argv = zmalloc(sizeof(robj*)*argc); fakeClient-&gt;argc = argc; fakeClient-&gt;argv = argv; for (j = 0; j &lt; argc; j++) &#123; //在遇到一个aof文件错误时就退出并且记录下错误的位置，方便有效释放之前参数的空间 if (fgets(buf,sizeof(buf),fp) == NULL) &#123; fakeClient-&gt;argc = j; /* Free up to j-1. */ freeFakeClientArgv(fakeClient); goto readerr; &#125; if (buf[0] != '$') goto fmterr; len = strtol(buf+1,NULL,10); argsds = sdsnewlen(NULL,len); if (len &amp;&amp; fread(argsds,len,1,fp) == 0) &#123; sdsfree(argsds); fakeClient-&gt;argc = j; /* Free up to j-1. */ freeFakeClientArgv(fakeClient); goto readerr; &#125; //设置第j个指令参数 argv[j] = createObject(OBJ_STRING,argsds); if (fread(buf,2,1,fp) == 0) &#123; fakeClient-&gt;argc = j+1; /* Free up to j. */ freeFakeClientArgv(fakeClient); goto readerr; /* discard CRLF */ &#125; &#125; /* Command lookup */ //查询指令 cmd = lookupCommand(argv[0]-&gt;ptr); if (!cmd) &#123; serverLog(LL_WARNING,"Unknown command '%s' reading the append only file", (char*)argv[0]-&gt;ptr); exit(1); &#125; /* Run the command in the context of a fake client */ fakeClient-&gt;cmd = cmd; //执行指令 cmd-&gt;proc(fakeClient); /* The fake client should not have a reply */ serverAssert(fakeClient-&gt;bufpos == 0 &amp;&amp; listLength(fakeClient-&gt;reply) == 0); /* The fake client should never get blocked */ serverAssert((fakeClient-&gt;flags &amp; CLIENT_BLOCKED) == 0); /* Clean up. Command code may have changed argv/argc so we use the * argv/argc of the client instead of the local variables. */ //释放此条指令的参数空间 重置虚拟客户端参数 freeFakeClientArgv(fakeClient); fakeClient-&gt;cmd = NULL; if (server.aof_load_truncated) valid_up_to = ftello(fp);//记录下aof文件的偏移量 &#125; /* This point can only be reached when EOF is reached without errors. * If the client is in the middle of a MULTI/EXEC, log error and quit. */ if (fakeClient-&gt;flags &amp; CLIENT_MULTI) goto uxeof;loaded_ok: /* DB loaded, cleanup and return C_OK to the caller. */ fclose(fp); freeFakeClient(fakeClient); server.aof_state = old_aof_state; stopLoading(); aofUpdateCurrentSize(); server.aof_rewrite_base_size = server.aof_current_size; return C_OK;readerr: /* Read error. If feof(fp) is true, fall through to unexpected EOF. */ if (!feof(fp)) &#123; if (fakeClient) freeFakeClient(fakeClient); /* avoid valgrind warning */ serverLog(LL_WARNING,"Unrecoverable error reading the append only file: %s", strerror(errno)); exit(1); &#125;uxeof: /* Unexpected AOF end of file. *///遇到不可期望的错误时，检查aof文件的偏移量正常，并且已经到达文件尾部那么载入正常 if (server.aof_load_truncated) &#123; serverLog(LL_WARNING,"!!! Warning: short read while loading the AOF file !!!"); serverLog(LL_WARNING,"!!! Truncating the AOF at offset %llu !!!", (unsigned long long) valid_up_to); if (valid_up_to == -1 || truncate(filename,valid_up_to) == -1) &#123; if (valid_up_to == -1) &#123; serverLog(LL_WARNING,"Last valid command offset is invalid"); &#125; else &#123; serverLog(LL_WARNING,"Error truncating the AOF file: %s", strerror(errno)); &#125; &#125; else &#123; /* Make sure the AOF file descriptor points to the end of the * file after the truncate call. */ if (server.aof_fd != -1 &amp;&amp; lseek(server.aof_fd,0,SEEK_END) == -1) &#123; serverLog(LL_WARNING,"Can't seek the end of the AOF file: %s", strerror(errno)); &#125; else &#123; serverLog(LL_WARNING, "AOF loaded anyway because aof-load-truncated is enabled"); goto loaded_ok; &#125; &#125; &#125; if (fakeClient) freeFakeClient(fakeClient); /* avoid valgrind warning */ serverLog(LL_WARNING,"Unexpected end of file reading the append only file. You can: 1) Make a backup of your AOF file, then use ./redis-check-aof --fix &lt;filename&gt;. 2) Alternatively you can set the 'aof-load-truncated' configuration option to yes and restart the server."); exit(1);fmterr: /* Format error. */ if (fakeClient) freeFakeClient(fakeClient); /* avoid valgrind warning */ serverLog(LL_WARNING,"Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix &lt;filename&gt;"); exit(1);&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(16)——rdb篇]]></title>
    <url>%2F2017%2F10%2F11%2Fredis%E6%BA%90%E7%A0%81-16-%E2%80%94%E2%80%94rdb%E7%AF%87%2F</url>
    <content type="text"><![CDATA[redis对内存中数据持久化手段之一rdb，即对数据库当前的存储状态进行快照存储，它的优点是存储的二进制数据量比较少相较于后面的aof，启动加载速度快，缺点就是对状态的存储使得数据备份的粒度变大，与之相比较aof对每一条指令都进行存储，粒度明显变小，并且存在fork操作，开销太大。redis分为手动以及自动两种方式，指令为save以及bgsave，save手动调用开启rdb备份，停止其他指令的响应，bgsave按照一定的条件进行调用，条件符合时开启子进程进行rdb，并且继续响应其他请求。条件如下在config文件中可以自己修改或用值指令修改save 900 1 //服务器在900秒之内，对数据库执行了至少1次修改save 300 10 //服务器在300秒之内，对数据库执行了至少10修改save 60 1000 //服务器在60秒之内，对数据库执行了至少1000修改下面是bgsave指令的流程图之前都是按照函数从底层源码，这一次rdb中大都是底层的各种类型数据的save以及load操作，按照指定版本的rdb文件写文件，这不是我们的中我们通过从指令阅读，在逐个解析其中的函数，这样自顶向下，有利于我们了解rdb的实现过程，这很重要。所以先阅读save以及bgsave指令的实现。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 手动save，停止所有request，直到rdb完成void saveCommand(client *c) &#123; //如果已经在进行rdb则拒绝指令 if (server.rdb_child_pid != -1) &#123; addReplyError(c,"Background save already in progress"); return; &#125; //将快照保存的制定文件 if (rdbSave(server.rdb_filename,NULL) == C_OK) &#123; addReply(c,shared.ok); &#125; else &#123; addReply(c,shared.err); &#125;&#125;/* BGSAVE [SCHEDULE] */// 手动bgsave 后台保存，继续相应request// SCHEDULE 表示当aof正在进行时，将此rdb提上日程void bgsaveCommand(client *c) &#123; int schedule = 0; //检查指令格式，记录是否有schedule的option，用来改变aof后的rdb行为 if (c-&gt;argc &gt; 1) &#123; if (c-&gt;argc == 2 &amp;&amp; !strcasecmp(c-&gt;argv[1]-&gt;ptr,"schedule")) &#123; schedule = 1; &#125; else &#123; addReply(c,shared.syntaxerr); return; &#125; &#125; //如果已经在进行rdb则拒绝指令 if (server.rdb_child_pid != -1) &#123; addReplyError(c,"Background save already in progress"); &#125; else if (server.aof_child_pid != -1) &#123; //如果正在进行aof进程，并且有schedule的option，修改server中的rdb_bgsave_scheduled值，将rdb提上日程 if (schedule) &#123; server.rdb_bgsave_scheduled = 1; addReplyStatus(c,"Background saving scheduled"); &#125; else &#123; addReplyError(c, "An AOF log rewriting in progress: can't BGSAVE right now. " "Use BGSAVE SCHEDULE in order to schedule a BGSAVE whenever " "possible."); &#125; &#125; else if (rdbSaveBackground(server.rdb_filename,NULL) == C_OK) &#123; //后台执行rdb保存进程 addReplyStatus(c,"Background saving started"); &#125; else &#123; addReply(c,shared.err); &#125;&#125; 下面我们主要查看的就是rdbSave以及rdbSaveBackground这两个函数了，分别是在当前进程rdb保存以及创建子进程rdb保存，在介绍上面的函数之前我们要了解一些关于数据库对rdb的全局变量保存在redisServer数据结构中。123456789101112131415161718192021struct redisServer &#123; /* RDB persistence */ long long dirty; /* Changes to DB from the last save 最后一次save后数据库的修改次数*/ long long dirty_before_bgsave; /* Used to restore dirty on failed BGSAVE bgsave失败时记录dirty*/ pid_t rdb_child_pid; /* PID of RDB saving child rdb子进程的pid*/ struct saveparam *saveparams; /* Save points array for RDB rdb触发条件的记录结构*/ int saveparamslen; /* Number of saving points 触发条件数目*/ char *rdb_filename; /* Name of RDB file rdb文件名*/ int rdb_compression; /* Use compression in RDB? 是否使用压缩*/ int rdb_checksum; /* Use RDB checksum? 是否使用校验码*/ time_t lastsave; /* Unix time of last successful save 最后一次成功save时间*/ time_t lastbgsave_try; /* Unix time of last attempted bgsave 最后一次尝试bgsave时间*/ time_t rdb_save_time_last; /* Time used by last RDB save run. 最后一次rdbsave所用的时间*/ time_t rdb_save_time_start; /* Current RDB save start time. 当前rdb开始的时间*/ int rdb_bgsave_scheduled; /* BGSAVE when possible if true. bgsave提上日程*/ int rdb_child_type; /* Type of save by active child. 子进程类型*/ int lastbgsave_status; /* C_OK or C_ERR 最后一次bgsave状态*/ int stop_writes_on_bgsave_err; /* Don't allow writes if can't BGSAVE 如果不能bgsave不允许写*/ int rdb_pipe_write_result_to_parent; /* RDB pipes used to return the state rdb管道写端用来返回save状态*/ int rdb_pipe_read_result_from_child; /* of each slave in diskless SYNC. rdb管道读端*/ &#125; 下面是rdbSave以及rdbSaveBackground这两个函数的实现,先看rdbSaveBackground，因为在其中调用了rdbSave：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127// 后台rdb保存快照int rdbSaveBackground(char *filename, rdbSaveInfo *rsi) &#123; pid_t childpid; long long start; // 如果有rdb或者aof子进程在运行，return错误 if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) return C_ERR; // 记录相关的bgsave数据 server.dirty_before_bgsave = server.dirty; server.lastbgsave_try = time(NULL); openChildInfoPipe();//打开子进程消息管道 start = ustime();//记录开始时间 // 开启rdb子进程 if ((childpid = fork()) == 0) &#123; int retval; /* Child */ // 关闭套接字监听 closeListeningSockets(0); // 设置进程标题 redisSetProcTitle("redis-rdb-bgsave"); // 保存当前快照 retval = rdbSave(filename,rsi); if (retval == C_OK) &#123; size_t private_dirty = zmalloc_get_private_dirty(-1);//获取私有的脏数据 if (private_dirty) &#123; serverLog(LL_NOTICE, "RDB: %zu MB of memory used by copy-on-write", private_dirty/(1024*1024)); &#125; server.child_info_data.cow_size = private_dirty; sendChildInfo(CHILD_INFO_TYPE_RDB);//数据发送给父进程 &#125; // 从子进程退出 exitFromChild((retval == C_OK) ? 0 : 1); &#125; else &#123; /* Parent */ // 父进程记录fork时间点，时间间隔 server.stat_fork_time = ustime()-start; server.stat_fork_rate = (double) zmalloc_used_memory() * 1000000 / server.stat_fork_time / (1024*1024*1024); /* GB per second. */ latencyAddSampleIfNeeded("fork",server.stat_fork_time/1000);//在需要的情况下记录事件的延迟 // 子进程创建失败 if (childpid == -1) &#123; closeChildInfoPipe(); server.lastbgsave_status = C_ERR; serverLog(LL_WARNING,"Can't save in background: fork: %s", strerror(errno)); return C_ERR; &#125; serverLog(LL_NOTICE,"Background saving started by pid %d",childpid); server.rdb_save_time_start = time(NULL); server.rdb_child_pid = childpid; server.rdb_child_type = RDB_CHILD_TYPE_DISK; // 开启dict resize功能 updateDictResizePolicy(); return C_OK; &#125; return C_OK; /* unreached */&#125;// 对db状态进行快照，将文件存到disk上int rdbSave(char *filename, rdbSaveInfo *rsi) &#123; char tmpfile[256]; char cwd[MAXPATHLEN]; /* Current working dir path for error messages. */ FILE *fp; rio rdb; int error = 0; // 创建临时文件 snprintf(tmpfile,256,"temp-%d.rdb", (int) getpid()); fp = fopen(tmpfile,"w"); if (!fp) &#123; // 文件创建失败 char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, "Failed opening the RDB file %s (in server root dir %s) " "for saving: %s", filename, cwdp ? cwdp : "unknown", strerror(errno)); return C_ERR; &#125; // 初始化rio，用来往文件中写数据的工具数据结构 rioInitWithFile(&amp;rdb,fp); // 保存数据库快照到文件 if (rdbSaveRio(&amp;rdb,&amp;error,RDB_SAVE_NONE,rsi) == C_ERR) &#123; errno = error; goto werr; &#125; /* Make sure data will not remain on the OS's output buffers */ // 刷新文件流的缓冲区，确保没有数据在缓冲区中 if (fflush(fp) == EOF) goto werr; if (fsync(fileno(fp)) == -1) goto werr; if (fclose(fp) == EOF) goto werr; /* Use RENAME to make sure the DB file is changed atomically only * if the generate DB file is ok. */ // rdb快照完成，修改临时文件的名称 if (rename(tmpfile,filename) == -1) &#123; char *cwdp = getcwd(cwd,MAXPATHLEN); serverLog(LL_WARNING, "Error moving temp DB file %s on the final " "destination %s (in server root dir %s): %s", tmpfile, filename, cwdp ? cwdp : "unknown", strerror(errno)); unlink(tmpfile); return C_ERR; &#125; // 系统日志 serverLog(LL_NOTICE,"DB saved on disk"); // 更新服务器的相关属性，修改数据次数置0，保存最后save保存以及保存状态 server.dirty = 0; server.lastsave = time(NULL); server.lastbgsave_status = C_OK; return C_OK;werr: serverLog(LL_WARNING,"Write error saving DB on disk: %s", strerror(errno)); fclose(fp); unlink(tmpfile); return C_ERR;&#125; 在了解了前台以及后台rdb操作的逻辑之后我们可以来查看rdbSaveRio函数，看看服务器的快照是如何存储在一个文件中的：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788// 产生一个数据库的rdb格式镜像发送到指定的io频道，返回C_OK，否则返回错误，部分或所有的输出可能丢失因为io错误// 当返回错误，如果error不为空，error被设置为错误的代码int rdbSaveRio(rio *rdb, int *error, int flags, rdbSaveInfo *rsi) &#123; dictIterator *di = NULL; dictEntry *de; char magic[10]; int j; long long now = mstime(); uint64_t cksum; size_t processed = 0; if (server.rdb_checksum) // 如果服务器要求检查rdb写入总和，设置更新函数 rdb-&gt;update_cksum = rioGenericUpdateChecksum; snprintf(magic,sizeof(magic),"REDIS%04d",RDB_VERSION); // 写入rdb格式版本 if (rdbWriteRaw(rdb,magic,9) == -1) goto werr; // 写入flags以及rdbSaveInfo相关保存信息 if (rdbSaveInfoAuxFields(rdb,flags,rsi) == -1) goto werr; // 保存每个数据库的快照 for (j = 0; j &lt; server.dbnum; j++) &#123; redisDb *db = server.db+j; dict *d = db-&gt;dict; if (dictSize(d) == 0) continue; di = dictGetSafeIterator(d); if (!di) return C_ERR; /* Write the SELECT DB opcode */ // 写入选择数据库指令 if (rdbSaveType(rdb,RDB_OPCODE_SELECTDB) == -1) goto werr; // 写入数据库id if (rdbSaveLen(rdb,j) == -1) goto werr; // 写入db resize指令，最大为UINT32_MAX，但这不影响实际可以插入的数目，应为dict可以expand uint32_t db_size, expires_size; db_size = (dictSize(db-&gt;dict) &lt;= UINT32_MAX) ? dictSize(db-&gt;dict) : UINT32_MAX; expires_size = (dictSize(db-&gt;expires) &lt;= UINT32_MAX) ? dictSize(db-&gt;expires) : UINT32_MAX; if (rdbSaveType(rdb,RDB_OPCODE_RESIZEDB) == -1) goto werr; if (rdbSaveLen(rdb,db_size) == -1) goto werr; if (rdbSaveLen(rdb,expires_size) == -1) goto werr; /* Iterate this DB writing every entry */ // 迭代数据库，写入每一个键值对 while((de = dictNext(di)) != NULL) &#123; sds keystr = dictGetKey(de); robj key, *o = dictGetVal(de); long long expire; // 用sds初始化一个robj对象 initStaticStringObject(key,keystr); expire = getExpire(db,&amp;key); // 写入键值对 if (rdbSaveKeyValuePair(rdb,&amp;key,o,expire,now) == -1) goto werr; /* When this RDB is produced as part of an AOF rewrite, move * accumulated diff from parent to child while rewriting in * order to have a smaller final write. */ if (flags &amp; RDB_SAVE_AOF_PREAMBLE &amp;&amp; rdb-&gt;processed_bytes &gt; processed+AOF_READ_DIFF_INTERVAL_BYTES) &#123; processed = rdb-&gt;processed_bytes; aofReadDiffFromParent(); &#125; &#125; dictReleaseIterator(di); &#125; di = NULL; /* So that we don't release it again on error. */ /* EOF opcode */ // 写入eof符号 if (rdbSaveType(rdb,RDB_OPCODE_EOF) == -1) goto werr; /* CRC64 checksum. It will be zero if checksum computation is disabled, the * loading code skips the check in this case. */ cksum = rdb-&gt;cksum; memrev64ifbe(&amp;cksum); // 写入cksum if (rioWrite(rdb,&amp;cksum,8) == 0) goto werr; return C_OK;werr: if (error) *error = errno; if (di) dictReleaseIterator(di); return C_ERR;&#125; 上面函数的实现中又很多写入函数如rdbSaveKeyValuePair，rdbSaveType，rdbSaveLen等，这些函数按照一定的格式将数据写入到rdb文件中，对于不同的对象不同的底层实现有不同的存储方式，在load时按照save的格式进行载入，此外还有一些特别的字符以及信息写入，具体可以参考：《redis设计与实现》的rdb篇中的解释，这里就不在解释了。下面是rdb的载入过程，在系统启动时aof处于关闭状态，那么系统就会默认rdb文件加载redis的状态，主要的函数是rdbLoad：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206//加载rdb文件恢复数据库状态int rdbLoad(char *filename, rdbSaveInfo *rsi) &#123; FILE *fp; rio rdb; int retval; //打开rdb文件 if ((fp = fopen(filename,"r")) == NULL) return C_ERR; startLoading(fp);//设置参数标记正在载入 rioInitWithFile(&amp;rdb,fp);//初始化rio，读取rdb文件数据 retval = rdbLoadRio(&amp;rdb,rsi);//载入数据 fclose(fp); stopLoading();//停止载入 return retval;&#125;//设置正在进行载入以及相关的全局参数void startLoading(FILE *fp) &#123; struct stat sb; /* Load the DB */ server.loading = 1; server.loading_start_time = time(NULL); server.loading_loaded_bytes = 0; if (fstat(fileno(fp), &amp;sb) == -1) &#123; server.loading_total_bytes = 0; &#125; else &#123; server.loading_total_bytes = sb.st_size; &#125;&#125;void stopLoading(void) &#123; server.loading = 0;&#125;/* Load an RDB file from the rio stream 'rdb'. On success C_OK is returned, * otherwise C_ERR is returned and 'errno' is set accordingly. *///读取rdb文件恢复redis的状态成功返回C_OK，否则返回C_ERR，errno设置为错误标号int rdbLoadRio(rio *rdb, rdbSaveInfo *rsi) &#123; uint64_t dbid; int type, rdbver; redisDb *db = server.db+0; char buf[1024]; long long expiretime, now = mstime(); //设置cksum跟新函数以及最大处理数据字节数 rdb-&gt;update_cksum = rdbLoadProgressCallback; rdb-&gt;max_processing_chunk = server.loading_process_events_interval_bytes; //读取redis版本 if (rioRead(rdb,buf,9) == 0) goto eoferr; buf[9] = '\0'; if (memcmp(buf,"REDIS",5) != 0) &#123; serverLog(LL_WARNING,"Wrong signature trying to load DB from file"); errno = EINVAL; return C_ERR; &#125; rdbver = atoi(buf+5); //检查版本信息 if (rdbver &lt; 1 || rdbver &gt; RDB_VERSION) &#123; serverLog(LL_WARNING,"Can't handle RDB format version %d",rdbver); errno = EINVAL; return C_ERR; &#125; while(1) &#123; robj *key, *val; expiretime = -1; /* Read type. */ //读取type if ((type = rdbLoadType(rdb)) == -1) goto eoferr; /* Handle special types. */ //解决特殊的types if (type == RDB_OPCODE_EXPIRETIME) &#123; //读取过期时间的type /* EXPIRETIME: load an expire associated with the next key * to load. Note that after loading an expire we need to * load the actual type, and continue. */ if ((expiretime = rdbLoadTime(rdb)) == -1) goto eoferr; /* We read the time so we need to read the object type again. */ if ((type = rdbLoadType(rdb)) == -1) goto eoferr; /* the EXPIRETIME opcode specifies time in seconds, so convert * into milliseconds. */ expiretime *= 1000; &#125; else if (type == RDB_OPCODE_EXPIRETIME_MS) &#123; /* EXPIRETIME_MS: milliseconds precision expire times introduced * with RDB v3. Like EXPIRETIME but no with more precision. */ if ((expiretime = rdbLoadMillisecondTime(rdb)) == -1) goto eoferr; /* We read the time so we need to read the object type again. */ if ((type = rdbLoadType(rdb)) == -1) goto eoferr; &#125; else if (type == RDB_OPCODE_EOF) &#123; //读取eof后退出循环 /* EOF: End of file, exit the main loop. */ break; &#125; else if (type == RDB_OPCODE_SELECTDB) &#123; //读取选取数据库的type，读取相应参数，选择数据库 /* SELECTDB: Select the specified database. */ //读取数据库id if ((dbid = rdbLoadLen(rdb,NULL)) == RDB_LENERR) goto eoferr; if (dbid &gt;= (unsigned)server.dbnum) &#123; serverLog(LL_WARNING, "FATAL: Data file was created with a Redis " "server configured to handle more than %d " "databases. Exiting\n", server.dbnum); exit(1); &#125; db = server.db+dbid; continue; /* Read type again. */ &#125; else if (type == RDB_OPCODE_RESIZEDB) &#123; /* RESIZEDB: Hint about the size of the keys in the currently * selected data base, in order to avoid useless rehashing. */ //读取RDB_OPCODE_RESIZEDB的type，再读取字典大小以及期限字典size，并扩展字典的大小 uint64_t db_size, expires_size; if ((db_size = rdbLoadLen(rdb,NULL)) == RDB_LENERR) goto eoferr; if ((expires_size = rdbLoadLen(rdb,NULL)) == RDB_LENERR) goto eoferr; dictExpand(db-&gt;dict,db_size); dictExpand(db-&gt;expires,expires_size); continue; /* Read type again. */ &#125; else if (type == RDB_OPCODE_AUX) &#123; /* AUX: generic string-string fields. Use to add state to RDB * which is backward compatible. Implementations of RDB loading * are requierd to skip AUX fields they don't understand. * * An AUX field is composed of two strings: key and value. */ // 读取RDB_OPCODE_AUX的type，继续读取相应的参数，并且将参数写入到rsi中 robj *auxkey, *auxval; if ((auxkey = rdbLoadStringObject(rdb)) == NULL) goto eoferr; if ((auxval = rdbLoadStringObject(rdb)) == NULL) goto eoferr; if (((char*)auxkey-&gt;ptr)[0] == '%') &#123; /* All the fields with a name staring with '%' are considered * information fields and are logged at startup with a log * level of NOTICE. */ serverLog(LL_NOTICE,"RDB '%s': %s", (char*)auxkey-&gt;ptr, (char*)auxval-&gt;ptr); &#125; else if (!strcasecmp(auxkey-&gt;ptr,"repl-stream-db")) &#123; if (rsi) rsi-&gt;repl_stream_db = atoi(auxval-&gt;ptr); &#125; else if (!strcasecmp(auxkey-&gt;ptr,"repl-id")) &#123; if (rsi &amp;&amp; sdslen(auxval-&gt;ptr) == CONFIG_RUN_ID_SIZE) &#123; memcpy(rsi-&gt;repl_id,auxval-&gt;ptr,CONFIG_RUN_ID_SIZE+1); rsi-&gt;repl_id_is_set = 1; &#125; &#125; else if (!strcasecmp(auxkey-&gt;ptr,"repl-offset")) &#123; if (rsi) rsi-&gt;repl_offset = strtoll(auxval-&gt;ptr,NULL,10); &#125; else &#123; /* We ignore fields we don't understand, as by AUX field * contract. */ serverLog(LL_DEBUG,"Unrecognized RDB AUX field: '%s'", (char*)auxkey-&gt;ptr); &#125; decrRefCount(auxkey); decrRefCount(auxval); continue; /* Read type again. */ &#125; /* Read key */ //读取key if ((key = rdbLoadStringObject(rdb)) == NULL) goto eoferr; /* Read value */ //读取value数据对象，在知道类型的情况下，按照不同的存储格式读取 if ((val = rdbLoadObject(type,rdb)) == NULL) goto eoferr; /* Check if the key already expired. This function is used when loading * an RDB file from disk, either at startup, or when an RDB was * received from the master. In the latter case, the master is * responsible for key expiry. If we would expire keys here, the * snapshot taken by the master may not be reflected on the slave. */ //如果是master主机，并且key已经过期，那么不添加到字典中 if (server.masterhost == NULL &amp;&amp; expiretime != -1 &amp;&amp; expiretime &lt; now) &#123; decrRefCount(key); decrRefCount(val); continue; &#125; /* Add the new object in the hash table */ //添加键值对到字典中 dbAdd(db,key,val); /* Set the expire time if needed */ //如果需要的话，设置键的过期时间 if (expiretime != -1) setExpire(NULL,db,key,expiretime); decrRefCount(key); &#125; /* Verify the checksum if RDB version is &gt;= 5 */ //读取尾部是的校验码 if (rdbver &gt;= 5 &amp;&amp; server.rdb_checksum) &#123; uint64_t cksum, expected = rdb-&gt;cksum; if (rioRead(rdb,&amp;cksum,8) == 0) goto eoferr; memrev64ifbe(&amp;cksum); if (cksum == 0) &#123; serverLog(LL_WARNING,"RDB file was saved with checksum disabled: no check performed."); &#125; else if (cksum != expected) &#123; serverLog(LL_WARNING,"Wrong RDB checksum. Aborting now."); //预期与实际不符合直接启动失败 rdbExitReportCorruptRDB("RDB CRC error"); &#125; &#125; return C_OK;eoferr: /* unexpected end of file is handled here with a fatal exit */ serverLog(LL_WARNING,"Short read or OOM loading DB. Unrecoverable error, aborting now."); rdbExitReportCorruptRDB("Unexpected EOF reading RDB file"); return C_ERR; /* Just to avoid warning */&#125; 至此关于rdb的载入以及保存的主要函数已经阅读完毕，其他关于不同格式的对象的rdb操作可以自行阅读注释，在最新的rdb中还有涉及集群的操作，在以后会讲解，谢谢。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(15)——rio篇]]></title>
    <url>%2F2017%2F10%2F05%2Fredis%E6%BA%90%E7%A0%81-15-%E2%80%94%E2%80%94rio%E7%AF%87%2F</url>
    <content type="text"><![CDATA[在介绍rdb以及aof这两种redis备份方式之前，我们先看一下rio这个源文件，这个文件主要针对缓冲区，文件流以及socket三种数据载体的io操作，通过redis的io数据结构rio可以屏蔽底层不同实现，实现数据的读写操作。为rdb以及aof中的快照文件加载写入，以及指令写入加载提供工具。先看rio.h,主要包括了rio数据结构的定义，以及不同载体的文件操作函数的定义，可以看出通过几个静态的函数，调用不同载体的io操作具体实现，来屏蔽不同载体的操作函数，用户只需要准备好初始化的参数即可，同时也实现了解耦，便于代码的修改以及模块添加。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130// redis抽象的io数据结构struct _rio &#123; /* Backend functions. * Since this functions do not tolerate short writes or reads the return * value is simplified to: zero on error, non zero on complete success. */ // 对于各种类型数据存储对象的读写移动指针以及刷新的函数指针 size_t (*read)(struct _rio *, void *buf, size_t len); size_t (*write)(struct _rio *, const void *buf, size_t len); off_t (*tell)(struct _rio *); int (*flush)(struct _rio *); /* The update_cksum method if not NULL is used to compute the checksum of * all the data that was read or written so far. The method should be * designed so that can be called with the current checksum, and the buf * and len fields pointing to the new block of data to add to the checksum * computation. */ // 如果这个方法不为空，用来计算所有被读写数据的checksum void (*update_cksum)(struct _rio *, const void *buf, size_t len); /* The current checksum */ // 当前的checksum uint64_t cksum; /* number of bytes read or written */ // 读或者写的数据的字节数 size_t processed_bytes; /* maximum single read or write chunk size */ // 单次最大读写的块大小 size_t max_processing_chunk; /* Backend-specific vars. */ // buffer file以及网络套接字的对象指针 union &#123; /* In-memory buffer target. */ struct &#123; sds ptr; off_t pos; &#125; buffer; /* Stdio file pointer target. */ struct &#123; FILE *fp; // 最后一次同步后写入的字节数 off_t buffered; /* Bytes written since last fsync. */ // 自动同步的字节数限制 off_t autosync; /* fsync after 'autosync' bytes written. */ &#125; file; /* Multiple FDs target (used to write to N sockets). */ struct &#123; // 文件描述符 int *fds; /* File descriptors. */ // 每一个文件的状态 int *state; /* Error state of each fd. 0 (if ok) or errno. */ // 描述符数目 int numfds; // 数据偏移 off_t pos; // 写入数据 sds buf; &#125; fdset; &#125; io;&#125;;typedef struct _rio rio;/* The following functions are our interface with the stream. They'll call the * actual implementation of read / write / tell, and will update the checksum * if needed. */// 实现对各种流的写数据功能，在需要时检查checksum，调用其相应载体具体的读写实现static inline size_t rioWrite(rio *r, const void *buf, size_t len) &#123; while (len) &#123; // 这一轮写入的数据长度 size_t bytes_to_write = (r-&gt;max_processing_chunk &amp;&amp; r-&gt;max_processing_chunk &lt; len) ? r-&gt;max_processing_chunk : len; // 如果需要检查cksum if (r-&gt;update_cksum) r-&gt;update_cksum(r,buf,bytes_to_write); // 写入数据 if (r-&gt;write(r,buf,bytes_to_write) == 0) return 0; // 修改数据指针 buf = (char*)buf + bytes_to_write; // 修改写入数据长度 len -= bytes_to_write; // 记录写入字节总数 r-&gt;processed_bytes += bytes_to_write; &#125; return 1;&#125;// 实现各种流的读数据功能static inline size_t rioRead(rio *r, void *buf, size_t len) &#123; while (len) &#123; // 这一轮读取数据长度 size_t bytes_to_read = (r-&gt;max_processing_chunk &amp;&amp; r-&gt;max_processing_chunk &lt; len) ? r-&gt;max_processing_chunk : len; if (r-&gt;read(r,buf,bytes_to_read) == 0) return 0; if (r-&gt;update_cksum) r-&gt;update_cksum(r,buf,bytes_to_read); // 跟新buf指针 buf = (char*)buf + bytes_to_read; len -= bytes_to_read; // 记录读取字节码长度 r-&gt;processed_bytes += bytes_to_read; &#125; return 1;&#125;// 实现各种流的获取当前指针功能static inline off_t rioTell(rio *r) &#123; return r-&gt;tell(r);&#125;// 实现各种流的刷新缓冲区功能static inline int rioFlush(rio *r) &#123; return r-&gt;flush(r);&#125;// 各种类型的数据载体的rio初始化void rioInitWithFile(rio *r, FILE *fp);void rioInitWithBuffer(rio *r, sds s);void rioInitWithFdset(rio *r, int *fds, int numfds);// fdset的rio资源释放void rioFreeFdset(rio *r);// 按照想要的格式写入数据到各种类型的数据载体中size_t rioWriteBulkCount(rio *r, char prefix, int count);size_t rioWriteBulkString(rio *r, const char *buf, size_t len);size_t rioWriteBulkLongLong(rio *r, long long l);size_t rioWriteBulkDouble(rio *r, double d);struct redisObject;// 写入一个字符串robj对象，不在rio中实现，因为需要server.hint rioWriteBulkObject(rio *r, struct redisObject *obj);// cknum的跟新函数void rioGenericUpdateChecksum(rio *r, const void *buf, size_t len);// 设置rio自动同步的字节数阈值void rioSetAutoSync(rio *r, off_t bytes); 下面是rio.c的代码注释,包含了不同载体的io操作的具体实现，通过三个静态的rio的实例表示三个不同载体的rio实例，拥有不同的io函数，用来初始化用户定义rio结构。对于文件流以及socket提供了刷新缓冲区的操作，通过也通过各自的阈值来判断是否自动刷新缓冲区。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325/* ------------------------- Buffer I/O implementation ----------------------- */// 对于buffer的io操作的具体实现/* Returns 1 or 0 for success/failure. */// buffer的数据写入操作static size_t rioBufferWrite(rio *r, const void *buf, size_t len) &#123; // 在buffer末尾加上写入数据 r-&gt;io.buffer.ptr = sdscatlen(r-&gt;io.buffer.ptr,(char*)buf,len); // 修改偏移量到buffer尾部 r-&gt;io.buffer.pos += len; return 1;&#125;/* Returns 1 or 0 for success/failure. */// buffer数据的读取操作static size_t rioBufferRead(rio *r, void *buf, size_t len) &#123; if (sdslen(r-&gt;io.buffer.ptr)-r-&gt;io.buffer.pos &lt; len) //如果偏移量后的数据长度小于len 则不够读返回0 return 0; /* not enough buffer to return len bytes. */ memcpy(buf,r-&gt;io.buffer.ptr+r-&gt;io.buffer.pos,len); // 修改pos后移len位 r-&gt;io.buffer.pos += len; return 1;&#125;/* Returns read/write position in buffer. */// buffer的返回当前的偏移量static off_t rioBufferTell(rio *r) &#123; return r-&gt;io.buffer.pos;&#125;/* Flushes any buffer to target device if applicable. Returns 1 on success * and 0 on failures. */// buffer的刷新缓冲区 其实什么都不要做static int rioBufferFlush(rio *r) &#123; UNUSED(r); return 1; /* Nothing to do, our write just appends to the buffer. */&#125;// buffer的rio实例static const rio rioBufferIO = &#123; rioBufferRead, rioBufferWrite, rioBufferTell, rioBufferFlush, NULL, /* update_checksum */ 0, /* current checksum */ 0, /* bytes read or written */ 0, /* read/write chunk size */ &#123; &#123; NULL, 0 &#125; &#125; /* union for io-specific vars */&#125;;// buffer的rio实例初始化void rioInitWithBuffer(rio *r, sds s) &#123; *r = rioBufferIO; r-&gt;io.buffer.ptr = s; r-&gt;io.buffer.pos = 0;&#125;/* --------------------- Stdio file pointer implementation ------------------- */// 对于文件流的io操作的具体实现/* Returns 1 or 0 for success/failure. */// 对文件流写入数据函数static size_t rioFileWrite(rio *r, const void *buf, size_t len) &#123; size_t retval; // 写入数据到缓冲区，记录缓冲区数据长度 retval = fwrite(buf,len,1,r-&gt;io.file.fp); r-&gt;io.file.buffered += len; // 如果自动同步，并且达到缓冲区达到同步范围 if (r-&gt;io.file.autosync &amp;&amp; r-&gt;io.file.buffered &gt;= r-&gt;io.file.autosync) &#123; // 刷新缓冲区，缓冲区长度置0，调用fflush刷新到内核缓冲区，调用aof_fsync刷新到disk fflush(r-&gt;io.file.fp); aof_fsync(fileno(r-&gt;io.file.fp)); r-&gt;io.file.buffered = 0; &#125; return retval;&#125;/* Returns 1 or 0 for success/failure. */// 对文件流的读数据static size_t rioFileRead(rio *r, void *buf, size_t len) &#123; return fread(buf,len,1,r-&gt;io.file.fp);&#125;/* Returns read/write position in file. */// 返回文件流的当前偏移量static off_t rioFileTell(rio *r) &#123; return ftello(r-&gt;io.file.fp);&#125;/* Flushes any buffer to target device if applicable. Returns 1 on success * and 0 on failures. */// 刷新文件流的数据缓冲区static int rioFileFlush(rio *r) &#123; return (fflush(r-&gt;io.file.fp) == 0) ? 1 : 0;&#125;// 文件流的rio实例static const rio rioFileIO = &#123; rioFileRead, rioFileWrite, rioFileTell, rioFileFlush, NULL, /* update_checksum */ 0, /* current checksum */ 0, /* bytes read or written */ 0, /* read/write chunk size */ &#123; &#123; NULL, 0 &#125; &#125; /* union for io-specific vars */&#125;;// 用文件流初始化rio void rioInitWithFile(rio *r, FILE *fp) &#123; *r = rioFileIO; // 初始化rio属性 r-&gt;io.file.fp = fp; r-&gt;io.file.buffered = 0; r-&gt;io.file.autosync = 0;&#125;/* ------------------- File descriptors set implementation ------------------- */// 对于文件描述符的io操作/* Returns 1 or 0 for success/failure. * The function returns success as long as we are able to correctly write * to at least one file descriptor. * * When buf is NULL and len is 0, the function performs a flush operation * if there is some pending buffer, so this function is also used in order * to implement rioFdsetFlush(). */// 文件描述符的写入数据操作，所有描述符都失败才返回0，如果buf是NULL并且len是0那么函数作用是刷新缓冲区static size_t rioFdsetWrite(rio *r, const void *buf, size_t len) &#123; ssize_t retval; int j; unsigned char *p = (unsigned char*) buf; // 判断是否是刷新操作 int doflush = (buf == NULL &amp;&amp; len == 0); /* To start we always append to our buffer. If it gets larger than * a given size, we actually write to the sockets. */ // 将需要写入的数据加入到数据缓冲区 if (len) &#123; r-&gt;io.fdset.buf = sdscatlen(r-&gt;io.fdset.buf,buf,len); len = 0; /* Prevent entering the while below if we don't flush. */ // 如果不刷新，不会进入下面的写数据循环 if (sdslen(r-&gt;io.fdset.buf) &gt; PROTO_IOBUF_LEN) doflush = 1; &#125; if (doflush) &#123; // 准备好写入的数据以及长度 p = (unsigned char*) r-&gt;io.fdset.buf; len = sdslen(r-&gt;io.fdset.buf); &#125; /* Write in little chunchs so that when there are big writes we * parallelize while the kernel is sending data in background to * the TCP socket. */ // 每次最多写入1024字节的数据，这样当写入很大的数据时，我们可以在后台并行处理 while(len) &#123; size_t count = len &lt; 1024 ? len : 1024; int broken = 0; // 循环写入每一个文件描述符 for (j = 0; j &lt; r-&gt;io.fdset.numfds; j++) &#123; if (r-&gt;io.fdset.state[j] != 0) &#123; /* Skip FDs alraedy in error. */ // 如果当前状态不为0 不写入直接跳过 broken++; continue; &#125; /* Make sure to write 'count' bytes to the socket regardless * of short writes. */ // 确保写入了count个字节的数据 size_t nwritten = 0; while(nwritten != count) &#123; // 写入数据 retval = write(r-&gt;io.fdset.fds[j],p+nwritten,count-nwritten); if (retval &lt;= 0) &#123; /* With blocking sockets, which is the sole user of this * rio target, EWOULDBLOCK is returned only because of * the SO_SNDTIMEO socket option, so we translate the error * into one more recognizable by the user. */ // 如果写入失败并且是阻塞错误 将errno=ETIMEDOUT if (retval == -1 &amp;&amp; errno == EWOULDBLOCK) errno = ETIMEDOUT; break; &#125; nwritten += retval; &#125; // 如果该描述符没有完全写入数据，标记该描述符状态为0 if (nwritten != count) &#123; /* Mark this FD as broken. */ r-&gt;io.fdset.state[j] = errno; if (r-&gt;io.fdset.state[j] == 0) r-&gt;io.fdset.state[j] = EIO; &#125; &#125; if (broken == r-&gt;io.fdset.numfds) return 0; /* All the FDs in error. */ p += count; len -= count; r-&gt;io.fdset.pos += count; &#125; // 如果flush需要将buf清空 if (doflush) sdsclear(r-&gt;io.fdset.buf); return 1;&#125;/* Returns 1 or 0 for success/failure. */// socket不支持读数据static size_t rioFdsetRead(rio *r, void *buf, size_t len) &#123; UNUSED(r); UNUSED(buf); UNUSED(len); return 0; /* Error, this target does not support reading. */&#125;/* Returns read/write position in file. */// 返回当前的文件偏移量static off_t rioFdsetTell(rio *r) &#123; return r-&gt;io.fdset.pos;&#125;/* Flushes any buffer to target device if applicable. Returns 1 on success * and 0 on failures. */// 刷新buf中数据static int rioFdsetFlush(rio *r) &#123; /* Our flush is implemented by the write method, that recognizes a * buffer set to NULL with a count of zero as a flush request. */ return rioFdsetWrite(r,NULL,0);&#125;// 描述符的rio实例static const rio rioFdsetIO = &#123; rioFdsetRead, rioFdsetWrite, rioFdsetTell, rioFdsetFlush, NULL, /* update_checksum */ 0, /* current checksum */ 0, /* bytes read or written */ 0, /* read/write chunk size */ &#123; &#123; NULL, 0 &#125; &#125; /* union for io-specific vars */&#125;;// 文件描述符rio对象初始化void rioInitWithFdset(rio *r, int *fds, int numfds) &#123; int j; *r = rioFdsetIO; r-&gt;io.fdset.fds = zmalloc(sizeof(int)*numfds); r-&gt;io.fdset.state = zmalloc(sizeof(int)*numfds); memcpy(r-&gt;io.fdset.fds,fds,sizeof(int)*numfds); for (j = 0; j &lt; numfds; j++) r-&gt;io.fdset.state[j] = 0; r-&gt;io.fdset.numfds = numfds; r-&gt;io.fdset.pos = 0; r-&gt;io.fdset.buf = sdsempty();&#125;/* release the rio stream. */// fdset资源释放void rioFreeFdset(rio *r) &#123; zfree(r-&gt;io.fdset.fds); zfree(r-&gt;io.fdset.state); sdsfree(r-&gt;io.fdset.buf);&#125;/* ---------------------------- Generic functions ---------------------------- *//* This function can be installed both in memory and file streams when checksum * computation is needed. */// 这个函数可以在内存或文件流中使用，当需要checksum时void rioGenericUpdateChecksum(rio *r, const void *buf, size_t len) &#123; r-&gt;cksum = crc64(r-&gt;cksum,buf,len);&#125;/* Set the file-based rio object to auto-fsync every 'bytes' file written. * By default this is set to zero that means no automatic file sync is * performed. * * This feature is useful in a few contexts since when we rely on OS write * buffers sometimes the OS buffers way too much, resulting in too many * disk I/O concentrated in very little time. When we fsync in an explicit * way instead the I/O pressure is more distributed across time. */void rioSetAutoSync(rio *r, off_t bytes) &#123; serverAssert(r-&gt;read == rioFileIO.read); r-&gt;io.file.autosync = bytes;&#125;/* --------------------------- Higher level interface -------------------------- * * The following higher level functions use lower level rio.c functions to help * generating the Redis protocol for the Append Only File. *//* Write multi bulk count in the format: "*&lt;count&gt;\r\n". */size_t rioWriteBulkCount(rio *r, char prefix, int count) &#123; char cbuf[128]; int clen; cbuf[0] = prefix; clen = 1+ll2string(cbuf+1,sizeof(cbuf)-1,count); cbuf[clen++] = '\r'; cbuf[clen++] = '\n'; if (rioWrite(r,cbuf,clen) == 0) return 0; return clen;&#125;/* Write binary-safe string in the format: "$&lt;count&gt;\r\n&lt;payload&gt;\r\n". */size_t rioWriteBulkString(rio *r, const char *buf, size_t len) &#123; size_t nwritten; if ((nwritten = rioWriteBulkCount(r,'$',len)) == 0) return 0; if (len &gt; 0 &amp;&amp; rioWrite(r,buf,len) == 0) return 0; if (rioWrite(r,"\r\n",2) == 0) return 0; return nwritten+len+2;&#125;/* Write a long long value in format: "$&lt;count&gt;\r\n&lt;payload&gt;\r\n". */size_t rioWriteBulkLongLong(rio *r, long long l) &#123; char lbuf[32]; unsigned int llen; llen = ll2string(lbuf,sizeof(lbuf),l); return rioWriteBulkString(r,lbuf,llen);&#125;/* Write a double value in the format: "$&lt;count&gt;\r\n&lt;payload&gt;\r\n" */size_t rioWriteBulkDouble(rio *r, double d) &#123; char dbuf[128]; unsigned int dlen; dlen = snprintf(dbuf,sizeof(dbuf),"%.17g",d); return rioWriteBulkString(r,dbuf,dlen);&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(14)——notify.c和pubsub.c篇]]></title>
    <url>%2F2017%2F09%2F27%2Fredis%E6%BA%90%E7%A0%81-14-%E2%80%94%E2%80%94notify-c%E5%92%8Cpubsub-c%E7%AF%87%2F</url>
    <content type="text"><![CDATA[发布和订阅功能是redis的特色之一，在客户端可以通过sub指令订阅频道，也可以通过pub发布消息，供其他客户端接受。在redis中，订阅消息属于发送即忘策略，即如果订阅的用户不在线，那么以后也不会接受到发送过的消息了。redis中sub／pub功能的实现在notify.c和pubsub.c文件中，pubsub.c文件中包含了订阅函数，退订函数，发布函数等，以及关于sub／pub功能的实现，在notify.c中则是关于server自身的操作，向其他客户端发送key的space或者event通知，这个功能建立在订阅发布功能的基础上。在client数据结构中对于客户端订阅的频道以及订阅的模式都有记录。1234567891011121314// 其他属性省略typedef struct client&#123; // 订阅的频道，用一个字典保存，key在channel，value为null // 同时在server中也有一个字典用来存储，订阅的channel，以及订阅了该channel的clients list dict *pubsub_channels; // 订阅的模式，是一个list里面存储着pattern // 同时在server中也有一个list用来存储，数据结构pubsubPattern list *pubsub_patterns;&#125;// 用来保存用户订阅的模式的数据结构typedef struct pubsubPattern &#123; client *client;//订阅的用户 robj *pattern;//订阅的模式&#125; pubsubPattern; pubsub.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336// pubsub的顶层实现// 释放pubsubPattern结构void freePubsubPattern(void *p) &#123; pubsubPattern *pat = p; // pattern的引用减1 decrRefCount(pat-&gt;pattern); zfree(pat);&#125;// 判断两个pubsubPattern是否相同int listMatchPubsubPattern(void *a, void *b) &#123; pubsubPattern *pa = a, *pb = b; // 用户相同并且模式相同 return (pa-&gt;client == pb-&gt;client) &amp;&amp; (equalStringObjects(pa-&gt;pattern,pb-&gt;pattern));&#125;// 返回客户端订阅的频道以及模式的和int clientSubscriptionsCount(client *c) &#123; return dictSize(c-&gt;pubsub_channels)+ listLength(c-&gt;pubsub_patterns);&#125;// 客户端订阅一个频道，返回1表示订阅成功，返回0表示已经订阅int pubsubSubscribeChannel(client *c, robj *channel) &#123; dictEntry *de; list *clients = NULL; int retval = 0; // 将channel添加到client的订阅哈希表中 if (dictAdd(c-&gt;pubsub_channels,channel,NULL) == DICT_OK) &#123; retval = 1; incrRefCount(channel); // 查找服务器中的频道字典中是否有该channel，有的话，在list尾加上此client，没有话创建list，添加到字典 de = dictFind(server.pubsub_channels,channel); if (de == NULL) &#123; clients = listCreate(); dictAdd(server.pubsub_channels,channel,clients); incrRefCount(channel); &#125; else &#123; clients = dictGetVal(de); &#125; listAddNodeTail(clients,c); &#125; // 通知用户订阅成功 addReply(c,shared.mbulkhdr[3]); addReply(c,shared.subscribebulk); addReplyBulk(c,channel); addReplyLongLong(c,clientSubscriptionsCount(c)); return retval;&#125;// 退订频道，如果退订成功返回1，返回0表示没有订阅该频道int pubsubUnsubscribeChannel(client *c, robj *channel, int notify) &#123; dictEntry *de; list *clients; listNode *ln; int retval = 0; // 从用户的订阅列表中删除，保证channel的存活，引用加一 incrRefCount(channel); if (dictDelete(c-&gt;pubsub_channels,channel) == DICT_OK) &#123; retval = 1; // 从list中删除该client de = dictFind(server.pubsub_channels,channel); serverAssertWithInfo(c,NULL,de != NULL); clients = dictGetVal(de); ln = listSearchKey(clients,c); serverAssertWithInfo(c,NULL,ln != NULL); listDelNode(clients,ln); if (listLength(clients) == 0) &#123; // 如果没有用户订阅该频道了，从字典中删除 dictDelete(server.pubsub_channels,channel); &#125; &#125; // 通知用户 if (notify) &#123; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.unsubscribebulk); addReplyBulk(c,channel); addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+ listLength(c-&gt;pubsub_patterns)); &#125; decrRefCount(channel); /* it is finally safe to release it */ return retval;&#125; // 客户端订阅一个模式，返回1表示订阅成功，返回0表示已经订阅int pubsubSubscribePattern(client *c, robj *pattern) &#123; int retval = 0; if (listSearchKey(c-&gt;pubsub_patterns,pattern) == NULL) &#123; retval = 1; pubsubPattern *pat; listAddNodeTail(c-&gt;pubsub_patterns,pattern); incrRefCount(pattern); pat = zmalloc(sizeof(*pat)); pat-&gt;pattern = getDecodedObject(pattern); pat-&gt;client = c; listAddNodeTail(server.pubsub_patterns,pat); &#125; /* Notify the client */ addReply(c,shared.mbulkhdr[3]); addReply(c,shared.psubscribebulk); addReplyBulk(c,pattern); addReplyLongLong(c,clientSubscriptionsCount(c)); return retval;&#125;// 退订模式，如果退订成功返回1，返回0表示没有订阅该频道int pubsubUnsubscribePattern(client *c, robj *pattern, int notify) &#123; listNode *ln; pubsubPattern pat; int retval = 0; incrRefCount(pattern); /* Protect the object. May be the same we remove */ if ((ln = listSearchKey(c-&gt;pubsub_patterns,pattern)) != NULL) &#123; retval = 1; listDelNode(c-&gt;pubsub_patterns,ln); pat.client = c; pat.pattern = pattern; ln = listSearchKey(server.pubsub_patterns,&amp;pat); listDelNode(server.pubsub_patterns,ln); &#125; /* Notify the client */ if (notify) &#123; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.punsubscribebulk); addReplyBulk(c,pattern); addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+ listLength(c-&gt;pubsub_patterns)); &#125; decrRefCount(pattern); return retval;&#125;// 退订所有的channelsint pubsubUnsubscribeAllChannels(client *c, int notify) &#123; dictIterator *di = dictGetSafeIterator(c-&gt;pubsub_channels); dictEntry *de; int count = 0; while((de = dictNext(di)) != NULL) &#123; // 遍历所有订阅的channel，依次退订 robj *channel = dictGetKey(de); count += pubsubUnsubscribeChannel(c,channel,notify); &#125; // 感觉这个地方代码有问题，在没有退订的情况应该不需要通知用户了 if (notify &amp;&amp; count == 0) &#123; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.unsubscribebulk); addReply(c,shared.nullbulk); addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+ listLength(c-&gt;pubsub_patterns)); &#125; dictReleaseIterator(di); return count;&#125;// 退订所有的patterns，实现同上int pubsubUnsubscribeAllPatterns(client *c, int notify) &#123; listNode *ln; listIter li; int count = 0; listRewind(c-&gt;pubsub_patterns,&amp;li); while ((ln = listNext(&amp;li)) != NULL) &#123; robj *pattern = ln-&gt;value; count += pubsubUnsubscribePattern(c,pattern,notify); &#125; if (notify &amp;&amp; count == 0) &#123; /* We were subscribed to nothing? Still reply to the client. */ addReply(c,shared.mbulkhdr[3]); addReply(c,shared.punsubscribebulk); addReply(c,shared.nullbulk); addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+ listLength(c-&gt;pubsub_patterns)); &#125; return count;&#125;// 发布一条消息int pubsubPublishMessage(robj *channel, robj *message) &#123; int receivers = 0; dictEntry *de; listNode *ln; listIter li; // 给订阅的clients发送消息 de = dictFind(server.pubsub_channels,channel); // 查找订阅了该channel的client list if (de) &#123; list *list = dictGetVal(de); listNode *ln; listIter li; listRewind(list,&amp;li); // 遍历clients while ((ln = listNext(&amp;li)) != NULL) &#123; client *c = ln-&gt;value; // 发送消息 addReply(c,shared.mbulkhdr[3]); addReply(c,shared.messagebulk); addReplyBulk(c,channel); addReplyBulk(c,message); receivers++; &#125; &#125; // 给订阅的pattern 满足channel的客户发送消息 if (listLength(server.pubsub_patterns)) &#123; listRewind(server.pubsub_patterns,&amp;li); channel = getDecodedObject(channel); // 遍历所有的pubsubPattern while ((ln = listNext(&amp;li)) != NULL) &#123; pubsubPattern *pat = ln-&gt;value; if (stringmatchlen((char*)pat-&gt;pattern-&gt;ptr, sdslen(pat-&gt;pattern-&gt;ptr), (char*)channel-&gt;ptr, sdslen(channel-&gt;ptr),0)) &#123; // 如果满足发送通知 addReply(pat-&gt;client,shared.mbulkhdr[4]); addReply(pat-&gt;client,shared.pmessagebulk); addReplyBulk(pat-&gt;client,pat-&gt;pattern); addReplyBulk(pat-&gt;client,channel); addReplyBulk(pat-&gt;client,message); receivers++; &#125; &#125; decrRefCount(channel); &#125; return receivers;&#125;/*----------------------------------------------------------------------------- * Pubsub commands implementation *----------------------------------------------------------------------------*/// pub/sub指令的实现void subscribeCommand(client *c) &#123; int j; for (j = 1; j &lt; c-&gt;argc; j++) pubsubSubscribeChannel(c,c-&gt;argv[j]); c-&gt;flags |= CLIENT_PUBSUB;//加上订阅标记&#125;void unsubscribeCommand(client *c) &#123; if (c-&gt;argc == 1) &#123; pubsubUnsubscribeAllChannels(c,1); &#125; else &#123; int j; for (j = 1; j &lt; c-&gt;argc; j++) pubsubUnsubscribeChannel(c,c-&gt;argv[j],1); &#125; if (clientSubscriptionsCount(c) == 0) c-&gt;flags &amp;= ~CLIENT_PUBSUB;&#125;void psubscribeCommand(client *c) &#123; int j; for (j = 1; j &lt; c-&gt;argc; j++) pubsubSubscribePattern(c,c-&gt;argv[j]); c-&gt;flags |= CLIENT_PUBSUB;&#125;void punsubscribeCommand(client *c) &#123; if (c-&gt;argc == 1) &#123; pubsubUnsubscribeAllPatterns(c,1); &#125; else &#123; int j; for (j = 1; j &lt; c-&gt;argc; j++) pubsubUnsubscribePattern(c,c-&gt;argv[j],1); &#125; if (clientSubscriptionsCount(c) == 0) c-&gt;flags &amp;= ~CLIENT_PUBSUB;&#125;void publishCommand(client *c) &#123; int receivers = pubsubPublishMessage(c-&gt;argv[1],c-&gt;argv[2]); if (server.cluster_enabled) clusterPropagatePublish(c-&gt;argv[1],c-&gt;argv[2]); else forceCommandPropagation(c,PROPAGATE_REPL); addReplyLongLong(c,receivers);&#125;/* PUBSUB command for Pub/Sub introspection. */// pubsub相关指令的实现void pubsubCommand(client *c) &#123; if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"channels") &amp;&amp; (c-&gt;argc == 2 || c-&gt;argc ==3)) &#123; /* PUBSUB CHANNELS [&lt;pattern&gt;] */ // 返回符合pattern的所有channel sds pat = (c-&gt;argc == 2) ? NULL : c-&gt;argv[2]-&gt;ptr; dictIterator *di = dictGetIterator(server.pubsub_channels); dictEntry *de; long mblen = 0; void *replylen; replylen = addDeferredMultiBulkLength(c); while((de = dictNext(di)) != NULL) &#123; robj *cobj = dictGetKey(de); sds channel = cobj-&gt;ptr; if (!pat || stringmatchlen(pat, sdslen(pat), channel, sdslen(channel),0)) &#123; addReplyBulk(c,cobj); mblen++; &#125; &#125; dictReleaseIterator(di); setDeferredMultiBulkLength(c,replylen,mblen); &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"numsub") &amp;&amp; c-&gt;argc &gt;= 2) &#123; /* PUBSUB NUMSUB [Channel_1 ... Channel_N] */ // 依次返回channel的订阅数 int j; addReplyMultiBulkLen(c,(c-&gt;argc-2)*2); for (j = 2; j &lt; c-&gt;argc; j++) &#123; list *l = dictFetchValue(server.pubsub_channels,c-&gt;argv[j]); addReplyBulk(c,c-&gt;argv[j]); addReplyLongLong(c,l ? listLength(l) : 0); &#125; &#125; else if (!strcasecmp(c-&gt;argv[1]-&gt;ptr,"numpat") &amp;&amp; c-&gt;argc == 2) &#123; /* PUBSUB NUMPAT */ // 返回所有pattern的订阅数 addReplyLongLong(c,listLength(server.pubsub_patterns)); &#125; else &#123; addReplyErrorFormat(c, "Unknown PUBSUB subcommand or wrong number of arguments for '%s'", (char*)c-&gt;argv[1]-&gt;ptr); &#125;&#125; notify.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// 将一个字符串转化为响应的flagsint keyspaceEventsStringToFlags(char *classes) &#123; char *p = classes; int c, flags = 0; while((c = *p++) != '\0') &#123; switch(c) &#123; case 'A': flags |= NOTIFY_ALL; break; case 'g': flags |= NOTIFY_GENERIC; break; case '$': flags |= NOTIFY_STRING; break; case 'l': flags |= NOTIFY_LIST; break; case 's': flags |= NOTIFY_SET; break; case 'h': flags |= NOTIFY_HASH; break; case 'z': flags |= NOTIFY_ZSET; break; case 'x': flags |= NOTIFY_EXPIRED; break; case 'e': flags |= NOTIFY_EVICTED; break; case 'K': flags |= NOTIFY_KEYSPACE; break; case 'E': flags |= NOTIFY_KEYEVENT; break; default: return -1; &#125; &#125; return flags;&#125;// 将flags转换为相应的字符串sds keyspaceEventsFlagsToString(int flags) &#123; sds res; res = sdsempty(); if ((flags &amp; NOTIFY_ALL) == NOTIFY_ALL) &#123; res = sdscatlen(res,"A",1); &#125; else &#123; if (flags &amp; NOTIFY_GENERIC) res = sdscatlen(res,"g",1); if (flags &amp; NOTIFY_STRING) res = sdscatlen(res,"$",1); if (flags &amp; NOTIFY_LIST) res = sdscatlen(res,"l",1); if (flags &amp; NOTIFY_SET) res = sdscatlen(res,"s",1); if (flags &amp; NOTIFY_HASH) res = sdscatlen(res,"h",1); if (flags &amp; NOTIFY_ZSET) res = sdscatlen(res,"z",1); if (flags &amp; NOTIFY_EXPIRED) res = sdscatlen(res,"x",1); if (flags &amp; NOTIFY_EVICTED) res = sdscatlen(res,"e",1); &#125; if (flags &amp; NOTIFY_KEYSPACE) res = sdscatlen(res,"K",1); if (flags &amp; NOTIFY_KEYEVENT) res = sdscatlen(res,"E",1); return res;&#125; // 服务器发送通知// 'event' 是事件的名称// 'key' 是发生操作的key// 'dbid' 键值存储的数据库id void notifyKeyspaceEvent(int type, char *event, robj *key, int dbid) &#123; sds chan; robj *chanobj, *eventobj; int len = -1; char buf[24]; // 如果notify_keyspace_events中配置了不发送type类型的通知，则直接返回 // notify_keyspace_events值为 一个type的亦或值，type保存有不发送的通知 if (!(server.notify_keyspace_events &amp; type)) return; eventobj = createStringObject(event,strlen(event)); /* __keyspace@&lt;db&gt;__:&lt;key&gt; &lt;event&gt; notifications. */ // 发送键空间通知 if (server.notify_keyspace_events &amp; NOTIFY_KEYSPACE) &#123; // 构建channel chan = sdsnewlen("__keyspace@",11); len = ll2string(buf,sizeof(buf),dbid); chan = sdscatlen(chan, buf, len); chan = sdscatlen(chan, "__:", 3); chan = sdscatsds(chan, key-&gt;ptr); chanobj = createObject(OBJ_STRING, chan); // 发送消息 pubsubPublishMessage(chanobj, eventobj); decrRefCount(chanobj); &#125; /* __keyevente@&lt;db&gt;__:&lt;event&gt; &lt;key&gt; notifications. */ // 发送键事件通知 if (server.notify_keyspace_events &amp; NOTIFY_KEYEVENT) &#123; chan = sdsnewlen("__keyevent@",11); if (len == -1) len = ll2string(buf,sizeof(buf),dbid); chan = sdscatlen(chan, buf, len); chan = sdscatlen(chan, "__:", 3); chan = sdscatsds(chan, eventobj-&gt;ptr); chanobj = createObject(OBJ_STRING, chan); // 发送通知 pubsubPublishMessage(chanobj, key); decrRefCount(chanobj); &#125; decrRefCount(eventobj);&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(13)——db.c篇]]></title>
    <url>%2F2017%2F09%2F26%2Fredis%E6%BA%90%E7%A0%81-13-%E2%80%94%E2%80%94db-c%E7%AF%87%2F</url>
    <content type="text"><![CDATA[数据库中记录着许多类型的数据对象，对于整个数据库，内部也是用一个字典来存储管理键值对，value就是各种robj对象，对于一个server可以有许多个数据库，对于一个客户端client只能选择一个数据库在一个时间点，下面我们看一下相关的数据结构，看看redisdb等之中存储的信息有哪些。123456789101112131415161718192021222324252627// redis中数据库结构，id用来表示数据库标号，从0到配置的最大标号typedef struct redisDb &#123; dict *dict; /* The keyspace for this DB */ // 存储数据库中键和对象 dict *expires; /* Timeout of keys with a timeout set */ // 每一个对象的过期时限 dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ // 存储阻塞的key以及阻塞的用户list dict *ready_keys; /* Blocked keys that received a PUSH */ // 存储准备解开阻塞的key dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ // 查看的key用于事务块 int id; /* Database ID */ // 数据库id long long avg_ttl; /* Average TTL, just for stats */ // 平均ttl&#125; redisDb;//Redis服务器和客户端也都保存有数据库的信息，下面截取出来：typedef struct client &#123; redisDb *db; /* Pointer to currently SELECTed DB. */&#125; client;struct redisServer &#123; redisDb *db; int dbnum; /* Total number of configured DBs */&#125;; redisdb中的dict用来存储数据库中的键值对，所以也存在相应的查询，添加删除操作函数。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 基础的查询api，不能直接调用，用lookupKeyRead(),lookupKeyWrite() and lookupKeyReadWithFlags()取代robj *lookupKey(redisDb *db, robj *key, int flags);// 查询key为了一个读操作。return null如果key不存在。// 调用这个函数的副作用分：1.一个键实效如果达到了它的ttl 2.最近访问时间跟新 3.全局命中丢失跟新// 当我们获取与键相连的对象时，只在只读操作时才可以使用此API。// flags改变指令行为：1.LOOKUP_NONE没有特殊指示 2.LOOKUP_NOTOUCH不改变最近跟新时间robj *lookupKeyReadWithFlags(redisDb *db, robj *key, int flags);// 常规的读查询robj *lookupKeyRead(redisDb *db, robj *key);// 查询key用来写操作，它副作用是，如果需要，使key实效如果ttl已经达到robj *lookupKeyWrite(redisDb *db, robj *key);robj *lookupKeyReadOrReply(client *c, robj *key, robj *reply);robj *lookupKeyWriteOrReply(client *c, robj *key, robj *reply);robj *lookupKeyReadWithFlags(redisDb *db, robj *key, int flags) &#123; robj *val; if (expireIfNeeded(db,key) == 1) &#123; // key达到过期时间，实效 // 在一个master环境下，key确保被删除，所以返回null if (server.masterhost == NULL) return NULL; // 在一个slave环境下，为了确保主从的一致性，返回null if (server.current_client &amp;&amp; server.current_client != server.master &amp;&amp; server.current_client-&gt;cmd &amp;&amp; server.current_client-&gt;cmd-&gt;flags &amp; CMD_READONLY) &#123; return NULL; &#125; &#125; val = lookupKey(db,key,flags); // 更新读查询命中以及丢失次数 if (val == NULL) server.stat_keyspace_misses++; else server.stat_keyspace_hits++; return val;&#125;// 向数据库添加键，同时增加value的引用的计数，如果已经存在 终止函数void dbAdd(redisDb *db, robj *key, robj *val)； // 重写已经存在的key，函数不会修改key的过期时间，程序终止，如果key不存在。void dbOverwrite(redisDb *db, robj *key, robj *val)；// 数据库中所有的key通过该函数添加。// 函数作用1.增加value引用计数 2.用户查看目标key通知 3.ttl重置void setKey(redisDb *db, robj *key, robj *val)；// 是否存在keyint dbExists(redisDb *db, robj *key)；// 随机返回一个key的redis对象，保证返回的key没有过期robj *dbRandomKey(redisDb *db)；// 同步删除key value以及相关的条目int dbSyncDelete(redisDb *db, robj *key)；// 删除包装，是否懒删除int dbDelete(redisDb *db, robj *key)；// 当出现对象正在share状态，或者编码不是RAW，我们需要unshare他们，为SETBIT or APPEND准备robj *dbUnshareStringValue(redisDb *db, robj *key, robj *o)；// 清空所欧的数据库，分为同步删除与异步删除long long emptyDb(int dbnum, int flags, void(callback)(void*))；// 切换dbint selectDb(client *c, int id)；// 键改变的钩子函数，每次数据库中的键更新时，调用该函数// 每次数据库被清空时调用signalFlushedDb，用于事务检查void signalModifiedKey(redisDb *db, robj *key) &#123; touchWatchedKey(db,key);&#125;void signalFlushedDb(int dbid) &#123; touchWatchedKeysOnFlush(dbid);&#125; 利用上面完成的关于db的函数来完成指令函数的实现，关于db的指令也有很多，下面主要注释几个比较复杂的函数比如scan等123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464/* This callback is used by scanGenericCommand in order to collect elements * returned by the dictionary iterator into a list. */// 这个callback函数被scanGenericCommand调用为了收集元素添加到list中通过字典迭代器void scanCallback(void *privdata, const dictEntry *de) &#123; void **pd = (void**) privdata; list *keys = pd[0]; robj *o = pd[1]; robj *key, *val = NULL; if (o == NULL) &#123; sds sdskey = dictGetKey(de); key = createStringObject(sdskey, sdslen(sdskey)); &#125; else if (o-&gt;type == OBJ_SET) &#123; sds keysds = dictGetKey(de); key = createStringObject(keysds,sdslen(keysds)); &#125; else if (o-&gt;type == OBJ_HASH) &#123; sds sdskey = dictGetKey(de); sds sdsval = dictGetVal(de); key = createStringObject(sdskey,sdslen(sdskey)); val = createStringObject(sdsval,sdslen(sdsval)); &#125; else if (o-&gt;type == OBJ_ZSET) &#123; sds sdskey = dictGetKey(de); key = createStringObject(sdskey,sdslen(sdskey)); val = createStringObjectFromLongDouble(*(double*)dictGetVal(de),0); &#125; else &#123; serverPanic("Type not handled in SCAN callback."); &#125; listAddNodeTail(keys, key); if (val) listAddNodeTail(keys, val);&#125;/* Try to parse a SCAN cursor stored at object 'o': * if the cursor is valid, store it as unsigned integer into *cursor and * returns C_OK. Otherwise return C_ERR and send an error to the * client. */// 获取scan指令中的cursor值int parseScanCursorOrReply(client *c, robj *o, unsigned long *cursor) &#123; char *eptr; /* Use strtoul() because we need an *unsigned* long, so * getLongLongFromObject() does not cover the whole cursor space. */ errno = 0; *cursor = strtoul(o-&gt;ptr, &amp;eptr, 10); if (isspace(((char*)o-&gt;ptr)[0]) || eptr[0] != '\0' || errno == ERANGE) &#123; addReplyError(c, "invalid cursor"); return C_ERR; &#125; return C_OK;&#125;/* This command implements SCAN, HSCAN and SSCAN commands. * If object 'o' is passed, then it must be a Hash or Set object, otherwise * if 'o' is NULL the command will operate on the dictionary associated with * the current database. * * When 'o' is not NULL the function assumes that the first argument in * the client arguments vector is a key so it skips it before iterating * in order to parse options. * * In the case of a Hash object the function returns both the field and value * of every element on the Hash. */// 此函数实现了SCAN。HSCAN，SSCAN指令// 如果o被传入，那么一定是hash或set对象，否则o为null，这个指令将会操作现在数据库的字典// 当o不是空，函数假设第一个参数在参数容器中是一个key，所以为了分析options在迭代之前跳过它。// 在hash对象的情况下，函数返回每个元素的field以及valuevoid scanGenericCommand(client *c, robj *o, unsigned long cursor) &#123; int i, j; list *keys = listCreate(); listNode *node, *nextnode; long count = 10; sds pat = NULL; int patlen = 0, use_pattern = 0; dict *ht; /* Object must be NULL (to iterate keys names), or the type of the object * must be Set, Sorted Set, or Hash. */ // 对象必须为空或者type为集合，哈希表，或者有序集合 serverAssert(o == NULL || o-&gt;type == OBJ_SET || o-&gt;type == OBJ_HASH || o-&gt;type == OBJ_ZSET); /* Set i to the first option argument. The previous one is the cursor. */ // 设置i为第一个option参数，前一个为游标参数。当o=null时，可以跳过key i = (o == NULL) ? 2 : 3; /* Skip the key argument if needed. */ /* Step 1: Parse options. */ // 第一步解析options while (i &lt; c-&gt;argc) &#123; j = c-&gt;argc - i; // 获取count option 以及参数，判断语法规范以及参数格式 if (!strcasecmp(c-&gt;argv[i]-&gt;ptr, "count") &amp;&amp; j &gt;= 2) &#123; if (getLongFromObjectOrReply(c, c-&gt;argv[i+1], &amp;count, NULL) != C_OK) &#123; goto cleanup; &#125; if (count &lt; 1) &#123; addReply(c,shared.syntaxerr); goto cleanup; &#125; i += 2; // 获取match option 以及参数，判断语法规范以及参数格式 &#125; else if (!strcasecmp(c-&gt;argv[i]-&gt;ptr, "match") &amp;&amp; j &gt;= 2) &#123; pat = c-&gt;argv[i+1]-&gt;ptr; patlen = sdslen(pat); /* The pattern always matches if it is exactly "*", so it is * equivalent to disabling it. */ // 如果pat=“*”那么不使用regex use_pattern = !(pat[0] == '*' &amp;&amp; patlen == 1); i += 2; &#125; else &#123; addReply(c,shared.syntaxerr); goto cleanup; &#125; &#125; /* Step 2: Iterate the collection. * * Note that if the object is encoded with a ziplist, intset, or any other * representation that is not a hash table, we are sure that it is also * composed of a small number of elements. So to avoid taking state we * just return everything inside the object in a single call, setting the * cursor to zero to signal the end of the iteration. */ // 第二步：迭代集合 // 注意如果对象的编码时ziplist, intset，或者其他不是hashtable，我们确定它包含少量的元素，所以我们直接返回所有的元素，将游标设为0标志到达迭代器尾部。 /* Handle the case of a hash table. */ ht = NULL; if (o == NULL) &#123; ht = c-&gt;db-&gt;dict; &#125; else if (o-&gt;type == OBJ_SET &amp;&amp; o-&gt;encoding == OBJ_ENCODING_HT) &#123; ht = o-&gt;ptr; &#125; else if (o-&gt;type == OBJ_HASH &amp;&amp; o-&gt;encoding == OBJ_ENCODING_HT) &#123; ht = o-&gt;ptr; count *= 2; /* We return key / value for this type. */ &#125; else if (o-&gt;type == OBJ_ZSET &amp;&amp; o-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = o-&gt;ptr; ht = zs-&gt;dict; count *= 2; /* We return key / value for this type. */ &#125; if (ht) &#123; void *privdata[2]; /* We set the max number of iterations to ten times the specified * COUNT, so if the hash table is in a pathological state (very * sparsely populated) we avoid to block too much time at the cost * of returning no or very few elements. */ // 我们设置最大迭代次数为count的10倍，这样如果哈希表非常小，我们防治阻塞太长的时间在返回极少的元素 long maxiterations = count*10; /* We pass two pointers to the callback: the list to which it will * add new elements, and the object containing the dictionary so that * it is possible to fetch more data in a type-dependent way. */ // 我们传两个指针给callback。一个供添加新元素的list，一个包含字典的对象，这样我们可能获取更多元素以一个类型依赖的方式 privdata[0] = keys; privdata[1] = o; do &#123; // 迭代对象中元素 cursor = dictScan(ht, cursor, scanCallback, NULL, privdata); &#125; while (cursor &amp;&amp; maxiterations-- &amp;&amp; listLength(keys) &lt; (unsigned long)count); &#125; else if (o-&gt;type == OBJ_SET) &#123; int pos = 0; int64_t ll; while(intsetGet(o-&gt;ptr,pos++,&amp;ll)) listAddNodeTail(keys,createStringObjectFromLongLong(ll)); cursor = 0; &#125; else if (o-&gt;type == OBJ_HASH || o-&gt;type == OBJ_ZSET) &#123; unsigned char *p = ziplistIndex(o-&gt;ptr,0); unsigned char *vstr; unsigned int vlen; long long vll; while(p) &#123; ziplistGet(p,&amp;vstr,&amp;vlen,&amp;vll); listAddNodeTail(keys, (vstr != NULL) ? createStringObject((char*)vstr,vlen) : createStringObjectFromLongLong(vll)); p = ziplistNext(o-&gt;ptr,p); &#125; cursor = 0; &#125; else &#123; serverPanic("Not handled encoding in SCAN."); &#125; /* Step 3: Filter elements. */ // 第三步过滤元素 node = listFirst(keys); while (node) &#123; robj *kobj = listNodeValue(node); nextnode = listNextNode(node); int filter = 0; /* Filter element if it does not match the pattern. */ if (!filter &amp;&amp; use_pattern) &#123; if (sdsEncodedObject(kobj)) &#123; if (!stringmatchlen(pat, patlen, kobj-&gt;ptr, sdslen(kobj-&gt;ptr), 0)) filter = 1; &#125; else &#123; char buf[LONG_STR_SIZE]; int len; serverAssert(kobj-&gt;encoding == OBJ_ENCODING_INT); len = ll2string(buf,sizeof(buf),(long)kobj-&gt;ptr); if (!stringmatchlen(pat, patlen, buf, len, 0)) filter = 1; &#125; &#125; /* Filter element if it is an expired key. */ // p判断key是否过期 if (!filter &amp;&amp; o == NULL &amp;&amp; expireIfNeeded(c-&gt;db, kobj)) filter = 1; /* Remove the element and its associted value if needed. */ // 如果被过滤从list中删除 if (filter) &#123; decrRefCount(kobj); listDelNode(keys, node); &#125; /* If this is a hash or a sorted set, we have a flat list of * key-value elements, so if this element was filtered, remove the * value, or skip it if it was not filtered: we only match keys. */ // 如果是要输出键值对那么往后再删除一个node if (o &amp;&amp; (o-&gt;type == OBJ_ZSET || o-&gt;type == OBJ_HASH)) &#123; node = nextnode; nextnode = listNextNode(node); if (filter) &#123; kobj = listNodeValue(node); decrRefCount(kobj); listDelNode(keys, node); &#125; &#125; node = nextnode; &#125; /* Step 4: Reply to the client. */ // 第四部，回应用户 addReplyMultiBulkLen(c, 2); addReplyBulkLongLong(c,cursor); addReplyMultiBulkLen(c, listLength(keys)); while ((node = listFirst(keys)) != NULL) &#123; robj *kobj = listNodeValue(node); addReplyBulk(c, kobj); decrRefCount(kobj); listDelNode(keys, node); &#125;cleanup: listSetFreeMethod(keys,decrRefCountVoid); listRelease(keys);&#125;// rename指令实现void renameGenericCommand(client *c, int nx) &#123; robj *o; long long expire; int samekey = 0; /* When source and dest key is the same, no operation is performed, * if the key exists, however we still return an error on unexisting key. */ // 如果源key与目标key相同，没有操作执行 if (sdscmp(c-&gt;argv[1]-&gt;ptr,c-&gt;argv[2]-&gt;ptr) == 0) samekey = 1; if ((o = lookupKeyWriteOrReply(c,c-&gt;argv[1],shared.nokeyerr)) == NULL) return; if (samekey) &#123; addReply(c,nx ? shared.czero : shared.ok); return; &#125; incrRefCount(o); expire = getExpire(c-&gt;db,c-&gt;argv[1]); if (lookupKeyWrite(c-&gt;db,c-&gt;argv[2]) != NULL) &#123; // 目标key已经存在 if (nx) &#123; decrRefCount(o); addReply(c,shared.czero); return; &#125; /* Overwrite: delete the old key before creating the new one * with the same name. */ // 删除已经存在的目标key dbDelete(c-&gt;db,c-&gt;argv[2]); &#125; // 添加新的目标key dbAdd(c-&gt;db,c-&gt;argv[2],o); // 设置原来的过期实现 if (expire != -1) setExpire(c,c-&gt;db,c-&gt;argv[2],expire); // 删除原来的key dbDelete(c-&gt;db,c-&gt;argv[1]); signalModifiedKey(c-&gt;db,c-&gt;argv[1]); signalModifiedKey(c-&gt;db,c-&gt;argv[2]); notifyKeyspaceEvent(NOTIFY_GENERIC,"rename_from", c-&gt;argv[1],c-&gt;db-&gt;id); notifyKeyspaceEvent(NOTIFY_GENERIC,"rename_to", c-&gt;argv[2],c-&gt;db-&gt;id); server.dirty++; addReply(c,nx ? shared.cone : shared.ok);&#125;// move指令实现void moveCommand(client *c) &#123; robj *o; redisDb *src, *dst; int srcid; long long dbid, expire; // 在集群模式下不可移动 if (server.cluster_enabled) &#123; addReplyError(c,"MOVE is not allowed in cluster mode"); return; &#125; /* Obtain source and target DB pointers */ src = c-&gt;db; srcid = c-&gt;db-&gt;id; // 获取目标数据库id if (getLongLongFromObject(c-&gt;argv[2],&amp;dbid) == C_ERR || dbid &lt; INT_MIN || dbid &gt; INT_MAX || selectDb(c,dbid) == C_ERR) &#123; addReply(c,shared.outofrangeerr); return; &#125; // 记录目标数据库 dst = c-&gt;db; // 返回原来的数据库 selectDb(c,srcid); /* Back to the source DB */ /* If the user is moving using as target the same * DB as the source DB it is probably an error. */ // 如果是同一个数据库那么返回错误 if (src == dst) &#123; addReply(c,shared.sameobjecterr); return; &#125; /* Check if the element exists and get a reference */ // 查找源数据库中移动的key o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); if (!o) &#123; addReply(c,shared.czero); return; &#125; expire = getExpire(c-&gt;db,c-&gt;argv[1]); // 如果目标数据库中存在key那么直接返回错误 /* Return zero if the key already exists in the target DB */ if (lookupKeyWrite(dst,c-&gt;argv[1]) != NULL) &#123; addReply(c,shared.czero); return; &#125; // 往目标数据库添加key，设置过期时限 dbAdd(dst,c-&gt;argv[1],o); if (expire != -1) setExpire(c,dst,c-&gt;argv[1],expire); incrRefCount(o); /* OK! key moved, free the entry in the source DB */ // 删除源数据库中的key dbDelete(src,c-&gt;argv[1]); server.dirty++; addReply(c,shared.cone);&#125;/* Helper function for dbSwapDatabases(): scans the list of keys that have * one or more blocked clients for B[LR]POP or other list blocking commands * and signal the keys are ready if they are lists. See the comment where * the function is used for more info. */// 检查blocking_keys，将符合的key加入到readylist，该函数是dbSwapDatabases的辅助函数void scanDatabaseForReadyLists(redisDb *db) &#123; dictEntry *de; dictIterator *di = dictGetSafeIterator(db-&gt;blocking_keys); while((de = dictNext(di)) != NULL) &#123; robj *key = dictGetKey(de); robj *value = lookupKey(db,key,LOOKUP_NOTOUCH); // 如果该key在新的数据库中存在且类型为list加入到readylist if (value &amp;&amp; value-&gt;type == OBJ_LIST) signalListAsReady(db, key); &#125; dictReleaseIterator(di);&#125;/* Swap two databases at runtime so that all clients will magically see * the new database even if already connected. Note that the client * structure c-&gt;db points to a given DB, so we need to be smarter and * swap the underlying referenced structures, otherwise we would need * to fix all the references to the Redis DB structure. * * Returns C_ERR if at least one of the DB ids are out of range, otherwise * C_OK is returned. */// 交换两个数据库实现int dbSwapDatabases(int id1, int id2) &#123; if (id1 &lt; 0 || id1 &gt;= server.dbnum || id2 &lt; 0 || id2 &gt;= server.dbnum) return C_ERR; if (id1 == id2) return C_OK; redisDb aux = server.db[id1]; redisDb *db1 = &amp;server.db[id1], *db2 = &amp;server.db[id2]; /* Swap hash tables. Note that we don't swap blocking_keys, * ready_keys and watched_keys, since we want clients to * remain in the same DB they were. */ // 交换相应的属性 db1-&gt;dict = db2-&gt;dict; db1-&gt;expires = db2-&gt;expires; db1-&gt;avg_ttl = db2-&gt;avg_ttl; db2-&gt;dict = aux.dict; db2-&gt;expires = aux.expires; db2-&gt;avg_ttl = aux.avg_ttl; /* Now we need to handle clients blocked on lists: as an effect * of swapping the two DBs, a client that was waiting for list * X in a given DB, may now actually be unblocked if X happens * to exist in the new version of the DB, after the swap. * * However normally we only do this check for efficiency reasons * in dbAdd() when a list is created. So here we need to rescan * the list of clients blocked on lists and signal lists as ready * if needed. */ // 交换后的db，可能阻塞的key不在阻塞了，所以进行检查，将可能的key加入到readylist scanDatabaseForReadyLists(db1); scanDatabaseForReadyLists(db2); return C_OK;&#125;/* SWAPDB db1 db2 */// 交换两个db指令实现void swapdbCommand(client *c) &#123; long id1, id2; /* Not allowed in cluster mode: we have just DB 0 there. */ // 在集群模式下不允许执行该指令 if (server.cluster_enabled) &#123; addReplyError(c,"SWAPDB is not allowed in cluster mode"); return; &#125; /* Get the two DBs indexes. */ // 获取两个db的id if (getLongFromObjectOrReply(c, c-&gt;argv[1], &amp;id1, "invalid first DB index") != C_OK) return; if (getLongFromObjectOrReply(c, c-&gt;argv[2], &amp;id2, "invalid second DB index") != C_OK) return; /* Swap... */ // 交换数据库 if (dbSwapDatabases(id1,id2) == C_ERR) &#123; addReplyError(c,"DB index is out of range"); return; &#125; else &#123; server.dirty++; addReply(c,shared.ok); &#125;&#125; 接下来是关于数据库key的过期时限的操作，在数据库中也是用一个字典来管理存储每一个key的expire的，下面是关于expire的操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// 移除key的过期时间int removeExpire(redisDb *db, robj *key) &#123; /* An expire may only be removed if there is a corresponding entry in the * main dict. Otherwise, the key will never be freed. */ serverAssertWithInfo(NULL,key,dictFind(db-&gt;dict,key-&gt;ptr) != NULL); return dictDelete(db-&gt;expires,key-&gt;ptr) == DICT_OK;&#125;/* Set an expire to the specified key. If the expire is set in the context * of an user calling a command 'c' is the client, otherwise 'c' is set * to NULL. The 'when' parameter is the absolute unix time in milliseconds * after which the key will no longer be considered valid. */// 设置key的过期时间void setExpire(client *c, redisDb *db, robj *key, long long when) &#123; dictEntry *kde, *de; /* Reuse the sds from the main dict in the expire dict */ kde = dictFind(db-&gt;dict,key-&gt;ptr); serverAssertWithInfo(NULL,key,kde != NULL); de = dictAddOrFind(db-&gt;expires,dictGetKey(kde)); dictSetSignedIntegerVal(de,when); int writable_slave = server.masterhost &amp;&amp; server.repl_slave_ro == 0; if (c &amp;&amp; writable_slave &amp;&amp; !(c-&gt;flags &amp; CLIENT_MASTER)) rememberSlaveKeyWithExpire(db,key);&#125;/* Return the expire time of the specified key, or -1 if no expire * is associated with this key (i.e. the key is non volatile) */// 返回该键的过期时间，或者返回-1 如果没有实效时间关联到该键 long long getExpire(redisDb *db, robj *key) &#123; dictEntry *de; /* No expire? return ASAP */ if (dictSize(db-&gt;expires) == 0 || (de = dictFind(db-&gt;expires,key-&gt;ptr)) == NULL) return -1; /* The entry was found in the expire dict, this means it should also * be present in the main dict (safety check). */ serverAssertWithInfo(NULL,key,dictFind(db-&gt;dict,key-&gt;ptr) != NULL); return dictGetSignedIntegerVal(de);&#125;/* Propagate expires into slaves and the AOF file. * When a key expires in the master, a DEL operation for this key is sent * to all the slaves and the AOF file if enabled. * * This way the key expiry is centralized in one place, and since both * AOF and the master-&gt;slave link guarantee operation ordering, everything * will be consistent even if we allow write operations against expiring * keys. */// 发生实效时，向aof以及slave服务器发送删除操作void propagateExpire(redisDb *db, robj *key, int lazy) &#123; robj *argv[2]; argv[0] = lazy ? shared.unlink : shared.del; argv[1] = key; incrRefCount(argv[0]); incrRefCount(argv[1]); if (server.aof_state != AOF_OFF) feedAppendOnlyFile(server.delCommand,db-&gt;id,argv,2); replicationFeedSlaves(server.slaves,db-&gt;id,argv,2); decrRefCount(argv[0]); decrRefCount(argv[1]);&#125;// 数据库中该key在需要时，使它实效int expireIfNeeded(redisDb *db, robj *key) &#123; mstime_t when = getExpire(db,key); mstime_t now; // 不存在expire if (when &lt; 0) return 0; /* No expire for this key */ /* Don't expire anything while loading. It will be done later. */ // 如果服务器正在加载，稍后再做 if (server.loading) return 0; /* If we are in the context of a Lua script, we claim that time is * blocked to when the Lua script started. This way a key can expire * only the first time it is accessed and not in the middle of the * script execution, making propagation to slaves / AOF consistent. * See issue #1525 on Github for more information. */ // 如果是一个lua脚本，那么now为脚本开始时间 now = server.lua_caller ? server.lua_time_start : mstime(); /* If we are running in the context of a slave, return ASAP: * the slave key expiration is controlled by the master that will * send us synthesized DEL operations for expired keys. * * Still we try to return the right information to the caller, * that is, 0 if we think the key should be still valid, 1 if * we think the key is expired at this time. */ // 如果是slave那么只返回逻辑是否过期 if (server.masterhost != NULL) return now &gt; when; /* Return when this key has not expired */ if (now &lt;= when) return 0; /* Delete the key */ server.stat_expiredkeys++; propagateExpire(db,key,server.lazyfree_lazy_expire); notifyKeyspaceEvent(NOTIFY_EXPIRED, "expired",key,db-&gt;id); return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) : dbSyncDelete(db,key);&#125; 最后一部分是关于获取指令key参数的函数以及对于server来说用散列管理的一个key slot哈希表，可以更快速的获取想要的key，这里不是主体，自行参考源码不多做解释。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(12)——t_zset.c篇]]></title>
    <url>%2F2017%2F09%2F18%2Fredis%E6%BA%90%E7%A0%81-12-%E2%80%94%E2%80%94t-zset-c%E7%AF%87%2F</url>
    <content type="text"><![CDATA[在t_zset.c源文件中，比较复杂，分为好几个部分，首先是前面讲过的skiplist的相关操作函数，相关数据结构定义在server.h中，这里就不再介绍，然后是skiplist用来作为有序集合编码时的相关操作函数，再后面是有序集合的相关操作函数，基于skiplist和dict的底层实现以及ziplist的底层实现来完成，最后一部分是关于有序集合指令的函数实现。首先列出所有基于ziplist底层实现的有序集合操作函数的定义1234567891011121314151617181920212223242526272829303132333435// sptr为一个value以及score的score指针，返回浮点型的scoredouble zzlGetScore(unsigned char *sptr);// 返回一个value的sds对象，sptr为value的指针，而非scoresds ziplistGetObject(unsigned char *sptr);/ 与zset中的一个元素比较int zzlCompareElements(unsigned char *eptr, unsigned char *cstr, unsigned int clen);// ziplist中存储的zset的元素个数unsigned int zzlLength(unsigned char *zl);// 将指针eptr以及sptr移到存储的下一个实体上包括elem以及scorevoid zzlNext(unsigned char *zl, unsigned char **eptr, unsigned char **sptr);// 将指针eptr以及sptr移到存储的上一个实体上包括elem以及scorevoid zzlPrev(unsigned char *zl, unsigned char **eptr, unsigned char **sptr);// 根据score判断zset是否有elem在规定范围内int zzlIsInRange(unsigned char *zl, zrangespec *range);// 第一个在范围内吃的elemunsigned char *zzlFirstInRange(unsigned char *zl, zrangespec *range);// 最后一个出现在范围内的elemunsigned char *zzlLastInRange(unsigned char *zl, zrangespec *range);int zzlIsInLexRange(unsigned char *zl, zlexrangespec *range);unsigned char *zzlFirstInLexRange(unsigned char *zl, zlexrangespec *range);unsigned char *zzlLastInLexRange(unsigned char *zl, zlexrangespec *range);// 在ziplist的zset中查找elem为ele，返回其指针，并且存储scoreunsigned char *zzlFind(unsigned char *zl, sds ele, double *score);// 删除ziplist的zset的eptr上的value以及scoreunsigned char *zzlDelete(unsigned char *zl, unsigned char *eptr);// 在eptr前面插入新的元素unsigned char *zzlInsertAt(unsigned char *zl, unsigned char *eptr, sds ele, double score);// 往ziplist的zset插入新的元素，假设zset之前不存在该元素，如果score相同再比较sdsunsigned char *zzlInsert(unsigned char *zl, sds ele, double score);// 根据score删除范围内的元素unsigned char *zzlDeleteRangeByScore(unsigned char *zl, zrangespec *range, unsigned long *deleted);// 根据lex删除范围内的元素unsigned char *zzlDeleteRangeByLex(unsigned char *zl, zlexrangespec *range, unsigned long *deleted);// 删除所有rank排序start到end的元素unsigned char *zzlDeleteRangeByRank(unsigned char *zl, unsigned int start, unsigned int end, unsigned long *deleted); 对于ziplist的底层实现，设计方式是先存value再存一个score，其他常用的ziplist操作在ziplist.c中已经实现，所以实现逻辑相对较简单，这里就不做解释。下面是zset的操作函数，但是它的函数并不全面，比如delete等，在命令函数中需要对底层实现讨论后，调用函数自己实现，可能是应为删除的方式有许多种，会造成代码冗余，且实现简单，所以不进行封装，直接在命令函数中编写。123456789101112131415161718192021222324252627282930313233// 返回有序集合中元素个数unsigned int zsetLength(const robj *zobj);// 有序集合底层编码转化 从ziplist转换到skiplist 以及从skiplist转换到ziplistvoid zsetConvert(robj *zobj, int encoding);// 如果skiplist编码的zset在ziplist编码的条件内那么转换有序集合编码为ziplistvoid zsetConvertToZiplistIfNeeded(robj *zobj, size_t maxelelen);// 返回集合中元素member的score，用索引存储int zsetScore(robj *zobj, sds member, double *score);// 有序集合中添加元素或者更新一个已经存在的元素的score// flag用来改变指令的行为，他们用整数指针传递，在函数执行之后清空，用别的flag替代标志不同的情况// 输入的flag有下面几种：// ZADD_INCR:在已有的score上加上参数跟新score，如果元素之前不存在，假设之前的score为0// ZADD_NX:执行这个操作当元素不存在时// ZADD_XX:执行这个操作当元素存在时// 当ZADD_INCR被使用时，新的score存储在newscore中如果newscore不为空// 返回的flag有下面几种：// ZADD_NAN:结果score不是一个数字// ZADD_ADDED:元素被添加// ZADD_UPDATED:元素被更新// ZADD_NOP:没有操作执行因为nx或者xx// 函数return的值：// 函数返回1在成功时，并且flag被指为add或update标志什么操作呗执行// 函数返回0在失败时，仅当增加导致一个nan或者使用score不是一个整数// 指令又一个副作用就是导致编码的转换// ele的内存管理：// 此函数没有ele的所有权，在需要时对ele进行复制。int zsetAdd(robj *zobj, double score, sds ele, int *flags, double *newscore);//删除元素ele从有序集合中，如果返回1代表删除成功，否则返回0int zsetDel(robj *zobj, sds ele);// 提供一个有序集合对象，返回一个元素的从0开始的排序序号或者不存在返回-1// reverse为0标志从score小的开始排序，reverse非0代表逆向排序long zsetRank(robj *zobj, sds ele, int reverse); 之后是两个相关的数据结构zsetopsrc以及zsetopval，以及关于迭代器的相关函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 集合迭代器包括有序以及无序集合，同时保存关于集合的参数以及集合本身typedef struct &#123; robj *subject;//存储集合对象 int type; //集合类型无序或有序 int encoding;//对象编码 double weight;//权重 union &#123; // 无序集合迭代器 union _iterset &#123; // inset编码的迭代器 struct &#123; intset *is; int ii; &#125; is; // dict编码的迭代器 struct &#123; dict *dict; dictIterator *di; dictEntry *de; &#125; ht; &#125; set; // 有序集合的迭代器 union _iterzset &#123; // ziplist编码的集合迭代器 struct &#123; unsigned char *zl; unsigned char *eptr, *sptr; &#125; zl; // skiplist编码的集合迭代器 struct &#123; zset *zs; zskiplistNode *node; &#125; sl; &#125; zset; &#125; iter;&#125; zsetopsrc;// 存储迭代器的当前元素的值typedef struct &#123; int flags;//标志数据有效性 unsigned char _buf[32]; //私有缓冲区 sds ele;//sds对象 unsigned char *estr;//字符串 unsigned int elen;//字符串长度 long long ell;//整型数据 double score;//分数&#125; zsetopval;// 集合迭代器初始化void zuiInitIterator(zsetopsrc *op);// 清除集合迭代器不是释放空间void zuiClearIterator(zsetopsrc *op);// 返回迭代器的集合的元素个数int zuiLength(zsetopsrc *op);// 检查当前值时候有效，如果有效，将它存储早val中，移动到下一个元素，如果不合法，意味着我们到达了结构的尾端，程序abortint zuiNext(zsetopsrc *op, zsetopval *val);// 从val存储结构中分获取longlong型数据int zuiLongLongFromValue(zsetopval *val);// 从val存储结构中分获取sds型数据sds zuiSdsFromValue(zsetopval *val);// 从val存储结构中分获取sds型数据的复制sds zuiNewSdsFromValue(zsetopval *val);//从私有缓冲区获取valueint zuiBufferFromValue(zsetopval *val);// 通过val查找集合中的元素，找到返回1，并存储score，否则返回0int zuiFind(zsetopsrc *op, zsetopval *val, double *score); 之后就是zset的相关指令的实现了这里着重注释了交集并集，以及range和add和rem基本指令。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420/* This generic command implements both ZADD and ZINCRBY. */void zaddGenericCommand(client *c, int flags) &#123; static char *nanerr = "resulting score is not a number (NaN)"; robj *key = c-&gt;argv[1]; robj *zobj; sds ele; double score = 0, *scores = NULL; int j, elements; int scoreidx = 0; // 下面的参数用来提示在函数执行后，哪一种操作被执行了 int added = 0; //元素添加了 int updated = 0; //score被更新了 int processed = 0; //没有做操作 // 解析指令，解析可选参数 scoreidx = 2; while(scoreidx &lt; c-&gt;argc) &#123; char *opt = c-&gt;argv[scoreidx]-&gt;ptr; if (!strcasecmp(opt,"nx")) flags |= ZADD_NX; else if (!strcasecmp(opt,"xx")) flags |= ZADD_XX; else if (!strcasecmp(opt,"ch")) flags |= ZADD_CH; else if (!strcasecmp(opt,"incr")) flags |= ZADD_INCR; else break; scoreidx++; &#125; // 转化为变量标记 int incr = (flags &amp; ZADD_INCR) != 0; int nx = (flags &amp; ZADD_NX) != 0; int xx = (flags &amp; ZADD_XX) != 0; int ch = (flags &amp; ZADD_CH) != 0; //添加的元素参数应该是偶数个 elements = c-&gt;argc-scoreidx; if (elements % 2 || !elements) &#123; addReply(c,shared.syntaxerr); return; &#125; elements /= 2; /* Now this holds the number of score-element pairs. */ // 检查不可能的options if (nx &amp;&amp; xx) &#123; addReplyError(c, "XX and NX options at the same time are not compatible"); return; &#125; if (incr &amp;&amp; elements &gt; 1) &#123; addReplyError(c, "INCR option supports a single increment-element pair"); return; &#125; // 在添加之前需要检查每一个参数的正确性 scores = zmalloc(sizeof(double)*elements); for (j = 0; j &lt; elements; j++) &#123; if (getDoubleFromObjectOrReply(c,c-&gt;argv[scoreidx+j*2],&amp;scores[j],NULL) != C_OK) goto cleanup; &#125; // 搜索目标对象，如果不存在创建 zobj = lookupKeyWrite(c-&gt;db,key); if (zobj == NULL) &#123; if (xx) goto reply_to_client; //如果xx，不存在目标对象时不做操作 if (server.zset_max_ziplist_entries == 0 || server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[scoreidx+1]-&gt;ptr)) &#123; zobj = createZsetObject(); &#125; else &#123; zobj = createZsetZiplistObject(); &#125; dbAdd(c-&gt;db,key,zobj); &#125; else &#123; // 存在时检查类型 if (zobj-&gt;type != OBJ_ZSET) &#123; addReply(c,shared.wrongtypeerr); goto cleanup; &#125; &#125; // 对于每一个元素添加，根据retflag的值来更新相关的变量 for (j = 0; j &lt; elements; j++) &#123; double newscore; score = scores[j]; int retflags = flags; ele = c-&gt;argv[scoreidx+1+j*2]-&gt;ptr; int retval = zsetAdd(zobj, score, ele, &amp;retflags, &amp;newscore); if (retval == 0) &#123; addReplyError(c,nanerr); goto cleanup; &#125; if (retflags &amp; ZADD_ADDED) added++; if (retflags &amp; ZADD_UPDATED) updated++; if (!(retflags &amp; ZADD_NOP)) processed++; score = newscore; &#125; server.dirty += (added+updated);reply_to_client: if (incr) &#123; /* ZINCRBY or INCR option. */ if (processed) addReplyDouble(c,score); else addReply(c,shared.nullbulk); &#125; else &#123; /* ZADD. */ addReplyLongLong(c,ch ? added+updated : added); &#125;cleanup: zfree(scores); if (added || updated) &#123; signalModifiedKey(c-&gt;db,key); notifyKeyspaceEvent(NOTIFY_ZSET, incr ? "zincr" : "zadd", key, c-&gt;db-&gt;id); &#125;&#125;void zremrangeGenericCommand(client *c, int rangetype) &#123; robj *key = c-&gt;argv[1]; robj *zobj; int keyremoved = 0; unsigned long deleted = 0; zrangespec range; zlexrangespec lexrange; long start, end, llen; /* Step 1: 解析范围 */ if (rangetype == ZRANGE_RANK) &#123; if ((getLongFromObjectOrReply(c,c-&gt;argv[2],&amp;start,NULL) != C_OK) || (getLongFromObjectOrReply(c,c-&gt;argv[3],&amp;end,NULL) != C_OK)) return; &#125; else if (rangetype == ZRANGE_SCORE) &#123; if (zslParseRange(c-&gt;argv[2],c-&gt;argv[3],&amp;range) != C_OK) &#123; addReplyError(c,"min or max is not a float"); return; &#125; &#125; else if (rangetype == ZRANGE_LEX) &#123; if (zslParseLexRange(c-&gt;argv[2],c-&gt;argv[3],&amp;lexrange) != C_OK) &#123; addReplyError(c,"min or max not valid string range item"); return; &#125; &#125; /* Step 2: 查找目标对象检查类型 */ if ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == NULL || checkType(c,zobj,OBJ_ZSET)) goto cleanup; // 如果ZRANGE_RANK，对start以及end进行标准化 if (rangetype == ZRANGE_RANK) &#123; /* Sanitize indexes. */ llen = zsetLength(zobj); if (start &lt; 0) start = llen+start; if (end &lt; 0) end = llen+end; if (start &lt; 0) start = 0; // 检查start以及end的规范 if (start &gt; end || start &gt;= llen) &#123; addReply(c,shared.czero); goto cleanup; &#125; if (end &gt;= llen) end = llen-1; &#125; /* Step 3: 对不同的底层编码以及不同删除方式执行删除操作 */ if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; switch(rangetype) &#123; case ZRANGE_RANK: zobj-&gt;ptr = zzlDeleteRangeByRank(zobj-&gt;ptr,start+1,end+1,&amp;deleted); break; case ZRANGE_SCORE: zobj-&gt;ptr = zzlDeleteRangeByScore(zobj-&gt;ptr,&amp;range,&amp;deleted); break; case ZRANGE_LEX: zobj-&gt;ptr = zzlDeleteRangeByLex(zobj-&gt;ptr,&amp;lexrange,&amp;deleted); break; &#125; if (zzlLength(zobj-&gt;ptr) == 0) &#123; dbDelete(c-&gt;db,key); keyremoved = 1; &#125; &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = zobj-&gt;ptr; switch(rangetype) &#123; case ZRANGE_RANK: deleted = zslDeleteRangeByRank(zs-&gt;zsl,start+1,end+1,zs-&gt;dict); break; case ZRANGE_SCORE: deleted = zslDeleteRangeByScore(zs-&gt;zsl,&amp;range,zs-&gt;dict); break; case ZRANGE_LEX: deleted = zslDeleteRangeByLex(zs-&gt;zsl,&amp;lexrange,zs-&gt;dict); break; &#125; if (htNeedsResize(zs-&gt;dict)) dictResize(zs-&gt;dict); if (dictSize(zs-&gt;dict) == 0) &#123; dbDelete(c-&gt;db,key); keyremoved = 1; &#125; &#125; else &#123; serverPanic("Unknown sorted set encoding"); &#125; /* Step 4: 发送通知以及返回客户端 */ if (deleted) &#123; char *event[3] = &#123;"zremrangebyrank","zremrangebyscore","zremrangebylex"&#125;; signalModifiedKey(c-&gt;db,key); notifyKeyspaceEvent(NOTIFY_ZSET,event[rangetype],key,c-&gt;db-&gt;id); if (keyremoved) notifyKeyspaceEvent(NOTIFY_GENERIC,"del",key,c-&gt;db-&gt;id); &#125; server.dirty += deleted; addReplyLongLong(c,deleted);cleanup: if (rangetype == ZRANGE_LEX) zslFreeLexRange(&amp;lexrange);&#125;// 并集交集操作命令的实现void zunionInterGenericCommand(client *c, robj *dstkey, int op) &#123; int i, j; long setnum; int aggregate = REDIS_AGGR_SUM; zsetopsrc *src; zsetopval zval; sds tmp; unsigned int maxelelen = 0; robj *dstobj; zset *dstzset; zskiplistNode *znode; int touched = 0; // 检查指令格式，获取必要的参数 if ((getLongFromObjectOrReply(c, c-&gt;argv[2], &amp;setnum, NULL) != C_OK)) return; if (setnum &lt; 1) &#123; addReplyError(c, "at least 1 input key is needed for ZUNIONSTORE/ZINTERSTORE"); return; &#125; /* 检测参数是否超出 */ if (setnum &gt; c-&gt;argc-3) &#123; addReply(c,shared.syntaxerr); return; &#125; // 读取指令的key并且初始化迭代器 src = zcalloc(sizeof(zsetopsrc) * setnum); for (i = 0, j = 3; i &lt; setnum; i++, j++) &#123; robj *obj = lookupKeyWrite(c-&gt;db,c-&gt;argv[j]); if (obj != NULL) &#123; if (obj-&gt;type != OBJ_ZSET &amp;&amp; obj-&gt;type != OBJ_SET) &#123; zfree(src); addReply(c,shared.wrongtypeerr); return; &#125; src[i].subject = obj; src[i].type = obj-&gt;type; src[i].encoding = obj-&gt;encoding; &#125; else &#123; src[i].subject = NULL; &#125; src[i].weight = 1.0;//默认权重为1.0 &#125; // 解析其他参数 权重或者addregate if (j &lt; c-&gt;argc) &#123; int remaining = c-&gt;argc - j; while (remaining) &#123; if (remaining &gt;= (setnum + 1) &amp;&amp; !strcasecmp(c-&gt;argv[j]-&gt;ptr,"weights")) &#123; j++; remaining--; for (i = 0; i &lt; setnum; i++, j++, remaining--) &#123; if (getDoubleFromObjectOrReply(c,c-&gt;argv[j],&amp;src[i].weight, "weight value is not a float") != C_OK) &#123; zfree(src); return; &#125; &#125; &#125; else if (remaining &gt;= 2 &amp;&amp; !strcasecmp(c-&gt;argv[j]-&gt;ptr,"aggregate")) &#123; j++; remaining--; if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,"sum")) &#123; aggregate = REDIS_AGGR_SUM; &#125; else if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,"min")) &#123; aggregate = REDIS_AGGR_MIN; &#125; else if (!strcasecmp(c-&gt;argv[j]-&gt;ptr,"max")) &#123; aggregate = REDIS_AGGR_MAX; &#125; else &#123; zfree(src); addReply(c,shared.syntaxerr); return; &#125; j++; remaining--; &#125; else &#123; zfree(src); addReply(c,shared.syntaxerr); return; &#125; &#125; &#125; // 将参与运算的集合按照集合元素个数排序 qsort(src,setnum,sizeof(zsetopsrc),zuiCompareByCardinality); // 创建存储结果的集合 dstobj = createZsetObject(); dstzset = dstobj-&gt;ptr; memset(&amp;zval, 0, sizeof(zval)); if (op == SET_OP_INTER) &#123; // 交集操作 // 如果最小元素集合为空集那么直接跳过后面的集合 if (zuiLength(&amp;src[0]) &gt; 0) &#123; zuiInitIterator(&amp;src[0]); while (zuiNext(&amp;src[0],&amp;zval)) &#123; double score, value; score = src[0].weight * zval.score; if (isnan(score)) score = 0; for (j = 1; j &lt; setnum; j++) &#123; // 访问我们正在迭代的集合是不安全的，所以特别检查object是否相等 if (src[j].subject == src[0].subject) &#123; value = zval.score*src[j].weight; zunionInterAggregate(&amp;score,value,aggregate); &#125; else if (zuiFind(&amp;src[j],&amp;zval,&amp;value)) &#123; value *= src[j].weight; zunionInterAggregate(&amp;score,value,aggregate); &#125; else &#123; break; &#125; &#125; // 如果所有的集合都包含该集合奖value以及新的score添加到有序集合中 if (j == setnum) &#123; tmp = zuiNewSdsFromValue(&amp;zval); znode = zslInsert(dstzset-&gt;zsl,score,tmp); dictAdd(dstzset-&gt;dict,tmp,&amp;znode-&gt;score); if (sdslen(tmp) &gt; maxelelen) maxelelen = sdslen(tmp); &#125; &#125; zuiClearIterator(&amp;src[0]); &#125; &#125; else if (op == SET_OP_UNION) &#123; // 并集操作 dict *accumulator = dictCreate(&amp;setAccumulatorDictType,NULL); dictIterator *di; dictEntry *de, *existing; double score; if (setnum) &#123; // 按照最大的集合元素数目扩展字典 dictExpand(accumulator,zuiLength(&amp;src[setnum-1])); &#125; for (i = 0; i &lt; setnum; i++) &#123; // 如果集合为空集直接跳过 if (zuiLength(&amp;src[i]) == 0) continue; // 初始化集合迭代器 zuiInitIterator(&amp;src[i]); // 将集合中所有元素加入到accumulator中 while (zuiNext(&amp;src[i],&amp;zval)) &#123; score = src[i].weight * zval.score; if (isnan(score)) score = 0; de = dictAddRaw(accumulator,zuiSdsFromValue(&amp;zval),&amp;existing); if (!existing) &#123; // 如果没有改元素，添加新的元素 tmp = zuiNewSdsFromValue(&amp;zval); if (sdslen(tmp) &gt; maxelelen) maxelelen = sdslen(tmp); dictSetKey(accumulator, de, tmp); dictSetDoubleVal(de,score); &#125; else &#123; // 跟新score zunionInterAggregate(&amp;existing-&gt;v.d,score,aggregate); &#125; &#125; zuiClearIterator(&amp;src[i]); &#125; di = dictGetIterator(accumulator); dictExpand(dstzset-&gt;dict,dictSize(accumulator)); // 将accumulator中的元素添加到结果集中 while((de = dictNext(di)) != NULL) &#123; sds ele = dictGetKey(de); score = dictGetDoubleVal(de); znode = zslInsert(dstzset-&gt;zsl,score,ele); dictAdd(dstzset-&gt;dict,ele,&amp;znode-&gt;score); &#125; dictReleaseIterator(di); dictRelease(accumulator); &#125; else &#123; serverPanic("Unknown operator"); &#125; if (dbDelete(c-&gt;db,dstkey)) touched = 1; if (dstzset-&gt;zsl-&gt;length) &#123; zsetConvertToZiplistIfNeeded(dstobj,maxelelen); dbAdd(c-&gt;db,dstkey,dstobj); addReplyLongLong(c,zsetLength(dstobj)); signalModifiedKey(c-&gt;db,dstkey); notifyKeyspaceEvent(NOTIFY_ZSET, (op == SET_OP_UNION) ? "zunionstore" : "zinterstore", dstkey,c-&gt;db-&gt;id); server.dirty++; &#125; else &#123; decrRefCount(dstobj); addReply(c,shared.czero); if (touched) &#123; signalModifiedKey(c-&gt;db,dstkey); notifyKeyspaceEvent(NOTIFY_GENERIC,"del",dstkey,c-&gt;db-&gt;id); server.dirty++; &#125; &#125; zfree(src);&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(11)——t_set篇]]></title>
    <url>%2F2017%2F09%2F18%2Fredis%E6%BA%90%E7%A0%81-11-%E2%80%94%E2%80%94t-set%E7%AF%87%2F</url>
    <content type="text"><![CDATA[集合分为无序集合以及有序集合，t_set.c是对无序集合的实现，包含无序集合的操作函数，以及关于set的指令的实现。set的底层编码有两种，inset以及dict，当集合元素为整型并且元素的个数小于512时，底层编码为inset，否则底层编码为dict字典实现，用key存储元素值，value为null。下面列出所有set类型的操作函数定义，基于inset以及dict操作实现。12345678910111213141516171819202122// 根据value是整型还是字符型来创建一个inset或hash的集合对象robj *setTypeCreate(sds value);// 往集合中添加value，如果存在返回0，如果不存在添加返回1int setTypeAdd(robj *subject, sds value);// 删除集合中元素int setTypeRemove(robj *setobj, sds value);// 判断value是否是集合的元素int setTypeIsMember(robj *subject, sds value);// 初始化set迭代器setTypeIterator *setTypeInitIterator(robj *subject);// 释放set迭代器void setTypeReleaseIterator(setTypeIterator *si);// 如果没有下一个元素返回-1，如果存在下一个元素，值存在sdsele或llele中，并且返回set的实现编码int setTypeNext(setTypeIterator *si, sds *sdsele, int64_t *llele);// 如果没有下一个元素或未知的编码返回null，否则返回sds对象sds setTypeNextObject(setTypeIterator *si);// 从一个非空的集合中随机返回一个元素，同样返回集合编码，用sdsele或者llele存储int setTypeRandomElement(robj *setobj, sds *sdsele, int64_t *llele);// 返回集合的元素数量unsigned long setTypeSize(const robj *subject);// 转换集合的编码void setTypeConvert(robj *setobj, int enc); 下面是相关的数据结构：1234567// 无序集合的迭代器typedef struct &#123; robj *subject;//存储迭代器的集合对象 int encoding;//存储集合对象的底层编码 int ii; //inset的迭代器 dictIterator *di;//dict的迭代器&#125; setTypeIterator; 对于setcommand实现中比较重要的就是交集并集以及差集的指令实现了，在各自的实现中有redis编写者关于不同元素数量级的不同处理方案，以及考虑到实际算法效率的不同处理过程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390//相交集合指令函数实现，setkeys是所有交集集合的keys，setnum为集合个数，dstkey为结果存储的集合的keyvoid sinterGenericCommand(client *c, robj **setkeys, unsigned long setnum, robj *dstkey) &#123; // 分配集合对象空间，用来存储所有参与运算的集合 robj **sets = zmalloc(sizeof(robj*)*setnum); setTypeIterator *si; robj *dstset = NULL; sds elesds; int64_t intobj; void *replylen = NULL; unsigned long j, cardinality = 0; int encoding; for (j = 0; j &lt; setnum; j++) &#123; robj *setobj = dstkey ? lookupKeyWrite(c-&gt;db,setkeys[j]) : lookupKeyRead(c-&gt;db,setkeys[j]); if (!setobj) &#123; // 查找不到对应的集合，释放空间，删除库中的dstkey集合 zfree(sets); if (dstkey) &#123; if (dbDelete(c-&gt;db,dstkey)) &#123; signalModifiedKey(c-&gt;db,dstkey); server.dirty++; &#125; addReply(c,shared.czero); &#125; else &#123; addReply(c,shared.emptymultibulk); &#125; return; &#125; // 检查参与运算的对象是否为集合对象 if (checkType(c,setobj,OBJ_SET)) &#123; zfree(sets); return; &#125; // 填装集合 sets[j] = setobj; &#125; // 由于下面的算法需要，将所有集合按照元素个数从小到大排序，这里qsort是一个lua脚本 qsort(sets,setnum,sizeof(robj*),qsortCompareSetsByCardinality); // 如果不需要存储结果，先添加一个空对象，在之后得到结果元素个数时再修改 if (!dstkey) &#123; replylen = addDeferredMultiBulkLength(c); &#125; else &#123; // 创建一个提供存储结果的集合 dstset = createIntsetObject(); &#125; // 迭代第一个集合中的所有元素，对于之后的所有集合，如果有一个集合不包含该元素，直接跳过，如果所有集合都包含，那么此元素加入结果集 si = setTypeInitIterator(sets[0]); while((encoding = setTypeNext(si,&amp;elesds,&amp;intobj)) != -1) &#123; for (j = 1; j &lt; setnum; j++) &#123; // 两个集合相同不需要比较 if (sets[j] == sets[0]) continue; if (encoding == OBJ_ENCODING_INTSET) &#123; // 都是inset操作简单 if (sets[j]-&gt;encoding == OBJ_ENCODING_INTSET &amp;&amp; !intsetFind((intset*)sets[j]-&gt;ptr,intobj)) &#123; break; // 对于dict底层编码，现将intobj包装成sds然后调用settype函数 &#125; else if (sets[j]-&gt;encoding == OBJ_ENCODING_HT) &#123; elesds = sdsfromlonglong(intobj); if (!setTypeIsMember(sets[j],elesds)) &#123; sdsfree(elesds); break; &#125; sdsfree(elesds); &#125; // 编码都是dict比较简单 &#125; else if (encoding == OBJ_ENCODING_HT) &#123; if (!setTypeIsMember(sets[j],elesds)) &#123; break; &#125; &#125; &#125; // 意味着所有集合都包含该元素 if (j == setnum) &#123; // 如果不需要存储，直接将元素加入客户端缓冲区中 if (!dstkey) &#123; if (encoding == OBJ_ENCODING_HT) addReplyBulkCBuffer(c,elesds,sdslen(elesds)); else addReplyBulkLongLong(c,intobj); cardinality++; &#125; else &#123; // 如果需要存储将元素添加的结果集中 if (encoding == OBJ_ENCODING_INTSET) &#123; elesds = sdsfromlonglong(intobj); setTypeAdd(dstset,elesds); sdsfree(elesds); &#125; else &#123; setTypeAdd(dstset,elesds); &#125; &#125; &#125; &#125; setTypeReleaseIterator(si); if (dstkey) &#123; // 如果需要存储结果集，首先删除原有的dstkey对应的集合对象 int deleted = dbDelete(c-&gt;db,dstkey); if (setTypeSize(dstset) &gt; 0) &#123; dbAdd(c-&gt;db,dstkey,dstset); addReplyLongLong(c,setTypeSize(dstset)); notifyKeyspaceEvent(NOTIFY_SET,"sinterstore", dstkey,c-&gt;db-&gt;id); &#125; else &#123; // 如果结果集为空，那么结果报告为0，并且通知将dstkey的集合对象删除事件 decrRefCount(dstset); addReply(c,shared.czero); if (deleted) notifyKeyspaceEvent(NOTIFY_GENERIC,"del", dstkey,c-&gt;db-&gt;id); &#125; signalModifiedKey(c-&gt;db,dstkey); server.dirty++; &#125; else &#123; // 不需要存储则将之前的replylen长度修改返回 setDeferredMultiBulkLength(c,replylen,cardinality); &#125; zfree(sets);&#125;// 并集以及差集运算的实现，op表示运算的符号void sunionDiffGenericCommand(client *c, robj **setkeys, int setnum, robj *dstkey, int op) &#123; robj **sets = zmalloc(sizeof(robj*)*setnum); setTypeIterator *si; robj *dstset = NULL; sds ele; int j, cardinality = 0; int diff_algo = 1; // 下段代码与交集实现函数差不多 for (j = 0; j &lt; setnum; j++) &#123; robj *setobj = dstkey ? lookupKeyWrite(c-&gt;db,setkeys[j]) : lookupKeyRead(c-&gt;db,setkeys[j]); if (!setobj) &#123; sets[j] = NULL; continue; &#125; if (checkType(c,setobj,OBJ_SET)) &#123; zfree(sets); return; &#125; sets[j] = setobj; &#125; // 对于差集计算有两种算法 // 算法一的效率为O(N*M)，N为第一个集合的元素个数，M为所有的集合个数 // 算法二的效率为O(N)，N为所有集合的元素个数和 // 我们根据具体的元素情况来确定使用哪一种算法 if (op == SET_OP_DIFF &amp;&amp; sets[0]) &#123; long long algo_one_work = 0, algo_two_work = 0; // 计算两种算法的效率 for (j = 0; j &lt; setnum; j++) &#123; if (sets[j] == NULL) continue; algo_one_work += setTypeSize(sets[0]); algo_two_work += setTypeSize(sets[j]); &#125; // 算法一拥有固定的时间并且执行较少的字典操作所以给他一点优势 algo_one_work /= 2; diff_algo = (algo_one_work &lt;= algo_two_work) ? 1 : 2; if (diff_algo == 1 &amp;&amp; setnum &gt; 1) &#123; // 便于算法的时间减少，如果算法一，将之后的集合按照元素个数，从小到大排序 qsort(sets+1,setnum-1,sizeof(robj*), qsortCompareSetsByRevCardinality); &#125; &#125; // 创建一个临时的集合对象用来存储运算的结果，如果需要存储结果，就将该集合存储在数据库中 dstset = createIntsetObject(); if (op == SET_OP_UNION) &#123; // 对于并集操作就是将所有集合的元素加入到临时集合对象中，最后就可以得到结果集了 for (j = 0; j &lt; setnum; j++) &#123; if (!sets[j]) continue; //空集合直接跳过 si = setTypeInitIterator(sets[j]); while((ele = setTypeNextObject(si)) != NULL) &#123; if (setTypeAdd(dstset,ele)) cardinality++; sdsfree(ele); &#125; setTypeReleaseIterator(si); &#125; &#125; else if (op == SET_OP_DIFF &amp;&amp; sets[0] &amp;&amp; diff_algo == 1) &#123; // 对于差集的算法一，迭代第一个集合中的所有元素，对于其他所有集合都不包含的元素加入到结果集中 si = setTypeInitIterator(sets[0]); while((ele = setTypeNextObject(si)) != NULL) &#123; for (j = 1; j &lt; setnum; j++) &#123; if (!sets[j]) continue; //空集合所有不含直接跳过 if (sets[j] == sets[0]) break; //相同的集合必然包含跳出循环，结果集必为空 if (setTypeIsMember(sets[j],ele)) break;//一旦有其他集合包含，跳出循环 &#125; if (j == setnum) &#123; // 没有其他元素包含该元素加入到结果集中 setTypeAdd(dstset,ele); cardinality++; &#125; sdsfree(ele); &#125; setTypeReleaseIterator(si); &#125; else if (op == SET_OP_DIFF &amp;&amp; sets[0] &amp;&amp; diff_algo == 2) &#123; // 对于差集第二种算法，将第一个集合的元素加入到集合中，剩下的集合的所有元素，从临时集合中删去，最后就可以得到结果集合了 for (j = 0; j &lt; setnum; j++) &#123; if (!sets[j]) continue; //空集合直接跳过 si = setTypeInitIterator(sets[j]); while((ele = setTypeNextObject(si)) != NULL) &#123; if (j == 0) &#123; // 第一个集合添加元素 if (setTypeAdd(dstset,ele)) cardinality++; &#125; else &#123; // 其他集合元素执行删除 if (setTypeRemove(dstset,ele)) cardinality--; &#125; sdsfree(ele); &#125; setTypeReleaseIterator(si); // 如果结果集合已经为空了，剩下的集合元素删除没有意义直接跳出循环 if (cardinality == 0) break; &#125; &#125; // 如果没有存储需求，输出结果到客户端 if (!dstkey) &#123; addReplyMultiBulkLen(c,cardinality); si = setTypeInitIterator(dstset); while((ele = setTypeNextObject(si)) != NULL) &#123; addReplyBulkCBuffer(c,ele,sdslen(ele)); sdsfree(ele); &#125; setTypeReleaseIterator(si); decrRefCount(dstset); &#125; else &#123; // 先删除原有的数据对象 int deleted = dbDelete(c-&gt;db,dstkey); if (setTypeSize(dstset) &gt; 0) &#123; // 如果结果集有元素，存储集合对象，输出结果集个数 dbAdd(c-&gt;db,dstkey,dstset); addReplyLongLong(c,setTypeSize(dstset)); notifyKeyspaceEvent(NOTIFY_SET, op == SET_OP_UNION ? "sunionstore" : "sdiffstore", dstkey,c-&gt;db-&gt;id); &#125; else &#123; decrRefCount(dstset); addReply(c,shared.czero); if (deleted) notifyKeyspaceEvent(NOTIFY_GENERIC,"del", dstkey,c-&gt;db-&gt;id); &#125; signalModifiedKey(c-&gt;db,dstkey); server.dirty++; &#125; zfree(sets);&#125;// 用来处理SRANDMEMBER key &lt;count&gt;指令// 对于不同count参数会采取不同策略完成指令#define SRANDMEMBER_SUB_STRATEGY_MUL 3void srandmemberWithCountCommand(client *c) &#123; long l; unsigned long count, size; int uniq = 1; robj *set; sds ele; int64_t llele; int encoding; dict *d; // 获取count参数，如果count为负数，则从集合中可能随机重复的元素 if (getLongFromObjectOrReply(c,c-&gt;argv[2],&amp;l,NULL) != C_OK) return; if (l &gt;= 0) &#123; count = (unsigned) l; &#125; else &#123; count = -l; uniq = 0; &#125; // 查找数据库中对用的集合对象并且检查类型 if ((set = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.emptymultibulk)) == NULL || checkType(c,set,OBJ_SET)) return; size = setTypeSize(set); // 如果count=0则直接返回空值给客户端，返回 if (count == 0) &#123; addReply(c,shared.emptymultibulk); return; &#125; // case1:如果count为负数，那么从集合中随机元素，重复count次即可 if (!uniq) &#123; addReplyMultiBulkLen(c,count); while(count--) &#123; encoding = setTypeRandomElement(set,&amp;ele,&amp;llele); if (encoding == OBJ_ENCODING_INTSET) &#123; addReplyBulkLongLong(c,llele); &#125; else &#123; addReplyBulkCBuffer(c,ele,sdslen(ele)); &#125; &#125; return; &#125; // case2:count为正数，并且大于集合的size，那么直接返回整个集合 if (count &gt;= size) &#123; sunionDiffGenericCommand(c,c-&gt;argv+1,1,NULL,SET_OP_UNION); return; &#125; // 对于下面两种case，为了随机不重复的元素，创建一个辅助的字典 d = dictCreate(&amp;objectKeyPointerValueDictType,NULL); /* CASE 3: * The number of elements inside the set is not greater than * SRANDMEMBER_SUB_STRATEGY_MUL times the number of requested elements. * In this case we create a set from scratch with all the elements, and * subtract random elements to reach the requested number of elements. * * This is done because if the number of requsted elements is just * a bit less than the number of elements in the set, the natural approach * used into CASE 3 is highly inefficient. */ // case3:如果count的三倍大于集合的size，即count相较于size不过小，那么采用这种方法， // 现将所有的元素加到结果集中，然后从结果集中随机删除size-count个元素得到结果集 if (count*SRANDMEMBER_SUB_STRATEGY_MUL &gt; size) &#123; setTypeIterator *si; si = setTypeInitIterator(set); // 将所有的元素加到结果集中 while((encoding = setTypeNext(si,&amp;ele,&amp;llele)) != -1) &#123; int retval = DICT_ERR; if (encoding == OBJ_ENCODING_INTSET) &#123; retval = dictAdd(d,createStringObjectFromLongLong(llele),NULL); &#125; else &#123; retval = dictAdd(d,createStringObject(ele,sdslen(ele)),NULL); &#125; serverAssert(retval == DICT_OK); &#125; setTypeReleaseIterator(si); serverAssert(dictSize(d) == size); // 随机删除结果集中的元素，直到size=count while(size &gt; count) &#123; dictEntry *de; de = dictGetRandomKey(d); dictDelete(d,dictGetKey(de)); size--; &#125; &#125; // case4:count相交于集合size较小时，采用这中方式得到结果集 // 从集合中随机元素加到结果集中，直到结果集的size=count else &#123; unsigned long added = 0; robj *objele; while(added &lt; count) &#123; // 随机元素添加到结果集中 encoding = setTypeRandomElement(set,&amp;ele,&amp;llele); if (encoding == OBJ_ENCODING_INTSET) &#123; objele = createStringObjectFromLongLong(llele); &#125; else &#123; objele = createStringObject(ele,sdslen(ele)); &#125; // 如果添加成功，那么add++，如果有重复的元素，那么添加不成功，直到add=count，结果集完成 if (dictAdd(d,objele,NULL) == DICT_OK) added++; else decrRefCount(objele); &#125; &#125; // case3和4将结果集返回给客户端 &#123; dictIterator *di; dictEntry *de; addReplyMultiBulkLen(c,count); di = dictGetIterator(d); while((de = dictNext(di)) != NULL) addReplyBulk(c,dictGetKey(de)); dictReleaseIterator(di); dictRelease(d); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(10)——t_hash篇]]></title>
    <url>%2F2017%2F09%2F15%2Fredis%E6%BA%90%E7%A0%81-10-%E2%80%94%E2%80%94t-hash%E7%AF%87%2F</url>
    <content type="text"><![CDATA[t_hash.c源文件中也分为两个部分，关于hash表的操作以及关于hash表指令的实现。不同于list的底层实现只有quicklist，对于hash可能有两种底层实现，所以必须有ziplist到dict的实现的转化函数实现，两种底层实现转化的条件是：hash-max-ziplist-value 64 // ziplist中最大能存放的值长度hash-max-ziplist-entries 512 // ziplist中最多能存放的entry节点数量存储在redis.conf文件中，拥有默认值，当ziplist中实体个数超过上限，或者单个实体的长度超过上限那么将会从ziplist转换为dict的底层实现。下面列出所有hash的操作函数以及相关的数据结构：12345678910111213141516171819202122232425262728293031323334353637383940// 检查所有的实体值长度，达到上限时转化hash的底层实现void hashTypeTryConversion(robj *o, robj **argv, int start, int end);// 根据给定的field从ziplist底层实现的字典中查找值，如果是字符串用vstr保存长度用vlen保存，数字用vll保存int hashTypeGetFromZiplist(robj *o, sds field,unsigned char **vstr,unsigned int *vlen,long long *vll);// 根据给定的field从dict底层实现的字典中查找值，返回sds对象sds hashTypeGetFromHashTable(robj *o, sds field);// 根据给定的field从hash中查找值，不管底层实现，只有在ziplist底层实现并且值为数字时，vll才有值int hashTypeGetValue(robj *o, sds field, unsigned char **vstr, unsigned int *vlen, long long *vll);// 根据给定的field从hash中查找值，都返回robj对象robj *hashTypeGetValueObject(robj *o, sds field);// 根据给定的field从hash中查找值，返回值的长度size_t hashTypeGetValueLength(robj *o, sds field);// 判断hash是否存在field对应的值int hashTypeExists(robj *o, sds field);// 往hash对象中添加键值对，或者修改原来存在的键值对，如果添加返回1，如果跟新返回0int hashTypeSet(robj *o, sds field, sds value, int flags);// 删除hash对象中对应的键值对，成功返回1，没有找到返回0int hashTypeDelete(robj *o, sds field);// 返回hash字典中键值对的个数unsigned long hashTypeLength(const robj *o);// 初始化hash的迭代器，不同的底层实现不同的初始化方式，在底层实现转化时，需要跟新迭代器hashTypeIterator *hashTypeInitIterator(robj *subject);// 释放hash的迭代器void hashTypeReleaseIterator(hashTypeIterator *hi);// hash迭代器往后移动int hashTypeNext(hashTypeIterator *hi);// 在ziplist的底层实现中，获取当前迭代器指向的键值对的值，根据what决定key或者valuevoid hashTypeCurrentFromZiplist(hashTypeIterator *hi, int what,unsigned char **vstr,unsigned int *vlen,long long *vll);// 在dict的底层实现中，获取当前迭代器指向的键值对的值，根据what决定key或者valuesds hashTypeCurrentFromHashTable(hashTypeIterator *hi, int what);// 不管底层实现，获取当前迭代器指向的键值对的值，根据what决定key或者valuevoid hashTypeCurrentObject(hashTypeIterator *hi, int what, unsigned char **vstr, unsigned int *vlen, long long *vll);// 不管底层实现,获取当前迭代器指向的键值对的值，根据what决定key或者value,用sds返回sds hashTypeCurrentObjectNewSds(hashTypeIterator *hi, int what);// 在数据库查找字典如果不存在创建一个新的字典，返回查找的对象robj *hashTypeLookupWriteOrCreate(client *c, robj *key);// 根据enc，进行底层实现的转换void hashTypeConvertZiplist(robj *o, int enc);// 字典底层实现转换，o的enc为dict时不转换。void hashTypeConvert(robj *o, int enc); 下面列出所有新出现的结构体：1234567891011// hash迭代器typedef struct &#123; robj *subject;//迭代器的字典对象 int encoding;//字典的编码 //当底层实现为ziplist时，指向当前的key以及value指针 unsigned char *fptr, *vptr; //当底层实现为dict时，字典的迭代器 dictIterator *di; //当前指向的字典键值对 dictEntry *de;&#125; hashTypeIterator; 下面注释关于这个迭代器的初始化以及指向移动操作函数；12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849hashTypeIterator *hashTypeInitIterator(robj *subject) &#123; hashTypeIterator *hi = zmalloc(sizeof(hashTypeIterator));//分配空间 hi-&gt;subject = subject;//设置字典对象以及对象编码 hi-&gt;encoding = subject-&gt;encoding; // 如果底层实现为ziplist，对key以及value的指针初始化即可 if (hi-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; hi-&gt;fptr = NULL; hi-&gt;vptr = NULL; &#125; else if (hi-&gt;encoding == OBJ_ENCODING_HT) &#123; // 如果底层实现时dict那么直接设置dict的迭代器 hi-&gt;di = dictGetIterator(subject-&gt;ptr); &#125; else &#123; serverPanic("Unknown hash encoding"); &#125; return hi;&#125;int hashTypeNext(hashTypeIterator *hi) &#123; if (hi-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; unsigned char *zl; unsigned char *fptr, *vptr; zl = hi-&gt;subject-&gt;ptr; fptr = hi-&gt;fptr; vptr = hi-&gt;vptr; // 如果指针为空，说明迭代器刚出实话，将指针指向第一个键值对 if (fptr == NULL) &#123; serverAssert(vptr == NULL); fptr = ziplistIndex(zl, 0); &#125; else &#123; // 否则将key值指向当前value的下一个实体 serverAssert(vptr != NULL); fptr = ziplistNext(zl, vptr); &#125; // 已经到了最后一个键值对 if (fptr == NULL) return C_ERR; // 将value指针指向当前key对应的值 vptr = ziplistNext(zl, fptr); serverAssert(vptr != NULL); // 设置迭代器的值 hi-&gt;fptr = fptr; hi-&gt;vptr = vptr; &#125; else if (hi-&gt;encoding == OBJ_ENCODING_HT) &#123; // 在dict中找下一个键值对，如果已经到最后一个了返回错误 if ((hi-&gt;de = dictNext(hi-&gt;di)) == NULL) return C_ERR; &#125; else &#123; serverPanic("Unknown hash encoding"); &#125; return C_OK;&#125; 下面是关于hash的命令的函数实现注释：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115// hincrbyfloat命令的实现void hincrbyfloatCommand(client *c) &#123; long double value, incr; long long ll; robj *o; sds new; unsigned char *vstr; unsigned int vlen; // 获取指令中的float参数 if (getLongDoubleFromObjectOrReply(c,c-&gt;argv[3],&amp;incr,NULL) != C_OK) return; if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;//获取对应的字典对象，不存在就创建新的字典对象 if (hashTypeGetValue(o,c-&gt;argv[2]-&gt;ptr,&amp;vstr,&amp;vlen,&amp;ll) == C_OK) &#123; //获取原来的value值 if (vstr) &#123; if (string2ld((char*)vstr,vlen,&amp;value) == 0) &#123; // value值不是一个浮点型 addReplyError(c,"hash value is not a float"); return; &#125; &#125; else &#123; value = (long double)ll;//类型转换 &#125; &#125; else &#123; // 不存在key的键值对时，value设为0 value = 0; &#125; value += incr;//修改后的value值 char buf[256]; int len = ld2string(buf,sizeof(buf),value,1); new = sdsnewlen(buf,len); hashTypeSet(o,c-&gt;argv[2]-&gt;ptr,new,HASH_SET_TAKE_VALUE);//对新的键值对跟新或者添加 addReplyBulkCBuffer(c,buf,len); signalModifiedKey(c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_HASH,"hincrbyfloat",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++; // 为了防止在aof或者回复过程中，由于机器架构的原因，导致浮点型的值更新不同，所以将指令改为hset。 robj *aux, *newobj; aux = createStringObject("HSET",4); newobj = createRawStringObject(buf,len); rewriteClientCommandArgument(c,0,aux); decrRefCount(aux); rewriteClientCommandArgument(c,3,newobj); decrRefCount(newobj);&#125;// 对当前键值对的处理输出函数static void addHashIteratorCursorToReply(client *c, hashTypeIterator *hi, int what) &#123; if (hi-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;//对底层编码为ziplist的处理 unsigned char *vstr = NULL; unsigned int vlen = UINT_MAX; long long vll = LLONG_MAX; //获取当前键值对的key或value hashTypeCurrentFromZiplist(hi, what, &amp;vstr, &amp;vlen, &amp;vll); if (vstr) addReplyBulkCBuffer(c, vstr, vlen); else addReplyBulkLongLong(c, vll); &#125; else if (hi-&gt;encoding == OBJ_ENCODING_HT) &#123; //对底层编码为dict的处理 sds value = hashTypeCurrentFromHashTable(hi, what); addReplyBulkCBuffer(c, value, sdslen(value)); &#125; else &#123; serverPanic("Unknown hash encoding"); &#125;&#125;// hgetall hkeys hvals指令实现，flags用来标记是get，键值还是value值，还是都要void genericHgetallCommand(client *c, int flags) &#123; robj *o; hashTypeIterator *hi; int multiplier = 0; int length, count = 0; if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.emptymultibulk)) == NULL || checkType(c,o,OBJ_HASH)) return; if (flags &amp; OBJ_HASH_KEY) multiplier++; if (flags &amp; OBJ_HASH_VALUE) multiplier++; // 计算应该输出的字符串个数，在函数结尾有断言判断 length = hashTypeLength(o) * multiplier; addReplyMultiBulkLen(c, length); // 初始化迭代器，对每一个键值对调用addHashIteratorCursorToReply函数输出键值对需要的值 hi = hashTypeInitIterator(o); while (hashTypeNext(hi) != C_ERR) &#123; if (flags &amp; OBJ_HASH_KEY) &#123;//输出key值 addHashIteratorCursorToReply(c, hi, OBJ_HASH_KEY); count++; &#125; if (flags &amp; OBJ_HASH_VALUE) &#123;//输出value值 addHashIteratorCursorToReply(c, hi, OBJ_HASH_VALUE); count++; &#125; &#125; // 释放hash的迭代器 hashTypeReleaseIterator(hi); serverAssert(count == length);&#125;// hlen指令返回所有的键值对个数void hlenCommand(client *c) &#123; robj *o; if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL || checkType(c,o,OBJ_HASH)) return; addReplyLongLong(c,hashTypeLength(o));&#125;// hstrlen指令返回key对应的value的长度void hstrlenCommand(client *c) &#123; robj *o; if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL || checkType(c,o,OBJ_HASH)) return; addReplyLongLong(c,hashTypeGetValueLength(o,c-&gt;argv[2]-&gt;ptr));&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(9)——t_list篇]]></title>
    <url>%2F2017%2F09%2F12%2Fredis%E6%BA%90%E7%A0%81-9-%E2%80%94%E2%80%94t-list%E7%AF%87%2F</url>
    <content type="text"><![CDATA[在t_list.c中主要分为两个部分关于list操作api函数以及关于list command的api函数。下面列出关于list操作的函数定义,这些函数是基于list底层实现quicklist的操作的再一次包装，提供常用的操作函数。123456789101112131415161718192021222324//根据where往list的头或尾添加对象void listTypePush(robj *subject, robj *value, int where);//list弹出对象的保存函数以对象指针返回void *listPopSaver(unsigned char *data, unsigned int sz);//根据where从list头或尾弹出对象，并返回对象指针robj *listTypePop(robj *subject, int where);//获取list的长度即对象个数unsigned long listTypeLength(const robj *subject);//初始化list的迭代器，direction为迭代方向，index为当前迭代器指向的对象序数listTypeIterator *listTypeInitIterator(robj *subject, long index,unsigned char direction);//释放list迭代器void listTypeReleaseIterator(listTypeIterator *li);//迭代器指向对象按照方向往后移动int listTypeNext(listTypeIterator *li, listTypeEntry *entry);//获取迭代器当前指向的对象robj *listTypeGet(listTypeEntry *entry);//根据where往list中value对象的前或后面添加对象void listTypeInsert(listTypeEntry *entry, robj *value, int where); //判断对象是否相同int listTypeEqual(listTypeEntry *entry, robj *o);//删除list中的实体void listTypeDelete(listTypeIterator *iter, listTypeEntry *entry);//将底层为ziplist的list转换为quicklistvoid listTypeConvert(robj *subject, int enc); 123456789101112//list对象迭代器typedef struct &#123; robj *subject;//quicklist实现的list对象 unsigned char encoding;//编码 unsigned char direction;//迭代器方向 quicklistIter *iter;//真正的迭代器指针&#125; listTypeIterator;//list中存储对象实体typedef struct &#123; listTypeIterator *li;//当前list存储实体迭代器 quicklistEntry entry;//实体对象的指针&#125; listTypeEntry; 下面就是关于list的指令函数的实现，list指令分为非阻塞以及阻塞指令：阻塞指令包括下面三个指令：123BLPOP key [key ...] timeout BRPOP key [key ...] timeoutBRPOPLPUSH source destination timeout 非阻塞指令即当弹出元素时不存在该list或者list为空时，返回错误提示给客户端，不会使client停止工作。而对于阻塞指令，出现上面的情况，会阻塞相关的client直到，其他client对数据库中list执行push操作后，才解除阻塞状态，timeout为阻塞的时长，timeout等于0时，表示无限阻塞。由于其他command命令实现较简单，这里主要解释关于阻塞指令的部分：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313/*----------------------------------------------------------------------------- * Blocking POP operations *----------------------------------------------------------------------------*//*现在阻塞pop指令的工作方式，以我们使用blpop为例子：* 如果我们调用blpop时，键存在并且包含一个非空的list，那么用lpop代替。所以当阻塞不需要时，lpop与blpop相同。* 相反如果blpop被调用时，键不存在或者相应的list为空，那么我们需要阻塞，我们去除所有新的读请求的通知，即如果阻塞命令没有完成，那么不会相应新的请求指令，同时我们将client放到* db-&gt;blocking_key字典中，表示所有被该key阻塞的client列表。* 如果一个push操作在等待中的阻塞客户的key上执行，那么我们将这个key设为ready，在当前指令，事务块脚本被执行后，我们为所有list中等待的client服务，从第一个阻塞的到最后一个，根据readylist中key值。*///设置client为阻塞状态应为特殊的key，并且加上阻塞时限//client:执行指令的客户端//keys:所有的key值//numkeys:key值的个数//timeout:阻塞时限//brpoplpush指令的push的对象，其他指令设为nullvoid blockForKeys(client *c, robj **keys, int numkeys, mstime_t timeout, robj *target) &#123; dictEntry *de; list *l; int j; // 设置时限以及push的对象 c-&gt;bpop.timeout = timeout; c-&gt;bpop.target = target; if (target != NULL) incrRefCount(target); // 记录此client所有造成阻塞的key，以及更新db中因为该key而阻塞的所有client for (j = 0; j &lt; numkeys; j++) &#123; // 如果该key已经在client中阻塞了，跳过到下一个key if (dictAdd(c-&gt;bpop.keys,keys[j],NULL) != DICT_OK) continue; incrRefCount(keys[j]); // 如果db中没有应为该key阻塞的client，创建这样的mapping，value设为包含client的list，否则直接在list尾添加client de = dictFind(c-&gt;db-&gt;blocking_keys,keys[j]); if (de == NULL) &#123; int retval; l = listCreate(); retval = dictAdd(c-&gt;db-&gt;blocking_keys,keys[j],l); incrRefCount(keys[j]); serverAssertWithInfo(c,keys[j],retval == DICT_OK); &#125; else &#123; l = dictGetVal(de); &#125; listAddNodeTail(l,c); &#125; //client改为阻塞状态，并且跟新sever中参数值 blockClient(c,BLOCKED_LIST);&#125;// 解除client的阻塞状态，此函数不会直接调用，通过unblockClient()函数调用。void unblockClientWaitingData(client *c) &#123; dictEntry *de; dictIterator *di; list *l; // 确保此client处于阻塞状态中 serverAssertWithInfo(c,NULL,dictSize(c-&gt;bpop.keys) != 0); di = dictGetIterator(c-&gt;bpop.keys); // 对于阻塞client的每一个key，跟新db-&gt;blocking_keys的client列表，去除列表中相应client while((de = dictNext(di)) != NULL) &#123; robj *key = dictGetKey(de); l = dictFetchValue(c-&gt;db-&gt;blocking_keys,key); serverAssertWithInfo(c,key,l != NULL); // 去除列表中的client listDelNode(l,listSearchKey(l,c)); // 如果list为空，去除字典中的mapping if (listLength(l) == 0) dictDelete(c-&gt;db-&gt;blocking_keys,key); &#125; dictReleaseIterator(di); dictEmpty(c-&gt;bpop.keys,NULL); if (c-&gt;bpop.target) &#123; decrRefCount(c-&gt;bpop.target); c-&gt;bpop.target = NULL; &#125;&#125;// readylist是一个hash表防止我们在多次push操作后，将key多次加入list中// 每一次调用了push操作时，都要调用该函数，检查该数据库是否有阻塞的key，如果有假如到readylist中，以便后面的handleClientsBlockedOnLists函数来处理void signalListAsReady(redisDb *db, robj *key) &#123; readyList *rl; if (dictFind(db-&gt;blocking_keys,key) == NULL) return; if (dictFind(db-&gt;ready_keys,key) != NULL) return; rl = zmalloc(sizeof(*rl)); rl-&gt;key = key; rl-&gt;db = db; incrRefCount(key); listAddNodeTail(server.ready_keys,rl); incrRefCount(key); serverAssert(dictAdd(db-&gt;ready_keys,key,NULL) == DICT_OK);&#125;// 给相应的client提供服务，完成之前阻塞的指令，并给予客户端提示int serveClientBlockedOnList(client *receiver, robj *key, robj *dstkey, redisDb *db, robj *value, int where)&#123; robj *argv[3]; if (dstkey == NULL) &#123; /* Propagate the [LR]POP operation. */ argv[0] = (where == LIST_HEAD) ? shared.lpop : shared.rpop; argv[1] = key; propagate((where == LIST_HEAD) ? server.lpopCommand : server.rpopCommand, db-&gt;id,argv,2,PROPAGATE_AOF|PROPAGATE_REPL); /* BRPOP/BLPOP */ addReplyMultiBulkLen(receiver,2); addReplyBulk(receiver,key); addReplyBulk(receiver,value); &#125; else &#123; /* BRPOPLPUSH */ robj *dstobj = lookupKeyWrite(receiver-&gt;db,dstkey); if (!(dstobj &amp;&amp; checkType(receiver,dstobj,OBJ_LIST))) &#123; /* Propagate the RPOP operation. */ argv[0] = shared.rpop; argv[1] = key; propagate(server.rpopCommand, db-&gt;id,argv,2, PROPAGATE_AOF| PROPAGATE_REPL); rpoplpushHandlePush(receiver,dstkey,dstobj, value); /* Propagate the LPUSH operation. */ argv[0] = shared.lpush; argv[1] = dstkey; argv[2] = value; propagate(server.lpushCommand, db-&gt;id,argv,3, PROPAGATE_AOF| PROPAGATE_REPL); &#125; else &#123; /* BRPOPLPUSH failed because of wrong * destination type. */ return C_ERR; &#125; &#125; return C_OK;&#125;// 这个函数在每次单独指令，事务块或脚本执行后被调用。// 所有阻塞至少一个客户端的key在至少一次push操作后被加入到readylist中，之后这个函数会服务这些阻塞的客户端。// 注意这个函数可以不停的迭代，应为brpoppush中的push操作的作用。void handleClientsBlockedOnLists(void) &#123; while(listLength(server.ready_keys) != 0) &#123; list *l; // 将之前的readylist保存下来，创建新的list，是考虑到在处理过程中可能有新的client执行操作造成阻塞。 l = server.ready_keys; server.ready_keys = listCreate(); // 对readylist中的所有阻塞的key进行逐一处理 while(listLength(l) != 0) &#123; listNode *ln = listFirst(l); readyList *rl = ln-&gt;value; // 首先去除db中ready_keys中的key值 dictDelete(rl-&gt;db-&gt;ready_keys,rl-&gt;key); // 查询该key的值，如果存在并且是list类型那么对相应的client服务 robj *o = lookupKeyWrite(rl-&gt;db,rl-&gt;key); if (o != NULL &amp;&amp; o-&gt;type == OBJ_LIST) &#123; dictEntry *de; // 根据阻塞的顺序给clients提供服务 de = dictFind(rl-&gt;db-&gt;blocking_keys,rl-&gt;key); if (de) &#123; // 得到所有该key值阻塞的client list *clients = dictGetVal(de); int numclients = listLength(clients); while(numclients--) &#123; listNode *clientnode = listFirst(clients); client *receiver = clientnode-&gt;value; robj *dstkey = receiver-&gt;bpop.target; int where = (receiver-&gt;lastcmd &amp;&amp; receiver-&gt;lastcmd-&gt;proc == blpopCommand) ? LIST_HEAD : LIST_TAIL; robj *value = listTypePop(o,where); if (value) &#123; // 解除阻塞状态 if (dstkey) incrRefCount(dstkey); unblockClient(receiver); // 对相应的client提供服务处理 if (serveClientBlockedOnList(receiver, rl-&gt;key,dstkey,rl-&gt;db,value, where) == C_ERR) &#123; //如果处理失败那么将value重新加到list中去 listTypePush(o,value,where); &#125; if (dstkey) decrRefCount(dstkey); decrRefCount(value); &#125; else &#123; break; &#125; &#125; &#125; if (listTypeLength(o) == 0) &#123; dbDelete(rl-&gt;db,rl-&gt;key); &#125; &#125; decrRefCount(rl-&gt;key); zfree(rl); listDelNode(l,ln); // 删除readylist中处理完的key &#125; listRelease(l); // 处理完所有的key释放readylist空间 &#125;&#125;/* BRPOP/BLPOP指令的实现 * 这里源码似乎有点问题，只可以处理单个key*/void blockingPopGenericCommand(client *c, int where) &#123; robj *o; mstime_t timeout; int j; // 检查获取时限值 if (getTimeoutFromObjectOrReply(c,c-&gt;argv[c-&gt;argc-1],&amp;timeout,UNIT_SECONDS) != C_OK) return; for (j = 1; j &lt; c-&gt;argc-1; j++) &#123; o = lookupKeyWrite(c-&gt;db,c-&gt;argv[j]); if (o != NULL) &#123; if (o-&gt;type != OBJ_LIST) &#123; addReply(c,shared.wrongtypeerr); return; &#125; else &#123; if (listTypeLength(o) != 0) &#123; /* Non empty list, this is like a non normal [LR]POP. */ char *event = (where == LIST_HEAD) ? "lpop" : "rpop"; robj *value = listTypePop(o,where); serverAssert(value != NULL); addReplyMultiBulkLen(c,2); addReplyBulk(c,c-&gt;argv[j]); addReplyBulk(c,value); decrRefCount(value); notifyKeyspaceEvent(NOTIFY_LIST,event, c-&gt;argv[j],c-&gt;db-&gt;id); if (listTypeLength(o) == 0) &#123; dbDelete(c-&gt;db,c-&gt;argv[j]); notifyKeyspaceEvent(NOTIFY_GENERIC,"del", c-&gt;argv[j],c-&gt;db-&gt;id); &#125; signalModifiedKey(c-&gt;db,c-&gt;argv[j]); server.dirty++; /* Replicate it as an [LR]POP instead of B[LR]POP. */ rewriteClientCommandVector(c,2, (where == LIST_HEAD) ? shared.lpop : shared.rpop, c-&gt;argv[j]); return; &#125; &#125; &#125; &#125; if (c-&gt;flags &amp; CLIENT_MULTI) &#123; addReply(c,shared.nullmultibulk); return; &#125; // 如果不存在key对应的value或者list为空那么阻塞客户端 blockForKeys(c, c-&gt;argv + 1, c-&gt;argc - 2, timeout, NULL);&#125;void blpopCommand(client *c) &#123; blockingPopGenericCommand(c,LIST_HEAD);&#125;void brpopCommand(client *c) &#123; blockingPopGenericCommand(c,LIST_TAIL);&#125;void brpoplpushCommand(client *c) &#123; mstime_t timeout; if (getTimeoutFromObjectOrReply(c,c-&gt;argv[3],&amp;timeout,UNIT_SECONDS) != C_OK) return; robj *key = lookupKeyWrite(c-&gt;db, c-&gt;argv[1]); if (key == NULL) &#123; if (c-&gt;flags &amp; CLIENT_MULTI) &#123; /* Blocking against an empty list in a multi state * returns immediately. */ addReply(c, shared.nullbulk); &#125; else &#123; /* The list is empty and the client blocks. */ blockForKeys(c, c-&gt;argv + 1, 1, timeout, c-&gt;argv[2]); &#125; &#125; else &#123; if (key-&gt;type != OBJ_LIST) &#123; addReply(c, shared.wrongtypeerr); &#125; else &#123; /* The list exists and has elements, so * the regular rpoplpushCommand is executed. */ serverAssertWithInfo(c,key,listTypeLength(key) &gt; 0); rpoplpushCommand(c); &#125; &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业季的小情绪]]></title>
    <url>%2F2017%2F06%2F04%2F%E6%AF%95%E4%B8%9A%E5%AD%A3%E7%9A%84%E5%B0%8F%E6%83%85%E7%BB%AA%2F</url>
    <content type="text"><![CDATA[什么时候我们开始无法像孩子一样肆意地大呼小叫了？心里的小情绪堆积得像山一样高，直到溢出来。 与其如此，不如永远像孩子一样。毕业季的我很开心，很幸运可以来到武汉理工来到计算机学院，很幸运可以遇见一群信任相守的朋友，同样很幸运可以遇见一群让我看惯人情世故的朋友。毕业季的我很无奈，大学四年即将结束，在结尾阶段还是有做不完的事情，毕业设计，毕业晚会排练，等等主题只有一个毕业，然而我只想要一个安静舒适的毕业季，再看一眼想见的人，再说一些想说的话，再唱一些略带伤感的歌，再和兄弟们打几场篮球在理工大不算大的球场上。。。奈何时间零碎在不想做的事不想见的人身上。毕业季的我很矛盾，人总要长大，但是否愈加称为一个社会人就是长大呢，在理想主义与现实主义之间我驻足徘徊，得不到答案，残酷的是，当我选择理想主义选择不那么事故时，就会产生抛弃感还有别人的反驳，渐渐的我发现自己也变的社会了。毕业季的我很迷茫，毕业季大家各奔东西，很难说在工作的道路上谁会走得远飞的高，我听过一往无前，也听过厚积薄发，更听说过踩了狗屎运，在读研深造的道路上，我不知道自己能否坚持下来，我要的是一纸文凭，还是需要时间知识的积淀，我告诉自己只有经历了才有话语权，别倒在别人的言语之中，不忘初心即可。毕业季的我很腹黑，看看那些抱怨这抱怨那的人，我想他们一辈子都不会成功，我以为只有让我产生嫉妒感的人，才是值得做朋友的人，才是可以在一方有所作为的人，难怪人们说物以类聚，成功是需要标志的，即使是游戏打得好我也会尊敬他，即使坚持一件事失败了我也会尊敬他，那些只耍耍嘴皮或者闷不作声的人，或许就碌碌无为一生了吧。毕业季的我很激动，想象着最后的最后的场景，曲终人散，我们是借酒诉衷肠，还是互相拥抱，还是会留下不舍的泪水亦或是开心的笑容，我想听听大家的故事，听听大家对我的感受。光想想这些就很激动。毕业季的我很暴躁，兴许是我错误的理解健身的意义，对于身边的不满，我不愿意在临近毕业还放在心中，但大多时候我都知道言语解决不了问题，这也是之前不愿意说的原因，所以我都想用拳头来解决的冲动，兴许我克制了，我还是一个想安全的拿到毕业证的好同学。毕业季的我很好奇，我不知道自己的潜力有多大，说白了我想怼死球场的肌肉男，所以我毅然决然的加入了他们，每天三百的俯卧撑，加上其他腿部手部锻炼，坚持了一个月，是有胸肌了很开心，我决定坚持下去，走上健身的不归路，看看自己能变成什么样子。毕业季的我很感谢，感谢在我困难时，给我鼓励陪我的人，感谢在我一路风顺的时候，给我劝诫的人，感谢一起疯过的兄弟们，感谢教导过我的老师们，感谢我的同学们，感谢那些让我变得更好的女孩们，感谢我的毕设老师，感谢自己倔强又沉稳的性格，感谢我的母亲无微不至的叮嘱，感谢父亲的相见如不见的变向鞭策。 有的人即使离得很远，心还在一起。]]></content>
      <categories>
        <category>随口一说</category>
      </categories>
      <tags>
        <tag>心情</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(8)——t_string.c篇]]></title>
    <url>%2F2017%2F05%2F26%2Fredis%E6%BA%90%E7%A0%81-8-%E2%80%94%E2%80%94t-string-c%E7%AF%87%2F</url>
    <content type="text"><![CDATA[在redis的src源码目录下，除了底层数据结构的实现，还有一类文件，比如t_string.c,t_list.c等，它的作用就是负责客户端与服务端的通信，server接受client的指令调用相应的对象命令函数解析后执行，对内存中redisobj操作后，返回给client相应的信息。所以这一类文件中都包含有5中数据对象的指令执行函数，即command api，对于复杂的数据结构，对redisobj中数据值（robj-&gt;ptr）的操作有一次进行了封装,即list api，hash api等等。下面我们来分析t_string.c源码，首先我们列出redis中所有字符串相关指令：12345678910111213141516171819201.SET key value:设置指定的key的值2.GET key:获取指定的key的值3.GETRANGE key start end：获取指定key的值的子字符串4.GETSET key value：获取指定key的值，并且设置其新的值5.GETBIT key offset：获取指定key的值偏移量的位6.MGET key1 [key2..]:获取指定key集合的value集合7.SETBIT key offset value：设置指定key的值偏移量上的位8.SETEX key seconds value：设置指定的key的值，并且设置过期时间，单位为s9.SETNX key value：设置指定的key的值，当系统中不存在key键时10.SETRANGE key offset value：用value参数覆写给定key所储存的字符串值，从偏移量offset开始11.STRLEN key：返回指定key的值的长度12.MSET key1 value1 [key2 value2...]:同时设置多个键值对13.MSETNX key1 value1 [key2 value2...]:同时设置多个键值对，并且所有键值对在系统中不存在，否则都不添加14.PSETEX key milliseconds value：设置指定的key的值，并且设置过期时间，单位为ms15.INCR key:将key中存储的数字值加一16.INCRBY key increment：将key中存储的数字值加指定的值17.INCREBYFLOAT key increment：将key中存储的数字值加指定的浮点型值18.DECR key:将key中存储的数字值减一19.DECRBY key decrement:将key中存储的数字值减指定的值20.append key value:如果key键存在，在其value后添加value值 在t_string.c中对上面的文件都有相应command函数，在其内部对redisobj进行相应的操作，完成指令功能。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462// 检查字符串长度 最长不超过512Mstatic int checkStringLength(client *c, long long size) &#123; if (size &gt; 512*1024*1024) &#123; addReplyError(c,"string exceeds maximum allowed size (512MB)"); return C_ERR; &#125; return C_OK;&#125;/* The setGenericCommand() function implements the SET operation with different * options and variants. This function is called in order to implement the * following commands: SET, SETEX, PSETEX, SETNX. * * 'flags' changes the behavior of the command (NX or XX, see belove). * * 'expire' represents an expire to set in form of a Redis object as passed * by the user. It is interpreted according to the specified 'unit'. * * 'ok_reply' and 'abort_reply' is what the function will reply to the client * if the operation is performed, or when it is not because of NX or * XX flags. * * If ok_reply is NULL "+OK" is used. * If abort_reply is NULL, "$-1" is used. */#define OBJ_SET_NO_FLAGS 0#define OBJ_SET_NX (1&lt;&lt;0) /* Set if key not exists. */#define OBJ_SET_XX (1&lt;&lt;1) /* Set if key exists. */#define OBJ_SET_EX (1&lt;&lt;2) /* Set if time in seconds is given */#define OBJ_SET_PX (1&lt;&lt;3) /* Set if time in ms in given */// 关于字符串命令中set相关的操作实现 set setex psetex setnx// flags 标记命令行为 key值是否存在// expire定义key过期时间 格式由unit定义 ex或者px// ok_reply and abort_reply记录控制台输出内容，且都有默认值void setGenericCommand(client *c, int flags, robj *key, robj *val, robj *expire, int unit, robj *ok_reply, robj *abort_reply) &#123; long long milliseconds = 0; /* initialized to avoid any harmness warning */ if (expire) &#123; // 过期时间格式错误 if (getLongLongFromObjectOrReply(c, expire, &amp;milliseconds, NULL) != C_OK) return; // 过期时间小雨等于0 if (milliseconds &lt;= 0) &#123; addReplyErrorFormat(c,"invalid expire time in %s",c-&gt;cmd-&gt;name); return; &#125; // 单位处理 if (unit == UNIT_SECONDS) milliseconds *= 1000; &#125; // key不存在并且db中查找到了以及key存在并且db中没有查到需要报错 if ((flags &amp; OBJ_SET_NX &amp;&amp; lookupKeyWrite(c-&gt;db,key) != NULL) || (flags &amp; OBJ_SET_XX &amp;&amp; lookupKeyWrite(c-&gt;db,key) == NULL)) &#123; addReply(c, abort_reply ? abort_reply : shared.nullbulk); return; &#125; setKey(c-&gt;db,key,val);//设置key的value server.dirty++;//server中脏数据加1，每次修改都会做此操作 if (expire) setExpire(c,c-&gt;db,key,mstime()+milliseconds);//设置过期时间 notifyKeyspaceEvent(NOTIFY_STRING,"set",key,c-&gt;db-&gt;id);//触发set命令执行通知事件 // 触发key的过期时间事件 if (expire) notifyKeyspaceEvent(NOTIFY_GENERIC, "expire",key,c-&gt;db-&gt;id); addReply(c, ok_reply ? ok_reply : shared.ok);&#125;/* SET key value [NX] [XX] [EX &lt;seconds&gt;] [PX &lt;milliseconds&gt;] */// 对于上面的set命令进行解析 并且执行操作void setCommand(client *c) &#123; int j; robj *expire = NULL; int unit = UNIT_SECONDS; int flags = OBJ_SET_NO_FLAGS; // 对参数逐一解析，准备参数，执行set一般命令处理函数 for (j = 3; j &lt; c-&gt;argc; j++) &#123; char *a = c-&gt;argv[j]-&gt;ptr; robj *next = (j == c-&gt;argc-1) ? NULL : c-&gt;argv[j+1]; if ((a[0] == 'n' || a[0] == 'N') &amp;&amp; (a[1] == 'x' || a[1] == 'X') &amp;&amp; a[2] == '\0' &amp;&amp; !(flags &amp; OBJ_SET_XX)) &#123; flags |= OBJ_SET_NX; &#125; else if ((a[0] == 'x' || a[0] == 'X') &amp;&amp; (a[1] == 'x' || a[1] == 'X') &amp;&amp; a[2] == '\0' &amp;&amp; !(flags &amp; OBJ_SET_NX)) &#123; flags |= OBJ_SET_XX; &#125; else if ((a[0] == 'e' || a[0] == 'E') &amp;&amp; (a[1] == 'x' || a[1] == 'X') &amp;&amp; a[2] == '\0' &amp;&amp; !(flags &amp; OBJ_SET_PX) &amp;&amp; next) &#123; flags |= OBJ_SET_EX; unit = UNIT_SECONDS; expire = next; j++; &#125; else if ((a[0] == 'p' || a[0] == 'P') &amp;&amp; (a[1] == 'x' || a[1] == 'X') &amp;&amp; a[2] == '\0' &amp;&amp; !(flags &amp; OBJ_SET_EX) &amp;&amp; next) &#123; flags |= OBJ_SET_PX; unit = UNIT_MILLISECONDS; expire = next; j++; &#125; else &#123; addReply(c,shared.syntaxerr); return; &#125; &#125; c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]); setGenericCommand(c,flags,c-&gt;argv[1],c-&gt;argv[2],expire,unit,NULL,NULL);&#125;// 对setnx命令解析执行void setnxCommand(client *c) &#123; c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]); setGenericCommand(c,OBJ_SET_NX,c-&gt;argv[1],c-&gt;argv[2],NULL,0,shared.cone,shared.czero);&#125;// 对setex命令解析执行void setexCommand(client *c) &#123; c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]); setGenericCommand(c,OBJ_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_SECONDS,NULL,NULL);&#125;// 对psetex命令解析执行void psetexCommand(client *c) &#123; c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]); setGenericCommand(c,OBJ_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_MILLISECONDS,NULL,NULL);&#125;// get命令的基本执行方法int getGenericCommand(client *c) &#123; robj *o; if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.nullbulk)) == NULL)//没有查到key的value return C_OK; if (o-&gt;type != OBJ_STRING) &#123; addReply(c,shared.wrongtypeerr); return C_ERR; &#125; else &#123; addReplyBulk(c,o); return C_OK; &#125;&#125;// get命令实现void getCommand(client *c) &#123; getGenericCommand(c);&#125;// getset命令实现void getsetCommand(client *c) &#123; if (getGenericCommand(c) == C_ERR) return;//先读数据 c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]); setKey(c-&gt;db,c-&gt;argv[1],c-&gt;argv[2]);//再设置数据 notifyKeyspaceEvent(NOTIFY_STRING,"set",c-&gt;argv[1],c-&gt;db-&gt;id);//发送set指令执行通知事件 server.dirty++;&#125;// setrange key offset value 命令实现void setrangeCommand(client *c) &#123; robj *o; long offset; sds value = c-&gt;argv[3]-&gt;ptr; // 获取偏移量offset if (getLongFromObjectOrReply(c,c-&gt;argv[2],&amp;offset,NULL) != C_OK) return; if (offset &lt; 0) &#123; addReplyError(c,"offset is out of range"); return; &#125; o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); // 当需要set的key不存在时 if (o == NULL) &#123; /* Return 0 when setting nothing on a non-existing string */ // 设置的value长度为0时，直接返回 if (sdslen(value) == 0) &#123; addReply(c,shared.czero); return; &#125; /* Return when the resulting string exceeds allowed size */ // 在添加这个键值对之前，先检查字符串的长度 if (checkStringLength(c,offset+sdslen(value)) != C_OK) return; o = createObject(OBJ_STRING,sdsnewlen(NULL, offset+sdslen(value))); dbAdd(c-&gt;db,c-&gt;argv[1],o); &#125; else &#123; size_t olen; /* Key exists, check type */ // 检查值的类型 if (checkType(c,o,OBJ_STRING)) return; /* Return existing string length when setting nothing */ olen = stringObjectLen(o); // 如果修改的字符串长度为0 直接返回现有的字符串长度 if (sdslen(value) == 0) &#123; addReplyLongLong(c,olen); return; &#125; /* Return when the resulting string exceeds allowed size */ // 检查修改后的字符串长度 if (checkStringLength(c,offset+sdslen(value)) != C_OK) return; /* Create a copy when the object is shared or encoded. */ // 如果对象在被共享或者编码那么复制一份对象返回 o = dbUnshareStringValue(c-&gt;db,c-&gt;argv[1],o); &#125; if (sdslen(value) &gt; 0) &#123; // 需要修改的地方置0 o-&gt;ptr = sdsgrowzero(o-&gt;ptr,offset+sdslen(value)); // 复制修改的数据到相应的位置 memcpy((char*)o-&gt;ptr+offset,value,sdslen(value)); signalModifiedKey(c-&gt;db,c-&gt;argv[1]);//修改key值信号 notifyKeyspaceEvent(NOTIFY_STRING,//触发setrange指令执行通知事件 "setrange",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++; &#125; addReplyLongLong(c,sdslen(o-&gt;ptr));&#125;// get key start end 命令实现void getrangeCommand(client *c) &#123; robj *o; long long start, end; char *str, llbuf[32]; size_t strlen; // 获取开始和结束并做一系列处理 if (getLongLongFromObjectOrReply(c,c-&gt;argv[2],&amp;start,NULL) != C_OK) return; if (getLongLongFromObjectOrReply(c,c-&gt;argv[3],&amp;end,NULL) != C_OK) return; if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.emptybulk)) == NULL || checkType(c,o,OBJ_STRING)) return; if (o-&gt;encoding == OBJ_ENCODING_INT) &#123; str = llbuf; strlen = ll2string(llbuf,sizeof(llbuf),(long)o-&gt;ptr); &#125; else &#123; str = o-&gt;ptr; strlen = sdslen(str); &#125; /* Convert negative indexes */ if (start &lt; 0 &amp;&amp; end &lt; 0 &amp;&amp; start &gt; end) &#123; addReply(c,shared.emptybulk); return; &#125; if (start &lt; 0) start = strlen+start; if (end &lt; 0) end = strlen+end; if (start &lt; 0) start = 0; if (end &lt; 0) end = 0; if ((unsigned long long)end &gt;= strlen) end = strlen-1; /* Precondition: end &gt;= 0 &amp;&amp; end &lt; strlen, so the only condition where * nothing can be returned is: start &gt; end. */ if (start &gt; end || strlen == 0) &#123; addReply(c,shared.emptybulk); &#125; else &#123; addReplyBulkCBuffer(c,(char*)str+start,end-start+1); &#125;&#125;// mget key1，key2.....命令实现void mgetCommand(client *c) &#123; int j; addReplyMultiBulkLen(c,c-&gt;argc-1); for (j = 1; j &lt; c-&gt;argc; j++) &#123; robj *o = lookupKeyRead(c-&gt;db,c-&gt;argv[j]); if (o == NULL) &#123; addReply(c,shared.nullbulk); &#125; else &#123; if (o-&gt;type != OBJ_STRING) &#123; addReply(c,shared.nullbulk); &#125; else &#123; addReplyBulk(c,o); &#125; &#125; &#125;&#125;// mset命令的基本实现void msetGenericCommand(client *c, int nx) &#123; int j, busykeys = 0; if ((c-&gt;argc % 2) == 0) &#123; addReplyError(c,"wrong number of arguments for MSET"); return; &#125; /* Handle the NX flag. The MSETNX semantic is to return zero and don't * set nothing at all if at least one already key exists. */ // 对于拥有不存在标记的处理，对每一对键值对检查数据库中是否已经存在，已经存在的话直接返回 if (nx) &#123; for (j = 1; j &lt; c-&gt;argc; j += 2) &#123; if (lookupKeyWrite(c-&gt;db,c-&gt;argv[j]) != NULL) &#123; busykeys++; &#125; &#125; if (busykeys) &#123; addReply(c, shared.czero); return; &#125; &#125; for (j = 1; j &lt; c-&gt;argc; j += 2) &#123; c-&gt;argv[j+1] = tryObjectEncoding(c-&gt;argv[j+1]); setKey(c-&gt;db,c-&gt;argv[j],c-&gt;argv[j+1]); notifyKeyspaceEvent(NOTIFY_STRING,"set",c-&gt;argv[j],c-&gt;db-&gt;id); &#125; server.dirty += (c-&gt;argc-1)/2; addReply(c, nx ? shared.cone : shared.ok);&#125;// mset指令执行函数void msetCommand(client *c) &#123; msetGenericCommand(c,0);&#125;// msetnx指令执行函数void msetnxCommand(client *c) &#123; msetGenericCommand(c,1);&#125;// incre和decre命令的基本实现void incrDecrCommand(client *c, long long incr) &#123; long long value, oldvalue; robj *o, *new; o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); // 如果不是字符串类型或解析得不到参数中的整型，返回 if (o != NULL &amp;&amp; checkType(c,o,OBJ_STRING)) return; if (getLongLongFromObjectOrReply(c,o,&amp;value,NULL) != C_OK) return; oldvalue = value; // 修改后的值是否越界检查 if ((incr &lt; 0 &amp;&amp; oldvalue &lt; 0 &amp;&amp; incr &lt; (LLONG_MIN-oldvalue)) || (incr &gt; 0 &amp;&amp; oldvalue &gt; 0 &amp;&amp; incr &gt; (LLONG_MAX-oldvalue))) &#123; addReplyError(c,"increment or decrement would overflow"); return; &#125; value += incr; if (o &amp;&amp; o-&gt;refcount == 1 &amp;&amp; o-&gt;encoding == OBJ_ENCODING_INT &amp;&amp; (value &lt; 0 || value &gt;= OBJ_SHARED_INTEGERS) &amp;&amp; value &gt;= LONG_MIN &amp;&amp; value &lt;= LONG_MAX) &#123; new = o; o-&gt;ptr = (void*)((long)value); &#125; else &#123; new = createStringObjectFromLongLong(value); if (o) &#123; // 覆写原来的值 dbOverwrite(c-&gt;db,c-&gt;argv[1],new); &#125; else &#123; // 添加新的值 dbAdd(c-&gt;db,c-&gt;argv[1],new); &#125; &#125; signalModifiedKey(c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_STRING,"incrby",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++; addReply(c,shared.colon); addReply(c,new); addReply(c,shared.crlf);&#125;void incrCommand(client *c) &#123; incrDecrCommand(c,1);&#125;void decrCommand(client *c) &#123; incrDecrCommand(c,-1);&#125;void incrbyCommand(client *c) &#123; long long incr; if (getLongLongFromObjectOrReply(c, c-&gt;argv[2], &amp;incr, NULL) != C_OK) return; incrDecrCommand(c,incr);&#125;void decrbyCommand(client *c) &#123; long long incr; if (getLongLongFromObjectOrReply(c, c-&gt;argv[2], &amp;incr, NULL) != C_OK) return; incrDecrCommand(c,-incr);&#125;// 和incrDecrCommand相似ßvoid incrbyfloatCommand(client *c) &#123; long double incr, value; robj *o, *new, *aux; o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); if (o != NULL &amp;&amp; checkType(c,o,OBJ_STRING)) return; if (getLongDoubleFromObjectOrReply(c,o,&amp;value,NULL) != C_OK || getLongDoubleFromObjectOrReply(c,c-&gt;argv[2],&amp;incr,NULL) != C_OK) return; value += incr; if (isnan(value) || isinf(value)) &#123; addReplyError(c,"increment would produce NaN or Infinity"); return; &#125; new = createStringObjectFromLongDouble(value,1); if (o) dbOverwrite(c-&gt;db,c-&gt;argv[1],new); else dbAdd(c-&gt;db,c-&gt;argv[1],new); signalModifiedKey(c-&gt;db,c-&gt;argv[1]); notifyKeyspaceEvent(NOTIFY_STRING,"incrbyfloat",c-&gt;argv[1],c-&gt;db-&gt;id); server.dirty++; addReplyBulk(c,new); /* Always replicate INCRBYFLOAT as a SET command with the final value * in order to make sure that differences in float precision or formatting * will not create differences in replicas or after an AOF restart. */ // 将incrbyfloat解释为一个set指令，为了解决aop重启时的不同 aux = createStringObject("SET",3); rewriteClientCommandArgument(c,0,aux); decrRefCount(aux); rewriteClientCommandArgument(c,2,new);&#125;// append key value指令执行函数void appendCommand(client *c) &#123; size_t totlen; robj *o, *append; o = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]); if (o == NULL) &#123;//添加的key不存在时，创建一个键值对， /* Create the key */ c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]); dbAdd(c-&gt;db,c-&gt;argv[1],c-&gt;argv[2]); incrRefCount(c-&gt;argv[2]); totlen = stringObjectLen(c-&gt;argv[2]); &#125; else &#123; /* Key exists, check type */ if (checkType(c,o,OBJ_STRING)) return; /* "append" is an argument, so always an sds */ append = c-&gt;argv[2]; totlen = stringObjectLen(o)+sdslen(append-&gt;ptr); // 检查字符串长度 if (checkStringLength(c,totlen) != C_OK) return; /* Append the value */ o = dbUnshareStringValue(c-&gt;db,c-&gt;argv[1],o); o-&gt;ptr = sdscatlen(o-&gt;ptr,append-&gt;ptr,sdslen(append-&gt;ptr)); totlen = sdslen(o-&gt;ptr); &#125; signalModifiedKey(c-&gt;db,c-&gt;argv[1]);//同步key的value信号 notifyKeyspaceEvent(NOTIFY_STRING,"append",c-&gt;argv[1],c-&gt;db-&gt;id);//触发append指令执行通知事件 server.dirty++; addReplyLongLong(c,totlen);&#125;// strlen key指令执行函数void strlenCommand(client *c) &#123; robj *o; if ((o = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL || checkType(c,o,OBJ_STRING)) return; addReplyLongLong(c,stringObjectLen(o));&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(7)——skiplist篇]]></title>
    <url>%2F2017%2F05%2F20%2Fredis%E6%BA%90%E7%A0%81-7-%E2%80%94%E2%80%94skiplist%E7%AF%87%2F</url>
    <content type="text"><![CDATA[对于一个普通的链表进行检索，那么检索效率O(n),而通过红黑树可以使得效率变为O(logn)，但是红黑树的逻辑过于复杂，添加删除操作的过程很繁琐，所以一般程序员用跳跃表代替红黑树，检索效率也可以做到O(logn)，跳跃表的核心思想就是通过一个节点不仅可以访问后一个节点，也可以跨越的访问更后面的节点。这种做法是典型的用空间换取时间的设计方案。在redis中对传统的跳跃表进行了改进，这里就不对传统的跳跃表进行详解，主要讲解redis中修改后跳跃表以及一个哈希表如何作为有序集合的底层实现。先来看看相关的数据结构：在server.h中1234567891011121314151617181920typedef struct zskiplistNode &#123; sds ele;//用来在与字典中key对应找到value double score;//用来集合中排序，当score相同时比较ele struct zskiplistNode *backward; struct zskiplistLevel &#123; struct zskiplistNode *forward; unsigned int span; &#125; level[];//下一个节点集合&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail;//首尾节点 unsigned long length;//跳跃表的节点个数 int level;//跳跃表节点中最大的层数&#125; zskiplist;//有序集合由一个字典和一个跳跃表构成，两者之间通过ele来一一对应，跳跃表中存储顺序，字典中存储valuetypedef struct zset &#123; dict *dict;//存储键值对的字典 zskiplist *zsl;//存储顺序的跳跃表&#125; zset; zskiplist的相关接口在server.h中定义，在t_zset.c中实现，当然在t_zset.c中还有关于有序集合ziplist底层实现的api，以及有序集合控制台指令函数。这里就列出所有关于跳跃表的函数。主要包含了跳跃表中节点的添加删除以及查询，还有关于范围的解析查询操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639/*----------------------------------------------------------------------------- * Skiplist implementation of the low level API *----------------------------------------------------------------------------*/int zslLexValueGteMin(sds value, zlexrangespec *spec);int zslLexValueLteMax(sds value, zlexrangespec *spec);/* Create a skiplist node with the specified number of levels. * The SDS string 'ele' is referenced by the node after the call. */// 创建一个跳跃表节点，根据提供的level 代表节点的层数 sds代表节点的唯一标示zskiplistNode *zslCreateNode(int level, double score, sds ele) &#123; zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel));// 分配空间 zn-&gt;score = score; zn-&gt;ele = ele; return zn;&#125;/* Create a new skiplist. */// 创建一个跳跃表初始化zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; zsl = zmalloc(sizeof(*zsl)); // 初始化跳跃表的层数为1，节点个数为0 zsl-&gt;level = 1; zsl-&gt;length = 0; // 创建一个头节点，层数为最大层数32，并且每一层对应的forward为null zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; zsl-&gt;header-&gt;level[j].forward = NULL; zsl-&gt;header-&gt;level[j].span = 0; &#125; // 头节点的前驱为null 以及链表的尾节点也为null zsl-&gt;header-&gt;backward = NULL; zsl-&gt;tail = NULL; return zsl;&#125;/* Free the specified skiplist node. The referenced SDS string representation * of the element is freed too, unless node-&gt;ele is set to NULL before calling * this function. */// 释放快速链表节点空间void zslFreeNode(zskiplistNode *node) &#123; sdsfree(node-&gt;ele); zfree(node);&#125;/* Free a whole skiplist. */// 释放整个快速链表的空间void zslFree(zskiplist *zsl) &#123; zskiplistNode *node = zsl-&gt;header-&gt;level[0].forward, *next; // 通过第一层 逐个释放节点空间，最后释放链表表空间 zfree(zsl-&gt;header); while(node) &#123; next = node-&gt;level[0].forward; zslFreeNode(node); node = next; &#125; zfree(zsl);&#125;/* Returns a random level for the new skiplist node we are going to create. * The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL * (both inclusive), with a powerlaw-alike distribution where higher * levels are less likely to be returned. */// 随机为节点生成一个层数，当随机数大于32时，取最大值即可int zslRandomLevel(void) &#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;/* Insert a new node in the skiplist. Assumes the element does not already * exist (up to the caller to enforce that). The skiplist takes ownership * of the passed SDS string 'ele'. */// 往跳跃链表中插入节点，该函数假设链表中不存一样的节点zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) &#123; // update数组用来记录 插入节点前一个节点的指针 zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; // rank数组用来存储从header节点到插入位置的跨度span 方便确定新节点的span以及更新其他节点的span unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; serverAssert(!isnan(score)); x = zsl-&gt;header; // 确定插入位置，以及每一层的前一个节点，还有rank值更新 for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) // redis中对跳跃表的改动之一，不仅比较score还比较ele &#123; rank[i] += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; /* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */ // 创建node 随机level ，如果level大于链表层数那么更新链表 level = zslRandomLevel(); if (level &gt; zsl-&gt;level) &#123; for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; zsl-&gt;level = level; &#125; x = zslCreateNode(level,score,ele); // 更新forward指针以及span for (i = 0; i &lt; level; i++) &#123; x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; &#125; // 跟新其他层的span /* increment span for untouched levels */ for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; // 跟新前驱节点指针 x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; zsl-&gt;length++; return x;&#125;/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank */// 删除链表中x节点，根据update数组void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) &#123; int i; for (i = 0; i &lt; zsl-&gt;level; i++) &#123; if (update[i]-&gt;level[i].forward == x) &#123; update[i]-&gt;level[i].span += x-&gt;level[i].span - 1; update[i]-&gt;level[i].forward = x-&gt;level[i].forward; &#125; else &#123; update[i]-&gt;level[i].span -= 1; &#125; &#125; if (x-&gt;level[0].forward) &#123; x-&gt;level[0].forward-&gt;backward = x-&gt;backward; &#125; else &#123; zsl-&gt;tail = x-&gt;backward; &#125; while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL) zsl-&gt;level--; zsl-&gt;length--;&#125;/* Delete an element with matching score/element from the skiplist. * The function returns 1 if the node was found and deleted, otherwise * 0 is returned. * * If 'node' is NULL the deleted node is freed by zslFreeNode(), otherwise * it is not freed (but just unlinked) and *node is set to the node pointer, * so that it is possible for the caller to reuse the node (including the * referenced SDS string at node-&gt;ele). */// 根据score和ele查找删除节点，没找到或者node不为null时返回0.如果返回1表示找到并且删除，此时并没释放空间知识unlink状态int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. */ x = x-&gt;level[0].forward; if (x &amp;&amp; score == x-&gt;score &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) &#123; zslDeleteNode(zsl, x, update); if (!node) zslFreeNode(x); else *node = x; return 1; &#125; return 0; /* not found */&#125;int zslValueGteMin(double value, zrangespec *spec) &#123; return spec-&gt;minex ? (value &gt; spec-&gt;min) : (value &gt;= spec-&gt;min);&#125;int zslValueLteMax(double value, zrangespec *spec) &#123; return spec-&gt;maxex ? (value &lt; spec-&gt;max) : (value &lt;= spec-&gt;max);&#125;/* Returns if there is a part of the zset is in range. */// 判断跳跃表是否在一定范围内int zslIsInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; /* Test for ranges that will always be empty. */ if (range-&gt;min &gt; range-&gt;max || (range-&gt;min == range-&gt;max &amp;&amp; (range-&gt;minex || range-&gt;maxex))) return 0; x = zsl-&gt;tail; if (x == NULL || !zslValueGteMin(x-&gt;score,range)) return 0; x = zsl-&gt;header-&gt;level[0].forward; if (x == NULL || !zslValueLteMax(x-&gt;score,range)) return 0; return 1;&#125;/* Find the first node that is contained in the specified range. * Returns NULL when no element is contained in the range. */// 返回跳跃链表中第一个出现在范围内的节点zskiplistNode *zslFirstInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *OUT* of range. */ while (x-&gt;level[i].forward &amp;&amp; !zslValueGteMin(x-&gt;level[i].forward-&gt;score,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so the next node cannot be NULL. */ x = x-&gt;level[0].forward; serverAssert(x != NULL); /* Check if score &lt;= max. */ if (!zslValueLteMax(x-&gt;score,range)) return NULL; return x;&#125;/* Find the last node that is contained in the specified range. * Returns NULL when no element is contained in the range. */// 返回跳跃链表中最后一个出现在范围内的节点zskiplistNode *zslLastInRange(zskiplist *zsl, zrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *IN* range. */ while (x-&gt;level[i].forward &amp;&amp; zslValueLteMax(x-&gt;level[i].forward-&gt;score,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so this node cannot be NULL. */ serverAssert(x != NULL); /* Check if score &gt;= min. */ if (!zslValueGteMin(x-&gt;score,range)) return NULL; return x;&#125;/* Delete all the elements with score between min and max from the skiplist. * Min and max are inclusive, so a score &gt;= min || score &lt;= max is deleted. * Note that this function takes the reference to the hash table view of the * sorted set, in order to remove the elements from the hash table too. */// 删除跳跃表中一定范围的节点，同时删除字典中的键值对unsigned long zslDeleteRangeByScore(zskiplist *zsl, zrangespec *range, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long removed = 0; int i; // 搜索第一个在范围里面的节点 x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (range-&gt;minex ? x-&gt;level[i].forward-&gt;score &lt;= range-&gt;min : x-&gt;level[i].forward-&gt;score &lt; range-&gt;min)) x = x-&gt;level[i].forward; update[i] = x; &#125; /* Current node is the last with score &lt; or &lt;= min. */ x = x-&gt;level[0].forward; /* Delete nodes while in range. */ // 依次删除节点知道有节点大于范围 while (x &amp;&amp; (range-&gt;maxex ? x-&gt;score &lt; range-&gt;max : x-&gt;score &lt;= range-&gt;max)) &#123; zskiplistNode *next = x-&gt;level[0].forward; zslDeleteNode(zsl,x,update); dictDelete(dict,x-&gt;ele); // 删除节点成功 此时节点处于unlink状态 没有free zslFreeNode(x); /* Here is where x-&gt;ele is actually released. */ removed++; x = next; &#125; return removed;&#125;unsigned long zslDeleteRangeByLex(zskiplist *zsl, zlexrangespec *range, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long removed = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; !zslLexValueGteMin(x-&gt;level[i].forward-&gt;ele,range)) x = x-&gt;level[i].forward; update[i] = x; &#125; /* Current node is the last with score &lt; or &lt;= min. */ x = x-&gt;level[0].forward; /* Delete nodes while in range. */ while (x &amp;&amp; zslLexValueLteMax(x-&gt;ele,range)) &#123; zskiplistNode *next = x-&gt;level[0].forward; zslDeleteNode(zsl,x,update); dictDelete(dict,x-&gt;ele); zslFreeNode(x); /* Here is where x-&gt;ele is actually released. */ removed++; x = next; &#125; return removed;&#125;/* Delete all the elements with rank between start and end from the skiplist. * Start and end are inclusive. Note that start and end need to be 1-based */// 按照index或者rank来删除一定范围的节点unsigned long zslDeleteRangeByRank(zskiplist *zsl, unsigned int start, unsigned int end, dict *dict) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned long traversed = 0, removed = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt; start) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; traversed++; x = x-&gt;level[0].forward; while (x &amp;&amp; traversed &lt;= end) &#123; zskiplistNode *next = x-&gt;level[0].forward; zslDeleteNode(zsl,x,update); dictDelete(dict,x-&gt;ele); zslFreeNode(x); removed++; traversed++; x = next; &#125; return removed;&#125;/* Find the rank for an element by both score and key. * Returns 0 when the element cannot be found, rank otherwise. * Note that the rank is 1-based due to the span of zsl-&gt;header to the * first element. */// 返回score以及ele的节点的index，找不到返回0unsigned long zslGetRank(zskiplist *zsl, double score, sds ele) &#123; zskiplistNode *x; unsigned long rank = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt;= 0))) &#123; rank += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */ if (x-&gt;ele &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) &#123; return rank; &#125; &#125; return 0;&#125;/* Finds an element by its rank. The rank argument needs to be 1-based. */// 根据rank返回链表中的节点zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) &#123; zskiplistNode *x; unsigned long traversed = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (traversed + x-&gt;level[i].span) &lt;= rank) &#123; traversed += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; if (traversed == rank) &#123; return x; &#125; &#125; return NULL;&#125;/* Populate the rangespec according to the objects min and max. */// 解析字符串对象obj1以及2到范围结构里面，注意字符串前加（ 的话即带等于比较static int zslParseRange(robj *min, robj *max, zrangespec *spec) &#123; char *eptr; spec-&gt;minex = spec-&gt;maxex = 0; /* Parse the min-max interval. If one of the values is prefixed * by the "(" character, it's considered "open". For instance * ZRANGEBYSCORE zset (1.5 (2.5 will match min &lt; x &lt; max * ZRANGEBYSCORE zset 1.5 2.5 will instead match min &lt;= x &lt;= max */ if (min-&gt;encoding == OBJ_ENCODING_INT) &#123; spec-&gt;min = (long)min-&gt;ptr; &#125; else &#123; if (((char*)min-&gt;ptr)[0] == '(') &#123; spec-&gt;min = strtod((char*)min-&gt;ptr+1,&amp;eptr); if (eptr[0] != '\0' || isnan(spec-&gt;min)) return C_ERR; spec-&gt;minex = 1; &#125; else &#123; spec-&gt;min = strtod((char*)min-&gt;ptr,&amp;eptr); if (eptr[0] != '\0' || isnan(spec-&gt;min)) return C_ERR; &#125; &#125; if (max-&gt;encoding == OBJ_ENCODING_INT) &#123; spec-&gt;max = (long)max-&gt;ptr; &#125; else &#123; if (((char*)max-&gt;ptr)[0] == '(') &#123; spec-&gt;max = strtod((char*)max-&gt;ptr+1,&amp;eptr); if (eptr[0] != '\0' || isnan(spec-&gt;max)) return C_ERR; spec-&gt;maxex = 1; &#125; else &#123; spec-&gt;max = strtod((char*)max-&gt;ptr,&amp;eptr); if (eptr[0] != '\0' || isnan(spec-&gt;max)) return C_ERR; &#125; &#125; return C_OK;&#125;/* ------------------------ Lexicographic ranges ---------------------------- *//* Parse max or min argument of ZRANGEBYLEX. * (foo means foo (open interval) * [foo means foo (closed interval) * - means the min string possible * + means the max string possible * * If the string is valid the *dest pointer is set to the redis object * that will be used for the comparision, and ex will be set to 0 or 1 * respectively if the item is exclusive or inclusive. C_OK will be * returned. * * If the string is not a valid range C_ERR is returned, and the value * of *dest and *ex is undefined. */// 解析一个字符串对象，获得它的range部分以及是否有等于比较，注意这里的语法int zslParseLexRangeItem(robj *item, sds *dest, int *ex) &#123; char *c = item-&gt;ptr; switch(c[0]) &#123; case '+': if (c[1] != '\0') return C_ERR; *ex = 0; *dest = shared.maxstring; return C_OK; case '-': if (c[1] != '\0') return C_ERR; *ex = 0; *dest = shared.minstring; return C_OK; case '(': *ex = 1; *dest = sdsnewlen(c+1,sdslen(c)-1); return C_OK; case '[': *ex = 0; *dest = sdsnewlen(c+1,sdslen(c)-1); return C_OK; default: return C_ERR; &#125;&#125;/* Free a lex range structure, must be called only after zelParseLexRange() * populated the structure with success (C_OK returned). */// 释放一个字符串range中min和max的sds空间，保证在解析完之后调用void zslFreeLexRange(zlexrangespec *spec) &#123; if (spec-&gt;min != shared.minstring &amp;&amp; spec-&gt;min != shared.maxstring) sdsfree(spec-&gt;min); if (spec-&gt;max != shared.minstring &amp;&amp; spec-&gt;max != shared.maxstring) sdsfree(spec-&gt;max);&#125;/* Populate the lex rangespec according to the objects min and max. * * Return C_OK on success. On error C_ERR is returned. * When OK is returned the structure must be freed with zslFreeLexRange(), * otherwise no release is needed. */// 将字符串对象解析到一个字符串range中int zslParseLexRange(robj *min, robj *max, zlexrangespec *spec) &#123; /* The range can't be valid if objects are integer encoded. * Every item must start with ( or [. */ if (min-&gt;encoding == OBJ_ENCODING_INT || max-&gt;encoding == OBJ_ENCODING_INT) return C_ERR; spec-&gt;min = spec-&gt;max = NULL; if (zslParseLexRangeItem(min, &amp;spec-&gt;min, &amp;spec-&gt;minex) == C_ERR || zslParseLexRangeItem(max, &amp;spec-&gt;max, &amp;spec-&gt;maxex) == C_ERR) &#123; zslFreeLexRange(spec); return C_ERR; &#125; else &#123; return C_OK; &#125;&#125;/* This is just a wrapper to sdscmp() that is able to * handle shared.minstring and shared.maxstring as the equivalent of * -inf and +inf for strings */// 对sdscmp的包装，可以处理正无穷以及副无穷int sdscmplex(sds a, sds b) &#123; if (a == b) return 0; if (a == shared.minstring || b == shared.maxstring) return -1; if (a == shared.maxstring || b == shared.minstring) return 1; return sdscmp(a,b);&#125;// 下面两个函数都是字符串范围比较int zslLexValueGteMin(sds value, zlexrangespec *spec) &#123; return spec-&gt;minex ? (sdscmplex(value,spec-&gt;min) &gt; 0) : (sdscmplex(value,spec-&gt;min) &gt;= 0);&#125;int zslLexValueLteMax(sds value, zlexrangespec *spec) &#123; return spec-&gt;maxex ? (sdscmplex(value,spec-&gt;max) &lt; 0) : (sdscmplex(value,spec-&gt;max) &lt;= 0);&#125;/* Returns if there is a part of the zset is in the lex range. */// 判断跳表是否在字符串范围内int zslIsInLexRange(zskiplist *zsl, zlexrangespec *range) &#123; zskiplistNode *x; /* Test for ranges that will always be empty. */ // 检查范围格式是否正确 if (sdscmplex(range-&gt;min,range-&gt;max) &gt; 1 || (sdscmp(range-&gt;min,range-&gt;max) == 0 &amp;&amp; (range-&gt;minex || range-&gt;maxex))) return 0; x = zsl-&gt;tail; if (x == NULL || !zslLexValueGteMin(x-&gt;ele,range)) return 0; x = zsl-&gt;header-&gt;level[0].forward; if (x == NULL || !zslLexValueLteMax(x-&gt;ele,range)) return 0; return 1;&#125;/* Find the first node that is contained in the specified lex range. * Returns NULL when no element is contained in the range. */// 返回跳跃表中第一个在范围内的节点，没有返回nullzskiplistNode *zslFirstInLexRange(zskiplist *zsl, zlexrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInLexRange(zsl,range)) return NULL; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *OUT* of range. */ while (x-&gt;level[i].forward &amp;&amp; !zslLexValueGteMin(x-&gt;level[i].forward-&gt;ele,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so the next node cannot be NULL. */ x = x-&gt;level[0].forward; serverAssert(x != NULL); /* Check if score &lt;= max. */ if (!zslLexValueLteMax(x-&gt;ele,range)) return NULL; return x;&#125;/* Find the last node that is contained in the specified range. * Returns NULL when no element is contained in the range. */// 返回跳跃表中最后一个在范围内的节点，没有返回nullzskiplistNode *zslLastInLexRange(zskiplist *zsl, zlexrangespec *range) &#123; zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInLexRange(zsl,range)) return NULL; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* Go forward while *IN* range. */ while (x-&gt;level[i].forward &amp;&amp; zslLexValueLteMax(x-&gt;level[i].forward-&gt;ele,range)) x = x-&gt;level[i].forward; &#125; /* This is an inner range, so this node cannot be NULL. */ serverAssert(x != NULL); /* Check if score &gt;= min. */ if (!zslLexValueGteMin(x-&gt;ele,range)) return NULL; return x;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(6)——object篇]]></title>
    <url>%2F2017%2F05%2F05%2Fredis%E6%BA%90%E7%A0%81-6-%E2%80%94%E2%80%94object%E7%AF%87%2F</url>
    <content type="text"><![CDATA[在redis中有很多数据结构，可以分为底层数据结构对于用户透明，对于用户可以使用的是用户层数据结构，即字符串，列表，字典，无序集合，有序集合这五个基本类型。但是对于每一个基本类型，在redis底层都有多种实现方式，根据具体的存储内容以及使用需求自动选择适合的底层实现，以提高的redis的使用效率以及内存管理。对于底层实现的数据结构在源程序中列出如下：12345678910#define OBJ_ENCODING_RAW 0 /* sds字符串编码 */#define OBJ_ENCODING_INT 1 /* 整数编码 */#define OBJ_ENCODING_HT 2 /* 哈希列表编码*/#define OBJ_ENCODING_ZIPMAP 3 /* 压缩字典*/#define OBJ_ENCODING_LINKEDLIST 4 /* 不再使用，普通的双向链表 */#define OBJ_ENCODING_ZIPLIST 5 /* 压缩链表 */#define OBJ_ENCODING_INTSET 6 /* 有序整数集合 */#define OBJ_ENCODING_SKIPLIST 7 /* 跳跃链表 */#define OBJ_ENCODING_EMBSTR 8 /* 仿字符串编码 */#define OBJ_ENCODING_QUICKLIST 9 /* 快表，即一个节点为压缩列表的双向链表 */ 在redis中将所有的数据类型包装成redis数据对象，数据结构如下：1234567typedef struct redisObject &#123; unsigned type:4;//5种用户类型 unsigned encoding:4;／10种底层编码／ unsigned lru:LRU_BITS; /* 包含访问频率以及数据对象过期时间用于对象空间释放*/ int refcount;／／引用计数 void *ptr;／／数据指针&#125; robj; refcount用于refcount=0时对象空间释放标记以及refcount&gt;1时数据对象修改等操作限制。下面列出5种用户基本类型可能使用的底层实现：1.字符串使用sds字符串，整数，以及embstr三种底层编码实现，主要是普通sds与embstr之间区别，当字符串的长度不大于44时，采用embstr，embstr即将字符串底层对象与数据对象存储在一段连续的内存空间里。2.列表使用ziplist以及quicklist实现，linkedlist已经不在使用，ziplist就是将对象存储在一段连续的内存空间中，节省了前后指针空间。quicklist在上一章讲过，结果双向链表以及压缩链表的优点，在内存空间和链表操作复杂度之间平衡，取代linkedlist。3.字典使用ziplist以及hashtable实现，ziplist在键值对比较少的情况下使用，将key和value连续存储一段内存中，而ht就是哈希表的实现。4.无序集合采用的是intset以及ht实现，intset用来存储整数。5.有序集合用skiplist或者ziplist实现，同样ziplist在元素比较少的时候使用。 下面就分析object.c中关于数据对象的操作主要就是创建以及释放，还有一些工具函数和关于对象的命令操作以及内存管理和内存命令可以自行阅读。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461#include "server.h"#include &lt;math.h&gt;#include &lt;ctype.h&gt;#ifdef __CYGWIN__#define strtold(a,b) ((long double)strtod((a),(b)))#endif/*===================== Creation and parsing of objects ==================== *///根据提供的数据以及用户类型创建redis对象robj *createObject(int type, void *ptr) &#123; robj *o = zmalloc(sizeof(*o));//分配空间 o-&gt;type = type; o-&gt;encoding = OBJ_ENCODING_RAW;//不管什么用户类型默认设置raw o-&gt;ptr = ptr; o-&gt;refcount = 1;//应用初始值为1 /* Set the LRU to the current lruclock (minutes resolution), or * alternatively the LFU counter. */ //两种方式设置对象销毁期限 if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; o-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | LFU_INIT_VAL; &#125; else &#123; o-&gt;lru = LRU_CLOCK(); &#125; return o;&#125;/* Set a special refcount in the object to make it "shared": * incrRefCount and decrRefCount() will test for this special refcount * and will not touch the object. This way it is free to access shared * objects such as small integers from different threads without any * mutex. * * A common patter to create shared objects: * * robj *myobject = makeObjectShared(createObject(...)); * *///是的对象称为共享对象，在多个线程中不存在互斥锁。共享对象就不存在引用的加减操作robj *makeObjectShared(robj *o) &#123; serverAssert(o-&gt;refcount == 1); o-&gt;refcount = OBJ_SHARED_REFCOUNT; return o;&#125;/* Create a string object with encoding OBJ_ENCODING_RAW, that is a plain * string object where o-&gt;ptr points to a proper sds string. *///创建一个底层实现为raw的字符串对象，数据为ptr，字符串长度为lenrobj *createRawStringObject(const char *ptr, size_t len) &#123; return createObject(OBJ_STRING, sdsnewlen(ptr,len));&#125;/* Create a string object with encoding OBJ_ENCODING_EMBSTR, that is * an object where the sds string is actually an unmodifiable string * allocated in the same chunk as the object itself. *///创建一个底层实现为embstr的字符串对象，数据为ptr，长度为lenrobj *createEmbeddedStringObject(const char *ptr, size_t len) &#123; robj *o = zmalloc(sizeof(robj)+sizeof(struct sdshdr8)+len+1);//由于embstr将数据与redis对象放在一段连续的内存空间中，所以redis空间后面开辟一个sds结构空间 struct sdshdr8 *sh = (void*)(o+1);//64位系统 o-&gt;type = OBJ_STRING; o-&gt;encoding = OBJ_ENCODING_EMBSTR; o-&gt;ptr = sh+1;//设置数据 o-&gt;refcount = 1; if (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; o-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;8) | LFU_INIT_VAL; &#125; else &#123; o-&gt;lru = LRU_CLOCK(); &#125; sh-&gt;len = len; sh-&gt;alloc = len; sh-&gt;flags = SDS_TYPE_8; if (ptr) &#123; memcpy(sh-&gt;buf,ptr,len); sh-&gt;buf[len] = '\0'; &#125; else &#123; memset(sh-&gt;buf,0,len+1);//如果ptr为空值那么填充0 &#125; return o;&#125;/* Create a string object with EMBSTR encoding if it is smaller than * OBJ_ENCODING_EMBSTR_SIZE_LIMIT, otherwise the RAW encoding is * used. * * The current limit of 39 is chosen so that the biggest string object * we allocate as EMBSTR will still fit into the 64 byte arena of jemalloc. */#define OBJ_ENCODING_EMBSTR_SIZE_LIMIT 44//embstr限制当len长度不大于44才可以使用，创建字符串对象robj *createStringObject(const char *ptr, size_t len) &#123; if (len &lt;= OBJ_ENCODING_EMBSTR_SIZE_LIMIT) return createEmbeddedStringObject(ptr,len); else return createRawStringObject(ptr,len);&#125;//通过longlong类型整数创建字符串对象robj *createStringObjectFromLongLong(long long value) &#123; robj *o; if (value &gt;= 0 &amp;&amp; value &lt; OBJ_SHARED_INTEGERS) &#123; incrRefCount(shared.integers[value]);//当整数在这个范围内采用server内建的对象 o = shared.integers[value]; &#125; else &#123; if (value &gt;= LONG_MIN &amp;&amp; value &lt;= LONG_MAX) &#123; o = createObject(OBJ_STRING, NULL); o-&gt;encoding = OBJ_ENCODING_INT; o-&gt;ptr = (void*)((long)value);//对于long整数直接存储 &#125; else &#123; o = createObject(OBJ_STRING,sdsfromlonglong(value));//将longlong整数转化为str然后创建字符串对象，这样节省内存空间 &#125; &#125; return o;&#125;/* Create a string object from a long double. If humanfriendly is non-zero * it does not use exponential format and trims trailing zeroes at the end, * however this results in loss of precision. Otherwise exp format is used * and the output of snprintf() is not modified. * * The 'humanfriendly' option is used for INCRBYFLOAT and HINCRBYFLOAT. *///通过longdouble型数创建字符串对象robj *createStringObjectFromLongDouble(long double value, int humanfriendly) &#123; char buf[256]; int len = ld2string(buf,sizeof(buf),value,humanfriendly);//字符串转化 return createStringObject(buf,len);&#125;/* Duplicate a string object, with the guarantee that the returned object * has the same encoding as the original one. * * This function also guarantees that duplicating a small integere object * (or a string object that contains a representation of a small integer) * will always result in a fresh object that is unshared (refcount == 1). * * The resulting object always has refcount set to 1. *///复制一个字符串redis对象，对于小整数也创建一个对象，而不是用server内建对象，并且返回对象引用都为1robj *dupStringObject(const robj *o) &#123; robj *d; serverAssert(o-&gt;type == OBJ_STRING); switch(o-&gt;encoding) &#123; case OBJ_ENCODING_RAW: return createRawStringObject(o-&gt;ptr,sdslen(o-&gt;ptr)); case OBJ_ENCODING_EMBSTR: return createEmbeddedStringObject(o-&gt;ptr,sdslen(o-&gt;ptr)); case OBJ_ENCODING_INT://long或者系统内建 d = createObject(OBJ_STRING, NULL); d-&gt;encoding = OBJ_ENCODING_INT; d-&gt;ptr = o-&gt;ptr; return d; default: serverPanic("Wrong encoding."); break; &#125;&#125;//创建一个快速链表底层实现的链表对象robj *createQuicklistObject(void) &#123; quicklist *l = quicklistCreate(); robj *o = createObject(OBJ_LIST,l); o-&gt;encoding = OBJ_ENCODING_QUICKLIST; return o;&#125;//创建一个压缩链表底层实现的链表对象robj *createZiplistObject(void) &#123; unsigned char *zl = ziplistNew(); robj *o = createObject(OBJ_LIST,zl); o-&gt;encoding = OBJ_ENCODING_ZIPLIST; return o;&#125;//创建一个哈希表底层实现的无序集合对象robj *createSetObject(void) &#123; dict *d = dictCreate(&amp;setDictType,NULL); robj *o = createObject(OBJ_SET,d); o-&gt;encoding = OBJ_ENCODING_HT; return o;&#125;//创建一个intset底层实现的无序集合对象robj *createIntsetObject(void) &#123; intset *is = intsetNew(); robj *o = createObject(OBJ_SET,is); o-&gt;encoding = OBJ_ENCODING_INTSET; return o;&#125;//创建一个ziplist作为底层实现的字典对象robj *createHashObject(void) &#123; unsigned char *zl = ziplistNew(); robj *o = createObject(OBJ_HASH, zl); o-&gt;encoding = OBJ_ENCODING_ZIPLIST; return o;&#125;//创建一个skiplist作为底层实现的有序集合对象robj *createZsetObject(void) &#123; zset *zs = zmalloc(sizeof(*zs)); robj *o; zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL); zs-&gt;zsl = zslCreate(); o = createObject(OBJ_ZSET,zs); o-&gt;encoding = OBJ_ENCODING_SKIPLIST; return o;&#125;//创建一个由ziplist作为底层实现的有序集合对象robj *createZsetZiplistObject(void) &#123; unsigned char *zl = ziplistNew(); robj *o = createObject(OBJ_ZSET,zl); o-&gt;encoding = OBJ_ENCODING_ZIPLIST; return o;&#125;// 创建模块对象robj *createModuleObject(moduleType *mt, void *value) &#123; moduleValue *mv = zmalloc(sizeof(*mv)); mv-&gt;type = mt; mv-&gt;value = value; return createObject(OBJ_MODULE,mv);&#125;// 释放一个字符串对象void freeStringObject(robj *o) &#123; if (o-&gt;encoding == OBJ_ENCODING_RAW) &#123; sdsfree(o-&gt;ptr); &#125;&#125;// 释放一个链表对象 链表对象貌似不会用到ziplistvoid freeListObject(robj *o) &#123; if (o-&gt;encoding == OBJ_ENCODING_QUICKLIST) &#123; quicklistRelease(o-&gt;ptr); &#125; else &#123; serverPanic("Unknown list encoding type"); &#125;&#125;// 释放一个无序集合对象void freeSetObject(robj *o) &#123; switch (o-&gt;encoding) &#123; case OBJ_ENCODING_HT: dictRelease((dict*) o-&gt;ptr); break; case OBJ_ENCODING_INTSET: zfree(o-&gt;ptr); break; default: serverPanic("Unknown set encoding type"); &#125;&#125;// 释放一个有序集合对象void freeZsetObject(robj *o) &#123; zset *zs; switch (o-&gt;encoding) &#123; case OBJ_ENCODING_SKIPLIST: zs = o-&gt;ptr; dictRelease(zs-&gt;dict); zslFree(zs-&gt;zsl); zfree(zs); break; case OBJ_ENCODING_ZIPLIST: zfree(o-&gt;ptr); break; default: serverPanic("Unknown sorted set encoding"); &#125;&#125;// 释放一个字典对象空间void freeHashObject(robj *o) &#123; switch (o-&gt;encoding) &#123; case OBJ_ENCODING_HT: dictRelease((dict*) o-&gt;ptr); break; case OBJ_ENCODING_ZIPLIST: zfree(o-&gt;ptr); break; default: serverPanic("Unknown hash encoding type"); break; &#125;&#125;// 释放一个模块对象空间void freeModuleObject(robj *o) &#123; moduleValue *mv = o-&gt;ptr; mv-&gt;type-&gt;free(mv-&gt;value); zfree(mv);&#125;// 增加对象引用void incrRefCount(robj *o) &#123; if (o-&gt;refcount != OBJ_SHARED_REFCOUNT) o-&gt;refcount++;&#125;// 减少对象引用void decrRefCount(robj *o) &#123; // 如果对象为1，那么先释放对象中的数据空间，再释放对象空间 if (o-&gt;refcount == 1) &#123; switch(o-&gt;type) &#123; case OBJ_STRING: freeStringObject(o); break; case OBJ_LIST: freeListObject(o); break; case OBJ_SET: freeSetObject(o); break; case OBJ_ZSET: freeZsetObject(o); break; case OBJ_HASH: freeHashObject(o); break; case OBJ_MODULE: freeModuleObject(o); break; default: serverPanic("Unknown object type"); break; &#125; zfree(o); &#125; else &#123; if (o-&gt;refcount &lt;= 0) serverPanic("decrRefCount against refcount &lt;= 0"); if (o-&gt;refcount != OBJ_SHARED_REFCOUNT) o-&gt;refcount--; &#125;&#125;/* This variant of decrRefCount() gets its argument as void, and is useful * as free method in data structures that expect a 'void free_object(void*)' * prototype for the free method. */// 对上一个函数饿包装，传入void型指针void decrRefCountVoid(void *o) &#123; decrRefCount(o);&#125;/* This function set the ref count to zero without freeing the object. * It is useful in order to pass a new object to functions incrementing * the ref count of the received object. Example: * * functionThatWillIncrementRefCount(resetRefCount(CreateObject(...))); * * Otherwise you need to resort to the less elegant pattern: * * *obj = createObject(...); * functionThatWillIncrementRefCount(obj); * decrRefCount(obj); */// 重置引用为0robj *resetRefCount(robj *obj) &#123; obj-&gt;refcount = 0; return obj;&#125;// 检查对象的类型，如果不是制定类型则客户端报错int checkType(client *c, robj *o, int type) &#123; if (o-&gt;type != type) &#123; addReply(c,shared.wrongtypeerr); return 1; &#125; return 0;&#125;// sds字符串是否可以转化为longlong型整数int isSdsRepresentableAsLongLong(sds s, long long *llval) &#123; return string2ll(s,sdslen(s),llval) ? C_OK : C_ERR;&#125;// 字符串对象是否可以转化为longlong类型整数int isObjectRepresentableAsLongLong(robj *o, long long *llval) &#123; serverAssertWithInfo(NULL,o,o-&gt;type == OBJ_STRING); if (o-&gt;encoding == OBJ_ENCODING_INT) &#123; if (llval) *llval = (long) o-&gt;ptr; return C_OK; &#125; else &#123; return isSdsRepresentableAsLongLong(o-&gt;ptr,llval); &#125;&#125;/* Try to encode a string object in order to save space */// 对字符串对象进行再编码以节省内存空间robj *tryObjectEncoding(robj *o) &#123; long value; sds s = o-&gt;ptr; size_t len; /* Make sure this is a string object, the only type we encode * in this function. Other types use encoded memory efficient * representations but are handled by the commands implementing * the type. */ // 对字符串对象进行优化 serverAssertWithInfo(NULL,o,o-&gt;type == OBJ_STRING); /* We try some specialized encoding only for objects that are * RAW or EMBSTR encoded, in other words objects that are still * in represented by an actually array of chars. */ // 只有raw和embstr底层实现可以优化 if (!sdsEncodedObject(o)) return o; /* It's not safe to encode shared objects: shared objects can be shared * everywhere in the "object space" of Redis and may end in places where * they are not handled. We handle them only as values in the keyspace. */ // 引用大于1的话，进行优化不安全 if (o-&gt;refcount &gt; 1) return o; /* Check if we can represent this string as a long integer. * Note that we are sure that a string larger than 20 chars is not * representable as a 32 nor 64 bit integer. */ len = sdslen(s); // 如果字符串长度小于20并且可以转化为longlong整型 if (len &lt;= 20 &amp;&amp; string2l(s,len,&amp;value)) &#123; /* This object is encodable as a long. Try to use a shared object. * Note that we avoid using shared integers when maxmemory is used * because every object needs to have a private LRU field for the LRU * algorithm to work well. */ // 小整形直接转化为内建对象 if ((server.maxmemory == 0 || !(server.maxmemory_policy &amp; MAXMEMORY_FLAG_NO_SHARED_INTEGERS)) &amp;&amp; value &gt;= 0 &amp;&amp; value &lt; OBJ_SHARED_INTEGERS) &#123; decrRefCount(o); incrRefCount(shared.integers[value]); return shared.integers[value]; &#125; else &#123; // 否则就是long整数了，进行转化为int底层实现 if (o-&gt;encoding == OBJ_ENCODING_RAW) sdsfree(o-&gt;ptr); o-&gt;encoding = OBJ_ENCODING_INT; o-&gt;ptr = (void*) value; return o; &#125; &#125; /* If the string is small and is still RAW encoded, * try the EMBSTR encoding which is more efficient. * In this representation the object and the SDS string are allocated * in the same chunk of memory to save space and cache misses. */ // 将raw转化为embstr if (len &lt;= OBJ_ENCODING_EMBSTR_SIZE_LIMIT) &#123; robj *emb; if (o-&gt;encoding == OBJ_ENCODING_EMBSTR) return o; emb = createEmbeddedStringObject(s,sdslen(s)); decrRefCount(o); return emb; &#125; /* We can't encode the object... * * Do the last try, and at least optimize the SDS string inside * the string object to require little space, in case there * is more than 10% of free space at the end of the SDS string. * * We do that only for relatively large strings as this branch * is only entered if the length of the string is greater than * OBJ_ENCODING_EMBSTR_SIZE_LIMIT. */ // 满足条件时，去除多余的空白空间 if (o-&gt;encoding == OBJ_ENCODING_RAW &amp;&amp; sdsavail(s) &gt; len/10)//可用空间是字符串长度的10倍 &#123; o-&gt;ptr = sdsRemoveFreeSpace(o-&gt;ptr); &#125; /* Return the original object. */ return o;&#125;/* Get a decoded version of an encoded object (returned as a new object). * If the object is already raw-encoded just increment the ref count. */// 返回一个解码的字符串对象。如果是已经编码了就引用加1，直接返回。robj *getDecodedObject(robj *o) &#123; robj *dec; if (sdsEncodedObject(o)) &#123; incrRefCount(o); return o; &#125; if (o-&gt;type == OBJ_STRING &amp;&amp; o-&gt;encoding == OBJ_ENCODING_INT) &#123; char buf[32];// 将int底层实现转化为raw ll2string(buf,32,(long)o-&gt;ptr); dec = createStringObject(buf,strlen(buf)); return dec; &#125; else &#123; serverPanic("Unknown encoding type"); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(5)——quicklist篇]]></title>
    <url>%2F2017%2F04%2F29%2Fredis%E6%BA%90%E7%A0%81-5-%E2%80%94%E2%80%94quicklist%E7%AF%87%2F</url>
    <content type="text"><![CDATA[在redis中提供给用户的类型为用户层类型，而redis有很多自己的底层实现，list类型前面已经看过了adlist和ziplist，adlist是一个普通的双向链表，提供listnode数据类型，adlist中有首尾指针，ziplist是分配内存中的一段连续的区域作为存储区，拥有自己的存储规则，adlist的缺点是需要提供首尾指针以及pre和next指针存储区域，并且内存中存储不连续造成内存碎片，ziplist弥补了它的缺点，内存存储连续，并且不需要多余的指针存储，但是连续分区造成小内存碎片，之后难以分配大内存空间，并且每次对list的操作，都涉及内存的操作，与ziplist当时的存储长度有很大关系，所以结合了adlist和ziplist的优点，编写了quicklist，也是用户层list的底层实现。我们先看一下quicklist.h中关于数据结构的定义：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 //快速链表节点数据结构typedef struct quicklistNode &#123; struct quicklistNode *prev;//前节点指针 struct quicklistNode *next;//后节点指针 unsigned char *zl;//ziplist或者压缩链表指针 unsigned int sz; //未被压缩的ziplist的空间字节数 unsigned int count : 16; //ziplist中实体的个数 unsigned int encoding : 2; /* RAW==1 or LZF==2 */ unsigned int container : 2; /* NONE==1 or ZIPLIST==2 目前redis中只有2*/ unsigned int recompress : 1; /* 当前节点中ziplist之前是否被压缩过，在用完之后根据这个标记判断是否要压缩*/ unsigned int attempted_compress : 1; /* 节点的ziplist是否可以压缩*/ unsigned int extra : 10; /* 额外的10位用来扩展*/&#125; quicklistNode;//压缩ziplist的数据结构，当ziplist被压缩后node-&gt;zl指向quicklistLZFtypedef struct quicklistLZF &#123; unsigned int sz; //压缩后的空间字节数 char compressed[];//用来存放压缩后的数据实体&#125; quicklistLZF; //快速链表数据结构typedef struct quicklist &#123; quicklistNode *head; //头结点指针 quicklistNode *tail; //尾节点指针 unsigned long count; /* quicklist中实体个数*/ unsigned int len; /* 个数节点 */ int fill : 16; /* 每一个节点上ziplist中最多存储的实体个数 */ unsigned int compress : 16; /* 节点压缩限制，表示quicklist两端不压缩的节点的个数，当值为0时表示所有节点不压缩 */&#125; quicklist;//快速链表的节点迭代数据结构typedef struct quicklistIter &#123; const quicklist *quicklist;//迭代器指向的链表指针 quicklistNode *current;//当前迭代器指向节点 unsigned char *zi;//当前节点的ziplist指针 long offset; /* 当前ziplist中指向实体的偏移量*/ int direction;//迭代器方向&#125; quicklistIter;//快速链表中实体的数据结构typedef struct quicklistEntry &#123; const quicklist *quicklist;//实体所属的快速链表的指针 quicklistNode *node;//实体所属的快速链表节点的指针 unsigned char *zi;//实体所属的ziplist的指针 unsigned char *value;//实体的字符串值 long long longval;//实体的整数值 unsigned int sz;//实体的字节数 int offset;//实体在ziplist中偏移量&#125; quicklistEntry; 根据数据结构就可以看出来redis是怎么将adlist和ziplist结合的，quicklist表面上是一个普通的adlist双向链表结构，但是每一个节点中存储着一个ziplist，在每一个节点上存储着许多实体，这样就利用了两者的优点，所以redis的配置文件里面提供了两个参数分别对应了quicklist中的fill和compress，用户可以自己控制每个ziplist的最大存储量以及压缩的限制，以做到适应不同的场景。在quicklist.c文件中，比较重要的操作有压缩解压数据操作，插入，删除操作下面就分析一下这几个函数。123456789101112131415161718192021222324252627282930313233343536373839/* Insert 'new_node' after 'old_node' if 'after' is 1. * Insert 'new_node' before 'old_node' if 'after' is 0. * Note: 'new_node' is *always* uncompressed, so if we assign it to * head or tail, we do not need to uncompress it. *///在旧节点的前面或者后面添加节点,当插入实体时，节点超过了fill时，就需要创建新的节点存储实体REDIS_STATIC void __quicklistInsertNode(quicklist *quicklist, quicklistNode *old_node, quicklistNode *new_node, int after) &#123; if (after) &#123;//在旧节点之后 new_node-&gt;prev = old_node; if (old_node) &#123;//节点之间的链接 new_node-&gt;next = old_node-&gt;next; if (old_node-&gt;next) old_node-&gt;next-&gt;prev = new_node; old_node-&gt;next = new_node; &#125; if (quicklist-&gt;tail == old_node)//如果旧节点是尾节点修改尾节点指针 quicklist-&gt;tail = new_node; &#125; else &#123;//在旧节点之前 new_node-&gt;next = old_node; if (old_node) &#123;//节点之间的链接 new_node-&gt;prev = old_node-&gt;prev; if (old_node-&gt;prev) old_node-&gt;prev-&gt;next = new_node; old_node-&gt;prev = new_node; &#125; if (quicklist-&gt;head == old_node)//修改头指针 quicklist-&gt;head = new_node; &#125; /* If this insert creates the only element so far, initialize head/tail. */ if (quicklist-&gt;len == 0) &#123; quicklist-&gt;head = quicklist-&gt;tail = new_node; &#125; if (old_node) quicklistCompress(quicklist, old_node);//压缩节点，旧节点可能是两端的节点 quicklist-&gt;len++;//修改节点长度&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/* Force 'quicklist' to meet compression guidelines set by compress depth. * The only way to guarantee interior nodes get compressed is to iterate * to our "interior" compress depth then compress the next node we find. * If compress depth is larger than the entire list, we return immediately. *///根据depth来压缩quicklist，并且对参数node节点进行压缩，quicklist默认两端的实体经常被使用，所以两端的node不压缩，中间的node进行出具压缩REDIS_STATIC void __quicklistCompress(const quicklist *quicklist, quicklistNode *node) &#123; /* If length is less than our compress depth (from both sides), * we can't compress anything. */ if (!quicklistAllowsCompression(quicklist) || quicklist-&gt;len &lt; (unsigned int)(quicklist-&gt;compress * 2)) return; //如果链表不允许压缩或者长度小于depth的两倍直接返回 /* Iterate until we reach compress depth for both sides of the list.a * Note: because we do length checks at the *top* of this function, * we can skip explicit null checks below. Everything exists. */ quicklistNode *forward = quicklist-&gt;head; quicklistNode *reverse = quicklist-&gt;tail; int depth = 0; int in_depth = 0;//node解压标记 //头尾节点同时进行压缩进行 while (depth++ &lt; quicklist-&gt;compress) &#123; quicklistDecompressNode(forward); quicklistDecompressNode(reverse); if (forward == node || reverse == node) in_depth = 1;//记录node是否解压 if (forward == reverse) return;//已经解压完成返回 forward = forward-&gt;next; reverse = reverse-&gt;prev; &#125; if (!in_depth) quicklistCompressNode(node); if (depth &gt; 2) &#123;//对于depth&gt;2的节点要进行压缩边界节点 /* At this point, forward and reverse are one node beyond depth */ quicklistCompressNode(forward); quicklistCompressNode(reverse); &#125;&#125; 12345678910111213141516171819202122232425/* Add new entry to head node of quicklist. * * Returns 0 if used existing head. * Returns 1 if new head created. *///在quicklist头部加入一个实体，首先检查头部节点是否可以再加入实体，如果不可以创建节点添加实体，再添加节点到quicklistint quicklistPushHead(quicklist *quicklist, void *value, size_t sz) &#123; quicklistNode *orig_head = quicklist-&gt;head; if (likely(//检查头部是否可以插入实体 _quicklistNodeAllowInsert(quicklist-&gt;head, quicklist-&gt;fill, sz))) &#123; quicklist-&gt;head-&gt;zl = ziplistPush(quicklist-&gt;head-&gt;zl, value, sz, ZIPLIST_HEAD);//插入实体 quicklistNodeUpdateSz(quicklist-&gt;head);//更新node的size &#125; else &#123; //达到ziplist的最大实体数，创建新的节点插入实体 quicklistNode *node = quicklistCreateNode(); node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_HEAD); quicklistNodeUpdateSz(node); _quicklistInsertNodeBefore(quicklist, quicklist-&gt;head, node);//插入节点到quicklist &#125; //更新quicklist quicklist-&gt;count++; quicklist-&gt;head-&gt;count++; return (orig_head != quicklist-&gt;head);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/* Insert a new entry before or after existing entry 'entry'. * * If after==1, the new value is inserted after 'entry', otherwise * the new value is inserted before 'entry'. *///在quicklist中插入一个实体，给一个已经存在的实体entry作为标记，在其之前或之后REDIS_STATIC void _quicklistInsert(quicklist *quicklist, quicklistEntry *entry, void *value, const size_t sz, int after) &#123; int full = 0, at_tail = 0, at_head = 0, full_next = 0, full_prev = 0; int fill = quicklist-&gt;fill; quicklistNode *node = entry-&gt;node; quicklistNode *new_node = NULL; //没有节点。表明quicklist中还没有node if (!node) &#123; /* we have no reference node, so let's create only node in the list */ D("No node given!"); new_node = quicklistCreateNode();//创建节点 new_node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_HEAD);//创建ziplist加入实体 __quicklistInsertNode(quicklist, NULL, new_node, after);//插入节点 new_node-&gt;count++; quicklist-&gt;count++; return; &#125; /* Populate accounting flags for easier boolean checks later */ //下面试分析quicklist和节点，然后设置flags，便于后面分情况处理 if (!_quicklistNodeAllowInsert(node, fill, sz)) &#123; //该节点已经达到fill D("Current node is full with count %d with requested fill %lu", node-&gt;count, fill); full = 1; &#125; if (after &amp;&amp; (entry-&gt;offset == node-&gt;count)) &#123; D("At Tail of current ziplist"); at_tail = 1; if (!_quicklistNodeAllowInsert(node-&gt;next, fill, sz)) &#123; D("Next node is full too."); full_next = 1; //在该节点的尾部添加，并且下一个节点已经达到fill了 &#125; &#125; if (!after &amp;&amp; (entry-&gt;offset == 0)) &#123; D("At Head"); at_head = 1; if (!_quicklistNodeAllowInsert(node-&gt;prev, fill, sz)) &#123; D("Prev node is full too."); full_prev = 1; //在ziplist头部添加，并且前一个节点已经达到fill &#125; &#125; /* Now determine where and how to insert the new element */ //根据标记来决定如何添加实体 if (!full &amp;&amp; after) &#123;//插入节点未满，在给定实体之后插入 D("Not full, inserting after current position."); quicklistDecompressNodeForUse(node);//先解压节点数据 unsigned char *next = ziplistNext(node-&gt;zl, entry-&gt;zi); if (next == NULL) &#123; node-&gt;zl = ziplistPush(node-&gt;zl, value, sz, ZIPLIST_TAIL);//标记实体之后没有实体直接在尾部push &#125; else &#123;//否则在next之前插入 node-&gt;zl = ziplistInsert(node-&gt;zl, next, value, sz); &#125; node-&gt;count++; quicklistNodeUpdateSz(node); quicklistRecompressOnly(quicklist, node);//再次压缩 &#125; else if (!full &amp;&amp; !after) &#123;//基本同上 D("Not full, inserting before current position."); quicklistDecompressNodeForUse(node); node-&gt;zl = ziplistInsert(node-&gt;zl, entry-&gt;zi, value, sz); node-&gt;count++; quicklistNodeUpdateSz(node); quicklistRecompressOnly(quicklist, node); &#125; else if (full &amp;&amp; at_tail &amp;&amp; node-&gt;next &amp;&amp; !full_next &amp;&amp; after) &#123; /* If we are: at tail, next has free space, and inserting after: * - insert entry at head of next node. */ //如果插入节点满，并且之后的节点未满,那么在下一个节点头部直接添加 D("Full and tail, but next isn't full; inserting next node head"); new_node = node-&gt;next; quicklistDecompressNodeForUse(new_node); new_node-&gt;zl = ziplistPush(new_node-&gt;zl, value, sz, ZIPLIST_HEAD); new_node-&gt;count++; quicklistNodeUpdateSz(new_node); quicklistRecompressOnly(quicklist, new_node); &#125; else if (full &amp;&amp; at_head &amp;&amp; node-&gt;prev &amp;&amp; !full_prev &amp;&amp; !after) &#123; /* If we are: at head, previous has free space, and inserting before: * - insert entry at tail of previous node. */ //如果插入节点满，并且之前的节点未满,那么在上一个节点尾部直接添加 D("Full and head, but prev isn't full, inserting prev node tail"); new_node = node-&gt;prev; quicklistDecompressNodeForUse(new_node); new_node-&gt;zl = ziplistPush(new_node-&gt;zl, value, sz, ZIPLIST_TAIL); new_node-&gt;count++; quicklistNodeUpdateSz(new_node); quicklistRecompressOnly(quicklist, new_node); &#125; else if (full &amp;&amp; ((at_tail &amp;&amp; node-&gt;next &amp;&amp; full_next &amp;&amp; after) || (at_head &amp;&amp; node-&gt;prev &amp;&amp; full_prev &amp;&amp; !after))) &#123; /* If we are: full, and our prev/next is full, then: * - create new node and attach to quicklist */ //如果插入节点满了，并且前一个节点或后一个节点都满了，那么创建一个节点，插入实体，插入节点 D("\tprovisioning new node..."); new_node = quicklistCreateNode(); new_node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_HEAD); new_node-&gt;count++; quicklistNodeUpdateSz(new_node); __quicklistInsertNode(quicklist, node, new_node, after); &#125; else if (full) &#123; /* else, node is full we need to split it. */ /* covers both after and !after cases */ //如果插入节点满了，并且实体是插入到节点中间，先分割节点，然后插入实体，然后尝试合并节点 D("\tsplitting node..."); quicklistDecompressNodeForUse(node); new_node = _quicklistSplitNode(node, entry-&gt;offset, after); new_node-&gt;zl = ziplistPush(new_node-&gt;zl, value, sz, after ? ZIPLIST_HEAD : ZIPLIST_TAIL); new_node-&gt;count++; quicklistNodeUpdateSz(new_node); __quicklistInsertNode(quicklist, node, new_node, after); _quicklistMergeNodes(quicklist, node); &#125; quicklist-&gt;count++;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/* Delete a range of elements from the quicklist. * * elements may span across multiple quicklistNodes, so we * have to be careful about tracking where we start and end. * * Returns 1 if entries were deleted, 0 if nothing was deleted. */ //删除quicklist一定范围内的实体int quicklistDelRange(quicklist *quicklist, const long start, const long count) &#123; if (count &lt;= 0)//确保删除个数大于0 return 0; unsigned long extent = count; /* range is inclusive of start position */ //extent为从start开始删除个数，下面检测是否count越界，设置count if (start &gt;= 0 &amp;&amp; extent &gt; (quicklist-&gt;count - start)) &#123; /* if requesting delete more elements than exist, limit to list size. */ extent = quicklist-&gt;count - start;//剩余总数小于count &#125; else if (start &lt; 0 &amp;&amp; extent &gt; (unsigned long)(-start)) &#123; /* else, if at negative offset, limit max size to rest of list. */ extent = -start; /* c.f. LREM -29 29; just delete until end. */ //count大于尾部剩余个数 &#125; quicklistEntry entry; if (!quicklistIndex(quicklist, start, &amp;entry)) return 0; D("Quicklist delete request for start %ld, count %ld, extent: %ld", start, count, extent); quicklistNode *node = entry.node; /* iterate over next nodes until everything is deleted. */ while (extent) &#123; quicklistNode *next = node-&gt;next; unsigned long del; int delete_entire_node = 0;//删除是否包含整个node标记 if (entry.offset == 0 &amp;&amp; extent &gt;= node-&gt;count) &#123; /* If we are deleting more than the count of this node, we * can just delete the entire node without ziplist math. */ //从node的第一个实体开始，extent大于node中包含实体个数，表示删除整个节点即可 delete_entire_node = 1; del = node-&gt;count; &#125; else if (entry.offset &gt;= 0 &amp;&amp; extent &gt;= node-&gt;count) &#123; /* If deleting more nodes after this one, calculate delete based * on size of current node. */ //不从node第一个实体开始，extent大于node中包含实体个数，删除该节点尾部所有实体 del = node-&gt;count - entry.offset;//删除个数为节点实体个数减去开始删除的实体index &#125; else if (entry.offset &lt; 0) &#123; /* If offset is negative, we are in the first run of this loop * and we are deleting the entire range * from this start offset to end of list. Since the Negative * offset is the number of elements until the tail of the list, * just use it directly as the deletion count. */ //offset小于0从节点尾部计数，如果剩余个数大于extent，del=extent否则，尾部全部删除 del = -entry.offset; /* If the positive offset is greater than the remaining extent, * we only delete the remaining extent, not the entire offset. */ if (del &gt; extent) del = extent; &#125; else &#123; /* else, we are deleting less than the extent of this node, so * use extent directly. */ del = extent; &#125; D("[%ld]: asking to del: %ld because offset: %d; (ENTIRE NODE: %d), " "node count: %u", extent, del, entry.offset, delete_entire_node, node-&gt;count); if (delete_entire_node) &#123; __quicklistDelNode(quicklist, node);//直接删除节点 &#125; else &#123; quicklistDecompressNodeForUse(node); node-&gt;zl = ziplistDeleteRange(node-&gt;zl, entry.offset, del);//删除ziplist中范围实体 quicklistNodeUpdateSz(node); node-&gt;count -= del; quicklist-&gt;count -= del; quicklistDeleteIfEmpty(quicklist, node); if (node) quicklistRecompressOnly(quicklist, node); &#125; extent -= del; node = next; entry.offset = 0;//第一轮执行后，必然从下一个节点的头部开始删除 &#125; return 1;&#125; 在quicklist的底层实现中，不仅涉及到node的删除添加，还有ziplist的删除添加，当ziplist的count达到fill指标后，就要考虑创建新的节点添加实体，删除实体至节点为空时，就要考虑删除节点了，所有添加删除时，需要考虑的情况较多，比较复杂，但这样的代码换来了内存的高效是值得的。此外quicklist的底层还是实现了比如删除指定index的实体，分割quicklistnode，合并quicklistnode等操作，这里就不一一注释了。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(4)——intset和ziplist篇]]></title>
    <url>%2F2017%2F04%2F22%2Fredis%E6%BA%90%E7%A0%81-4-%E2%80%94%E2%80%94intset%E5%92%8Cziplist%E7%AF%87%2F</url>
    <content type="text"><![CDATA[intset存储整型的集合，内部按照大小排序，有三种整型长度可选，一般在元素为整数并且个数比较少的时候，采用inset结构型。intset.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/* * Copyright (c) 2009-2012, Pieter Noordhuis &lt;pcnoordhuis at gmail dot com&gt; * Copyright (c) 2009-2012, Salvatore Sanfilippo &lt;antirez at gmail dot com&gt; * All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions are met: * * * Redistributions of source code must retain the above copyright notice, * this list of conditions and the following disclaimer. * * Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * Neither the name of Redis nor the names of its contributors may be used * to endorse or promote products derived from this software without * specific prior written permission. * * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE * POSSIBILITY OF SUCH DAMAGE. */#ifndef __INTSET_H#define __INTSET_H#include &lt;stdint.h&gt;//整型集合typedef struct intset &#123; uint32_t encoding;//编码 uint32_t length;//长度 int8_t contents[];//存放内容&#125; intset;intset *intsetNew(void);//创建一个整型集合intset *intsetAdd(intset *is, int64_t value, uint8_t *success);//添加整数 success代表是否成功intset *intsetRemove(intset *is, int64_t value, int *success);//移除整数uint8_t intsetFind(intset *is, int64_t value);//查找整数是否在set中int64_t intsetRandom(intset *is);//随机获取一个元素uint8_t intsetGet(intset *is, uint32_t pos, int64_t *value);//通过pos获取整数uint32_t intsetLen(const intset *is);//设置长度size_t intsetBlobLen(intset *is);//设置intset结构2进制长度#ifdef REDIS_TESTint intsetTest(int argc, char *argv[]);#endif#endif // __INTSET_H intset.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include "intset.h"#include "zmalloc.h"#include "endianconv.h"/* Note that these encodings are ordered, so: * INTSET_ENC_INT16 &lt; INTSET_ENC_INT32 &lt; INTSET_ENC_INT64. */ //编码方式 长度不同#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t))/* Return the required encoding for the provided value. *///返回value适合的编码static uint8_t _intsetValueEncoding(int64_t v) &#123; if (v &lt; INT32_MIN || v &gt; INT32_MAX) return INTSET_ENC_INT64; else if (v &lt; INT16_MIN || v &gt; INT16_MAX) return INTSET_ENC_INT32; else return INTSET_ENC_INT16;&#125;/* Return the value at pos, given an encoding. *///根据编码返回pos处的整型数static int64_t _intsetGetEncoded(intset *is, int pos, uint8_t enc) &#123; int64_t v64; int32_t v32; int16_t v16; if (enc == INTSET_ENC_INT64) &#123; memcpy(&amp;v64,((int64_t*)is-&gt;contents)+pos,sizeof(v64)); memrev64ifbe(&amp;v64);//翻转数据 return v64; &#125; else if (enc == INTSET_ENC_INT32) &#123; memcpy(&amp;v32,((int32_t*)is-&gt;contents)+pos,sizeof(v32)); memrev32ifbe(&amp;v32); return v32; &#125; else &#123; memcpy(&amp;v16,((int16_t*)is-&gt;contents)+pos,sizeof(v16)); memrev16ifbe(&amp;v16); return v16; &#125;&#125;/* Return the value at pos, using the configured encoding. *///根据配置的编码返回pos处的整数static int64_t _intsetGet(intset *is, int pos) &#123; return _intsetGetEncoded(is,pos,intrev32ifbe(is-&gt;encoding));&#125;/* Set the value at pos, using the configured encoding. */static void _intsetSet(intset *is, int pos, int64_t value) &#123; uint32_t encoding = intrev32ifbe(is-&gt;encoding); //获取编码 if (encoding == INTSET_ENC_INT64) &#123; ((int64_t*)is-&gt;contents)[pos] = value;//设置value memrev64ifbe(((int64_t*)is-&gt;contents)+pos);//翻转数据 &#125; else if (encoding == INTSET_ENC_INT32) &#123; ((int32_t*)is-&gt;contents)[pos] = value; memrev32ifbe(((int32_t*)is-&gt;contents)+pos); &#125; else &#123; ((int16_t*)is-&gt;contents)[pos] = value; memrev16ifbe(((int16_t*)is-&gt;contents)+pos); &#125;&#125;/* Create an empty intset. */intset *intsetNew(void) &#123; intset *is = zmalloc(sizeof(intset)); is-&gt;encoding = intrev32ifbe(INTSET_ENC_INT16);//默认的编码 is-&gt;length = 0; return is;&#125;/* Resize the intset */static intset *intsetResize(intset *is, uint32_t len) &#123; uint32_t size = len*intrev32ifbe(is-&gt;encoding);//获取编码方式确定空间大小 is = zrealloc(is,sizeof(intset)+size); return is;&#125;/* Search for the position of "value". Return 1 when the value was found and * sets "pos" to the position of the value within the intset. Return 0 when * the value is not present in the intset and sets "pos" to the position * where "value" can be inserted. */ //寻找value 如果返回1表示找到 pos为value的index 返回0表示没有找到 pos表示可以插入的indexstatic uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) &#123; int min = 0, max = intrev32ifbe(is-&gt;length)-1, mid = -1; int64_t cur = -1; /* The value can never be found when the set is empty */ if (intrev32ifbe(is-&gt;length) == 0) &#123;//没有元素 if (pos) *pos = 0; return 0; &#125; else &#123; /* Check for the case where we know we cannot find the value, * but do know the insert position. */ if (value &gt; _intsetGet(is,intrev32ifbe(is-&gt;length)-1)) &#123; if (pos) *pos = intrev32ifbe(is-&gt;length);//可见intset内部元素从小到大排序 return 0; &#125; else if (value &lt; _intsetGet(is,0)) &#123; if (pos) *pos = 0; return 0; &#125; &#125; while(max &gt;= min) &#123; //二分法查询 mid = ((unsigned int)min + (unsigned int)max) &gt;&gt; 1; cur = _intsetGet(is,mid); if (value &gt; cur) &#123; min = mid+1; &#125; else if (value &lt; cur) &#123; max = mid-1; &#125; else &#123; break; &#125; &#125; if (value == cur) &#123; if (pos) *pos = mid; return 1; &#125; else &#123; if (pos) *pos = min; return 0; &#125;&#125;/* Upgrades the intset to a larger encoding and inserts the given integer. *///给一个绝对值最大最小的数 update编码并插入数据static intset *intsetUpgradeAndAdd(intset *is, int64_t value) &#123; uint8_t curenc = intrev32ifbe(is-&gt;encoding); uint8_t newenc = _intsetValueEncoding(value); int length = intrev32ifbe(is-&gt;length); int prepend = value &lt; 0 ? 1 : 0; /* First set new encoding and resize */ is-&gt;encoding = intrev32ifbe(newenc); is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); /* Upgrade back-to-front so we don't overwrite values. * Note that the "prepend" variable is used to make sure we have an empty * space at either the beginning or the end of the intset. */ //从后往前 防止扩大编码 覆盖数据 while(length--) _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc)); /* Set the value at the beginning or the end. */ if (prepend) _intsetSet(is,0,value); else _intsetSet(is,intrev32ifbe(is-&gt;length),value); is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is;&#125;//从from开始所有的数据移动到to开始的indexstatic void intsetMoveTail(intset *is, uint32_t from, uint32_t to) &#123; void *src, *dst; uint32_t bytes = intrev32ifbe(is-&gt;length)-from; uint32_t encoding = intrev32ifbe(is-&gt;encoding); if (encoding == INTSET_ENC_INT64) &#123; src = (int64_t*)is-&gt;contents+from; dst = (int64_t*)is-&gt;contents+to; bytes *= sizeof(int64_t); &#125; else if (encoding == INTSET_ENC_INT32) &#123; src = (int32_t*)is-&gt;contents+from; dst = (int32_t*)is-&gt;contents+to; bytes *= sizeof(int32_t); &#125; else &#123; src = (int16_t*)is-&gt;contents+from; dst = (int16_t*)is-&gt;contents+to; bytes *= sizeof(int16_t); &#125; memmove(dst,src,bytes);&#125;/* Insert an integer in the intset */intset *intsetAdd(intset *is, int64_t value, uint8_t *success) &#123; uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; if (success) *success = 1; /* Upgrade encoding if necessary. If we need to upgrade, we know that * this value should be either appended (if &gt; 0) or prepended (if &lt; 0), * because it lies outside the range of existing values. */ if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123;//扩大编码 /* This always succeeds, so we don't need to curry *success. */ return intsetUpgradeAndAdd(is,value); &#125; else &#123; /* Abort if the value is already present in the set. * This call will populate "pos" with the right position to insert * the value when it cannot be found. */ if (intsetSearch(is,value,&amp;pos)) &#123;//搜索是否已有该元素 if (success) *success = 0; return is; &#125; is = intsetResize(is,intrev32ifbe(is-&gt;length)+1);//分配空间 if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1);//整体后裔 &#125; _intsetSet(is,pos,value);//插入数据 is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is;&#125;/* Delete integer from intset */intset *intsetRemove(intset *is, int64_t value, int *success) &#123; uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; if (success) *success = 0; if (valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,&amp;pos)) &#123; uint32_t len = intrev32ifbe(is-&gt;length); /* We know we can delete */ if (success) *success = 1; /* Overwrite value with tail and update length */ if (pos &lt; (len-1)) intsetMoveTail(is,pos+1,pos);//整体迁移 is = intsetResize(is,len-1);//调整content size is-&gt;length = intrev32ifbe(len-1); &#125; return is;&#125;/* Determine whether a value belongs to this set */uint8_t intsetFind(intset *is, int64_t value) &#123; uint8_t valenc = _intsetValueEncoding(value); return valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,NULL);&#125;/* Return random member */int64_t intsetRandom(intset *is) &#123; return _intsetGet(is,rand()%intrev32ifbe(is-&gt;length));&#125;/* Get the value at the given position. When this position is * out of range the function returns 0, when in range it returns 1. */uint8_t intsetGet(intset *is, uint32_t pos, int64_t *value) &#123; if (pos &lt; intrev32ifbe(is-&gt;length)) &#123; *value = _intsetGet(is,pos); return 1; &#125; return 0;&#125;/* Return intset length */uint32_t intsetLen(const intset *is) &#123; return intrev32ifbe(is-&gt;length);&#125;/* Return intset blob size in bytes. */size_t intsetBlobLen(intset *is) &#123; return sizeof(intset)+intrev32ifbe(is-&gt;length)*intrev32ifbe(is-&gt;encoding);&#125; ziplist是压缩的链表，存储整数和字符串，用一个字符串存储，其中设定了特定的格式，通过解码编码函数写入读出，以及各自的格式。ziplist.h123456789101112131415161718192021222324252627#ifndef _ZIPLIST_H#define _ZIPLIST_H#define ZIPLIST_HEAD 0#define ZIPLIST_TAIL 1unsigned char *ziplistNew(void);//创建新的ziplistunsigned char *ziplistMerge(unsigned char **first, unsigned char **second);//合并两个ziplistunsigned char *ziplistPush(unsigned char *zl, unsigned char *s, unsigned int slen, int where);//从头部或尾部push一个实体unsigned char *ziplistIndex(unsigned char *zl, int index);//获取index处的实体unsigned char *ziplistNext(unsigned char *zl, unsigned char *p);//实体p的下一个实体unsigned char *ziplistPrev(unsigned char *zl, unsigned char *p);//实体p的上一个实体unsigned int ziplistGet(unsigned char *p, unsigned char **sval, unsigned int *slen, long long *lval);//获取当前实体p的字符串或整数值unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen);//在p实体后面插入实体unsigned char *ziplistDelete(unsigned char *zl, unsigned char **p);//删除实体punsigned char *ziplistDeleteRange(unsigned char *zl, int index, unsigned int num);//删除一个范围的实体unsigned int ziplistCompare(unsigned char *p, unsigned char *s, unsigned int slen);//用实体p和给定的值对比unsigned char *ziplistFind(unsigned char *p, unsigned char *vstr, unsigned int vlen, unsigned int skip);//每skip个实体，查找制定的实体unsigned int ziplistLen(unsigned char *zl);//返回ziplist的长度size_t ziplistBlobLen(unsigned char *zl);//返回ziplist的空间void ziplistRepr(unsigned char *zl);//输出ziplist#ifdef REDIS_TESTint ziplistTest(int argc, char *argv[]);#endif#endif /* _ZIPLIST_H */ ziplist.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258125912601261126212631264126512661267126812691270127112721273127412751276127712781279128012811282128312841285128612871288128912901291129212931294129512961297129812991300/* The ziplist is a specially encoded dually linked list that is designed * to be very memory efficient. It stores both strings and integer values, * where integers are encoded as actual integers instead of a series of * characters. It allows push and pop operations on either side of the list * in O(1) time. However, because every operation requires a reallocation of * the memory used by the ziplist, the actual complexity is related to the * amount of memory used by the ziplist. *压缩列表是一种特殊编码的链表，设计以做到内存高效。存储字符串和整型， *整型用一串字符代替，它可以从list两边pop或push,效率O(1)。但是每次操作都要分配内存，所以 *真实复杂度与list的内存使用量相关。 * ---------------------------------------------------------------------------- * * ZIPLIST OVERALL LAYOUT * ====================== * * The general layout of the ziplist is as follows: * 压缩列表整体结构 * &lt;zlbytes&gt; &lt;zltail&gt; &lt;zllen&gt; &lt;entry&gt; &lt;entry&gt; ... &lt;entry&gt; &lt;zlend&gt; * * NOTE: all fields are stored in little endian, if not specified otherwise. * * &lt;uint32_t zlbytes&gt; is an unsigned integer to hold the number of bytes that * the ziplist occupies, including the four bytes of the zlbytes field itself. * This value needs to be stored to be able to resize the entire structure * without the need to traverse it first. * zlbytes是一个无符号整数表示list分配的空间字节数，包含自身的4字节，这个字节数用来调整整个结构体而不需要遍历一遍。 * &lt;uint32_t zltail&gt; is the offset to the last entry in the list. This allows * a pop operation on the far side of the list without the need for full * traversal. * zltail是list中最后一个实体的偏移字节数，可以方便pop操作而不需要从头遍历整个list * &lt;uint16_t zllen&gt; is the number of entries. When there are more than * 2^16-2 entires, this value is set to 2^16-1 and we need to traverse the * entire list to know how many items it holds. * zllen是实体的个数，超过2^16-2时，值被设置为2^16-1，我们需要遍历实体列表来确定这个值。 * &lt;uint8_t zlend&gt; is a special entry representing the end of the ziplist. * Is encoded as a single byte equal to 255. No other normal entry starts * with a byte set to the value of 255. * zlend是一个特殊的实体代表压缩列表的结尾，没有别的特别定义被设置为255 实体结构 * ZIPLIST ENTRIES * =============== * * Every entry in the ziplist is prefixed by metadata that contains two pieces * of information. First, the length of the previous entry is stored to be * able to traverse the list from back to front. Second, the entry encoding is * provided. It represents the entry type, integer or string, and in the case * of strings it also represents the length of the string payload. * So a complete entry is stored like this: * 每一实体都有一个配置信息前缀包含两段信息，第一，前一个存储实体的长度用来从后往前遍历。 * 第二，实体的编码，它代表了实体类型，整型或字符串，在字符串的情况下，它也表示字符串的长度。 * &lt;prevlen&gt; &lt;encoding&gt; &lt;entry-data&gt; * * Sometimes the encoding represents the entry itself, like for small integers * as we'll see later. In such a case the &lt;entry-data&gt; part is missing, and we * could have just: * 有时候编码代表实体自身，比如小整数。实体数据部分消失，如下: * &lt;prevlen&gt; &lt;encoding&gt; * * The length of the previous entry, &lt;prevlen&gt;, is encoded in the following way: * If this length is smaller than 255 bytes, it will only consume a single * byte representing the length as an unsinged 8 bit integer. When the length * is greater than or equal to 255, it will consume 5 bytes. The first byte is * set to 255 (FF) to indicate a larger value is following. The remaining 4 * bytes take the length of the previous entry as value. * 如果&lt;prevlen&gt;长度小于255，用一个单独的字节作为一个8位无符号整数，如果大于或者等于255 用5个字节。第一字节设为255。表示下面是一个更大的数，剩下的4个字节存储前一个实体长度。 * So practically an entry is encoded in the following way: * * &lt;prevlen from 0 to 254&gt; &lt;encoding&gt; &lt;entry&gt; * * Or alternatively if the previous entry length is greater than 254 bytes * the following encoding is used: * * 0xFF &lt;4 bytes unsigned little endian prevlen&gt; &lt;encoding&gt; &lt;entry&gt; * * The encoding field of the entry depends on the content of the * entry. When the entry is a string, the first 2 bits of the encoding first * byte will hold the type of encoding used to store the length of the string, * followed by the actual length of the string. When the entry is an integer * the first 2 bits are both set to 1. The following 2 bits are used to specify * what kind of integer will be stored after this header. An overview of the * different types and encodings is as follows. The first byte is always enough * to determine the kind of entry. * 编码部分取决于实体内容，当实体是字符串，第一字节的前两位将表示用来存储字符串的长度的编码类型， 接下来存储真实的字符串长度，当实体是整数，第一个字节的前两位为1，接下来的两位用来存储整数的类型。 * |00pppppp| - 1 byte * String value with length less than or equal to 63 bytes (6 bits). * "pppppp" represents the unsigned 6 bit length. * |01pppppp|qqqqqqqq| - 2 bytes * String value with length less than or equal to 16383 bytes (14 bits). * IMPORTANT: The 14 bit number is stored in big endian. * |10000000|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes * String value with length greater than or equal to 16384 bytes. * Only the 4 bytes following the first byte represents the length * up to 32^2-1. The 6 lower bits of the first byte are not used and * are set to zero. * IMPORTANT: The 32 bit number is stored in big endian. * |11000000| - 3 bytes * Integer encoded as int16_t (2 bytes). * |11010000| - 5 bytes * Integer encoded as int32_t (4 bytes). * |11100000| - 9 bytes * Integer encoded as int64_t (8 bytes). * |11110000| - 4 bytes * Integer encoded as 24 bit signed (3 bytes). * |11111110| - 2 bytes * Integer encoded as 8 bit signed (1 byte). * |1111xxxx| - (with xxxx between 0000 and 1101) immediate 4 bit integer. * Unsigned integer from 0 to 12. The encoded value is actually from * 1 to 13 because 0000 and 1111 can not be used, so 1 should be * subtracted from the encoded 4 bit value to obtain the right value. * |11111111| - End of ziplist special entry. * * Like for the ziplist header, all the integers are represented in little * endian byte order, even when this code is compiled in big endian systems. * * EXAMPLES OF ACTUAL ZIPLISTS * =========================== * * The following is a ziplist containing the two elements representing * the strings "2" and "5". It is composed of 15 bytes, that we visually * split into sections: * * [0f 00 00 00] [0c 00 00 00] [02 00] [00 f3] [02 f6] [ff] * | | | | | | * zlbytes zltail entries "2" "5" end * * The first 4 bytes represent the number 15, that is the number of bytes * the whole ziplist is composed of. The second 4 bytes are the offset * at which the last ziplist entry is found, that is 12, in fact the * last entry, that is "5", is at offset 12 inside the ziplist. * The next 16 bit integer represents the number of elements inside the * ziplist, its value is 2 since there are just two elements inside. * Finally "00 f3" is the first entry representing the number 2. It is * composed of the previous entry length, which is zero because this is * our first entry, and the byte F3 which corresponds to the encoding * |1111xxxx| with xxxx between 0001 and 1101. We need to remove the "F" * higher order bits 1111, and subtract 1 from the "3", so the entry value * is "2". The next entry has a prevlen of 02, since the first entry is * composed of exactly two bytes. The entry itself, F6, is encoded exactly * like the first entry, and 6-1 = 5, so the value of the entry is 5. * Finally the special entry FF signals the end of the ziplist. * * Adding another element to the above string with the value "Hello World" * allows us to show how the ziplist encodes small strings. We'll just show * the hex dump of the entry itself. Imagine the bytes as following the * entry that stores "5" in the ziplist above: * * [02] [0b] [48 65 6c 6c 6f 20 57 6f 72 6c 64] * * The first byte, 02, is the length of the previous entry. The next * byte represents the encoding in the pattern |00pppppp| that means * that the entry is a string of length &lt;pppppp&gt;, so 0B means that * an 11 bytes string follows. From the third byte (48) to the last (64) * there are just the ASCII characters for "Hello World". * * ---------------------------------------------------------------------------- * * Copyright (c) 2009-2012, Pieter Noordhuis &lt;pcnoordhuis at gmail dot com&gt; * Copyright (c) 2009-2017, Salvatore Sanfilippo &lt;antirez at gmail dot com&gt; * All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions are met: * * * Redistributions of source code must retain the above copyright notice, * this list of conditions and the following disclaimer. * * Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * Neither the name of Redis nor the names of its contributors may be used * to endorse or promote products derived from this software without * specific prior written permission. * * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE * POSSIBILITY OF SUCH DAMAGE. */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdint.h&gt;#include &lt;limits.h&gt;#include "zmalloc.h"#include "util.h"#include "ziplist.h"#include "endianconv.h"#include "redisassert.h"#define ZIP_END 255 /* Special "end of ziplist" entry. *///结尾标记#define ZIP_BIG_PREVLEN 254 /* Max number of bytes of the previous entry, for the "prevlen" field prefixing each entry, to be represented with just a single byte. Otherwise it is represented as FF AA BB CC DD, where AA BB CC DD are a 4 bytes unsigned integer representing the previous entry len. *///prevlen大于254时5个字节小于等于时分配一个字节/* Different encoding/length possibilities *///所有不同的编码#define ZIP_STR_MASK 0xc0#define ZIP_INT_MASK 0x30#define ZIP_STR_06B (0 &lt;&lt; 6)#define ZIP_STR_14B (1 &lt;&lt; 6)#define ZIP_STR_32B (2 &lt;&lt; 6)#define ZIP_INT_16B (0xc0 | 0&lt;&lt;4)#define ZIP_INT_32B (0xc0 | 1&lt;&lt;4)#define ZIP_INT_64B (0xc0 | 2&lt;&lt;4)#define ZIP_INT_24B (0xc0 | 3&lt;&lt;4)#define ZIP_INT_8B 0xfe/* 4 bit integer immediate encoding |1111xxxx| with xxxx between * 0001 and 1101. */#define ZIP_INT_IMM_MASK 0x0f /* Mask to extract the 4 bits value. To add one is needed to reconstruct the value. */#define ZIP_INT_IMM_MIN 0xf1 /* 11110001 */#define ZIP_INT_IMM_MAX 0xfd /* 11111101 */#define INT24_MAX 0x7fffff#define INT24_MIN (-INT24_MAX - 1)/* Macro to determine if the entry is a string. String entries never start * with "11" as most significant bits of the first byte. */#define ZIP_IS_STR(enc) (((enc) &amp; ZIP_STR_MASK) &lt; ZIP_STR_MASK)//是否是字符串/* Utility macros.*//* Return total bytes a ziplist is composed of. */#define ZIPLIST_BYTES(zl) (*((uint32_t*)(zl)))//ziplist分配空间大小/* Return the offset of the last item inside the ziplist. */#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t))))//返回最后一个实习的偏移量/* Return the length of a ziplist, or UINT16_MAX if the length cannot be * determined without scanning the whole ziplist. */#define ZIPLIST_LENGTH(zl) (*((uint16_t*)((zl)+sizeof(uint32_t)*2)))//返回实体个数/* The size of a ziplist header: two 32 bit integers for the total * bytes count and last item offset. One 16 bit integer for the number * of items field. */#define ZIPLIST_HEADER_SIZE (sizeof(uint32_t)*2+sizeof(uint16_t))//ziplist header的空间大小/* Size of the "end of ziplist" entry. Just one byte. */#define ZIPLIST_END_SIZE (sizeof(uint8_t))//结尾标记空间大小/* Return the pointer to the first entry of a ziplist. */#define ZIPLIST_ENTRY_HEAD(zl) ((zl)+ZIPLIST_HEADER_SIZE)//返回第一个实体地址/* Return the pointer to the last entry of a ziplist, using the * last entry offset inside the ziplist header. */#define ZIPLIST_ENTRY_TAIL(zl) ((zl)+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl)))//返回最后一个实体的地址/* Return the pointer to the last byte of a ziplist, which is, the * end of ziplist FF entry. */#define ZIPLIST_ENTRY_END(zl) ((zl)+intrev32ifbe(ZIPLIST_BYTES(zl))-1)//返回结尾标记的首地址/* Increment the number of items field in the ziplist header. Note that this * macro should never overflow the unsigned 16 bit integer, since entires are * always pushed one at a time. When UINT16_MAX is reached we want the count * to stay there to signal that a full scan is needed to get the number of * items inside the ziplist. */ //增加ziplist的实体数目#define ZIPLIST_INCR_LENGTH(zl,incr) &#123; \ if (ZIPLIST_LENGTH(zl) &lt; UINT16_MAX) \ ZIPLIST_LENGTH(zl) = intrev16ifbe(intrev16ifbe(ZIPLIST_LENGTH(zl))+incr); \&#125;/* We use this function to receive information about a ziplist entry. * Note that this is not how the data is actually encoded, is just what we * get filled by a function in order to operate more easily. *///ziplist中记录实习的结构体，不代表实际的存储结构typedef struct zlentry &#123; unsigned int prevrawlensize; /* Bytes used to encode the previos entry len*/ unsigned int prevrawlen; /* Previous entry len. */ unsigned int lensize; /* Bytes used to encode this entry type/len. For example strings have a 1, 2 or 5 bytes header. Integers always use a single byte.*/ unsigned int len; /* Bytes used to represent the actual entry. For strings this is just the string length while for integers it is 1, 2, 3, 4, 8 or 0 (for 4 bit immediate) depending on the number range. */ unsigned int headersize; /* prevrawlensize + lensize. 前一个实体字type节数加上当前实体type字节数*/ unsigned char encoding; /* Set to ZIP_STR_* or ZIP_INT_* depending on //编码 the entry encoding. However for 4 bits immediate integers this can assume a range of values and must be range-checked. */ unsigned char *p; /* Pointer to the very start of the entry, that is, this points to prev-entry-len field. */&#125; zlentry;//结构体置0#define ZIPLIST_ENTRY_ZERO(zle) &#123; \ (zle)-&gt;prevrawlensize = (zle)-&gt;prevrawlen = 0; \ (zle)-&gt;lensize = (zle)-&gt;len = (zle)-&gt;headersize = 0; \ (zle)-&gt;encoding = 0; \ (zle)-&gt;p = NULL; \&#125;/* Extract the encoding from the byte pointed by 'ptr' and set it into * 'encoding' field of the zlentry structure. *///设置实体的encoding#define ZIP_ENTRY_ENCODING(ptr, encoding) do &#123; \ (encoding) = (ptr[0]); \ if ((encoding) &lt; ZIP_STR_MASK) (encoding) &amp;= ZIP_STR_MASK; \&#125; while(0)/* Return bytes needed to store integer encoded by 'encoding'. *///返回存储整数的字节数unsigned int zipIntSize(unsigned char encoding) &#123; switch(encoding) &#123; case ZIP_INT_8B: return 1; case ZIP_INT_16B: return 2; case ZIP_INT_24B: return 3; case ZIP_INT_32B: return 4; case ZIP_INT_64B: return 8; &#125; if (encoding &gt;= ZIP_INT_IMM_MIN &amp;&amp; encoding &lt;= ZIP_INT_IMM_MAX) return 0; /* 4 bit immediate */ panic("Invalid integer encoding 0x%02X", encoding); return 0;&#125;/* Write the encoidng header of the entry in 'p'. If p is NULL it just returns * the amount of bytes required to encode such a length. Arguments: * * 'encoding' is the encoding we are using for the entry. It could be * ZIP_INT_* or ZIP_STR_* or between ZIP_INT_IMM_MIN and ZIP_INT_IMM_MAX * for single-byte small immediate integers. * * 'rawlen' is only used for ZIP_STR_* encodings and is the length of the * srting that this entry represents. * * The function returns the number of bytes used by the encoding/length * header stored in 'p'. */ //根据encoding和rawlen 输出header到p 返回header字节数unsigned int zipStoreEntryEncoding(unsigned char *p, unsigned char encoding, unsigned int rawlen) &#123; unsigned char len = 1, buf[5]; if (ZIP_IS_STR(encoding)) &#123;//是否是字符串 /* Although encoding is given it may not be set for strings, * so we determine it here using the raw length. */ if (rawlen &lt;= 0x3f) &#123; if (!p) return len; buf[0] = ZIP_STR_06B | rawlen; &#125; else if (rawlen &lt;= 0x3fff) &#123; len += 1; if (!p) return len; buf[0] = ZIP_STR_14B | ((rawlen &gt;&gt; 8) &amp; 0x3f); buf[1] = rawlen &amp; 0xff; &#125; else &#123; len += 4; if (!p) return len; buf[0] = ZIP_STR_32B; buf[1] = (rawlen &gt;&gt; 24) &amp; 0xff; buf[2] = (rawlen &gt;&gt; 16) &amp; 0xff; buf[3] = (rawlen &gt;&gt; 8) &amp; 0xff; buf[4] = rawlen &amp; 0xff; &#125; &#125; else &#123; /* Implies integer encoding, so length is always 1. */ if (!p) return len; buf[0] = encoding; &#125; /* Store this length at p. */ memcpy(p,buf,len); return len;&#125;/* Decode the entry encoding type and data length (string length for strings, * number of bytes used for the integer for integer entries) encoded in 'ptr'. * The 'encoding' variable will hold the entry encoding, the 'lensize' * variable will hold the number of bytes required to encode the entry * length, and the 'len' variable will hold the entry length. */ //解码过程#define ZIP_DECODE_LENGTH(ptr, encoding, lensize, len) do &#123; \ ZIP_ENTRY_ENCODING((ptr), (encoding)); \ if ((encoding) &lt; ZIP_STR_MASK) &#123; \ if ((encoding) == ZIP_STR_06B) &#123; \ (lensize) = 1; \ (len) = (ptr)[0] &amp; 0x3f; \ &#125; else if ((encoding) == ZIP_STR_14B) &#123; \ (lensize) = 2; \ (len) = (((ptr)[0] &amp; 0x3f) &lt;&lt; 8) | (ptr)[1]; \ &#125; else if ((encoding) == ZIP_STR_32B) &#123; \ (lensize) = 5; \ (len) = ((ptr)[1] &lt;&lt; 24) | \ ((ptr)[2] &lt;&lt; 16) | \ ((ptr)[3] &lt;&lt; 8) | \ ((ptr)[4]); \ &#125; else &#123; \ panic("Invalid string encoding 0x%02X", (encoding)); \ &#125; \ &#125; else &#123; \ (lensize) = 1; \ (len) = zipIntSize(encoding); \ &#125; \&#125; while(0);/* Encode the length of the previous entry and write it to "p". This only * uses the larger encoding (required in __ziplistCascadeUpdate). */ //长度超过254的情况int zipStorePrevEntryLengthLarge(unsigned char *p, unsigned int len) &#123; if (p != NULL) &#123; p[0] = ZIP_BIG_PREVLEN; memcpy(p+1,&amp;len,sizeof(len)); memrev32ifbe(p+1); &#125; return 1+sizeof(len);&#125;/* Encode the length of the previous entry and write it to "p". Return the * number of bytes needed to encode this length if "p" is NULL. */ //对于两种情况都适用unsigned int zipStorePrevEntryLength(unsigned char *p, unsigned int len) &#123; if (p == NULL) &#123; return (len &lt; ZIP_BIG_PREVLEN) ? 1 : sizeof(len)+1; &#125; else &#123; if (len &lt; ZIP_BIG_PREVLEN) &#123; p[0] = len; return 1; &#125; else &#123; return zipStorePrevEntryLengthLarge(p,len); &#125; &#125;&#125;/* Return the number of bytes used to encode the length of the previous * entry. The length is returned by setting the var 'prevlensize'. */ //返回前一个实体长度的编码存储字节数#define ZIP_DECODE_PREVLENSIZE(ptr, prevlensize) do &#123; \ if ((ptr)[0] &lt; ZIP_BIG_PREVLEN) &#123; \ (prevlensize) = 1; \ &#125; else &#123; \ (prevlensize) = 5; \ &#125; \&#125; while(0);/* Return the length of the previous element, and the number of bytes that * are used in order to encode the previous element length. * 'ptr' must point to the prevlen prefix of an entry (that encodes the * length of the previos entry in order to navigate the elements backward). * The length of the previous entry is stored in 'prevlen', the number of * bytes needed to encode the previous entry length are stored in * 'prevlensize'. */ //解码实体长度存储字节数，以及真实长度#define ZIP_DECODE_PREVLEN(ptr, prevlensize, prevlen) do &#123; \ ZIP_DECODE_PREVLENSIZE(ptr, prevlensize); \ if ((prevlensize) == 1) &#123; \ (prevlen) = (ptr)[0]; \ &#125; else if ((prevlensize) == 5) &#123; \ assert(sizeof((prevlensize)) == 4); \ memcpy(&amp;(prevlen), ((char*)(ptr)) + 1, 4); \ memrev32ifbe(&amp;prevlen); \ &#125; \&#125; while(0);/* Given a pointer 'p' to the prevlen info that prefixes an entry, this * function returns the difference in number of bytes needed to encode * the prevlen if the previous entry changes of size. * * So if A is the number of bytes used right now to encode the 'prevlen' * field. * * And B is the number of bytes that are needed in order to encode the * 'prevlen' if the previous element will be updated to one of size 'len'. * * Then the function returns B - A * * So the function returns a positive number if more space is needed, * a negative number if less space is needed, or zero if the same space * is needed. */ //计算新的长度需要的空间与之前的差值，之前的信息存储在p*中 //返回正数表示需要分配空间，负数空间变小int zipPrevLenByteDiff(unsigned char *p, unsigned int len) &#123; unsigned int prevlensize; ZIP_DECODE_PREVLENSIZE(p, prevlensize);//解码之前需要的字节数 return zipStorePrevEntryLength(NULL, len) - prevlensize;&#125;/* Return the total number of bytes used by the entry pointed to by 'p'. *///根据p*返回当前实体需要的字节数unsigned int zipRawEntryLength(unsigned char *p) &#123; unsigned int prevlensize, encoding, lensize, len; ZIP_DECODE_PREVLENSIZE(p, prevlensize);//计算记录前一个实体长度需要的字节数 ZIP_DECODE_LENGTH(p + prevlensize, encoding, lensize, len);//计算当前记录实体编码字节数以及data长度 return prevlensize + lensize + len;//求和&#125;/* Check if string pointed to by 'entry' can be encoded as an integer. * Stores the integer value in 'v' and its encoding in 'encoding'. */ //检查实体是否可以转化为整数，可以的话值存在v中，encoding中记录编码int zipTryEncoding(unsigned char *entry, unsigned int entrylen, long long *v, unsigned char *encoding) &#123; long long value; if (entrylen &gt;= 32 || entrylen == 0) return 0; if (string2ll((char*)entry,entrylen,&amp;value)) &#123;//字符串转化为longlong /* Great, the string can be encoded. Check what's the smallest * of our encoding types that can hold this value. */ //检查编码类型 if (value &gt;= 0 &amp;&amp; value &lt;= 12) &#123; *encoding = ZIP_INT_IMM_MIN+value; &#125; else if (value &gt;= INT8_MIN &amp;&amp; value &lt;= INT8_MAX) &#123; *encoding = ZIP_INT_8B; &#125; else if (value &gt;= INT16_MIN &amp;&amp; value &lt;= INT16_MAX) &#123; *encoding = ZIP_INT_16B; &#125; else if (value &gt;= INT24_MIN &amp;&amp; value &lt;= INT24_MAX) &#123; *encoding = ZIP_INT_24B; &#125; else if (value &gt;= INT32_MIN &amp;&amp; value &lt;= INT32_MAX) &#123; *encoding = ZIP_INT_32B; &#125; else &#123; *encoding = ZIP_INT_64B; &#125; *v = value; return 1; &#125; return 0;&#125;/* Store integer 'value' at 'p', encoded as 'encoding' *///按照encoding将整数value存到p中void zipSaveInteger(unsigned char *p, int64_t value, unsigned char encoding) &#123; int16_t i16; int32_t i32; int64_t i64; if (encoding == ZIP_INT_8B) &#123; ((int8_t*)p)[0] = (int8_t)value; &#125; else if (encoding == ZIP_INT_16B) &#123; i16 = value; memcpy(p,&amp;i16,sizeof(i16)); memrev16ifbe(p); &#125; else if (encoding == ZIP_INT_24B) &#123; //没有24位整数，左移8位用32int存 i32 = value&lt;&lt;8; memrev32ifbe(&amp;i32); memcpy(p,((uint8_t*)&amp;i32)+1,sizeof(i32)-sizeof(uint8_t)); &#125; else if (encoding == ZIP_INT_32B) &#123; i32 = value; memcpy(p,&amp;i32,sizeof(i32)); memrev32ifbe(p); &#125; else if (encoding == ZIP_INT_64B) &#123; i64 = value; memcpy(p,&amp;i64,sizeof(i64)); memrev64ifbe(p); &#125; else if (encoding &gt;= ZIP_INT_IMM_MIN &amp;&amp; encoding &lt;= ZIP_INT_IMM_MAX) &#123; /* Nothing to do, the value is stored in the encoding itself. */ &#125; else &#123; assert(NULL); &#125;&#125;/* Read integer encoded as 'encoding' from 'p' *///根据encoding读取p*整数int64_t zipLoadInteger(unsigned char *p, unsigned char encoding) &#123; int16_t i16; int32_t i32; int64_t i64, ret = 0; if (encoding == ZIP_INT_8B) &#123; ret = ((int8_t*)p)[0]; &#125; else if (encoding == ZIP_INT_16B) &#123; memcpy(&amp;i16,p,sizeof(i16)); memrev16ifbe(&amp;i16); ret = i16; &#125; else if (encoding == ZIP_INT_32B) &#123; memcpy(&amp;i32,p,sizeof(i32)); memrev32ifbe(&amp;i32); ret = i32; &#125; else if (encoding == ZIP_INT_24B) &#123; //24位处理与save相反即可 i32 = 0; memcpy(((uint8_t*)&amp;i32)+1,p,sizeof(i32)-sizeof(uint8_t)); memrev32ifbe(&amp;i32); ret = i32&gt;&gt;8; &#125; else if (encoding == ZIP_INT_64B) &#123; memcpy(&amp;i64,p,sizeof(i64)); memrev64ifbe(&amp;i64); ret = i64; &#125; else if (encoding &gt;= ZIP_INT_IMM_MIN &amp;&amp; encoding &lt;= ZIP_INT_IMM_MAX) &#123; ret = (encoding &amp; ZIP_INT_IMM_MASK)-1; &#125; else &#123; assert(NULL); &#125; return ret;&#125;/* Return a struct with all information about an entry. *///根据p中存储信息，填充一个zlentryvoid zipEntry(unsigned char *p, zlentry *e) &#123; ZIP_DECODE_PREVLEN(p, e-&gt;prevrawlensize, e-&gt;prevrawlen); ZIP_DECODE_LENGTH(p + e-&gt;prevrawlensize, e-&gt;encoding, e-&gt;lensize, e-&gt;len); e-&gt;headersize = e-&gt;prevrawlensize + e-&gt;lensize; e-&gt;p = p;&#125;/* Create a new empty ziplist. *///创建一个新的ziplistunsigned char *ziplistNew(void) &#123; unsigned int bytes = ZIPLIST_HEADER_SIZE+1;//header加上结尾标志 unsigned char *zl = zmalloc(bytes); ZIPLIST_BYTES(zl) = intrev32ifbe(bytes);//ziplist总共分配空间初始化 ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE);//最后一个实体偏移量初始化 ZIPLIST_LENGTH(zl) = 0;//实体个数出书画 zl[bytes-1] = ZIP_END; return zl;&#125;/* Resize the ziplist. */unsigned char *ziplistResize(unsigned char *zl, unsigned int len) &#123; zl = zrealloc(zl,len);//扩展空间 ZIPLIST_BYTES(zl) = intrev32ifbe(len);//重謟iplist分配空间大小 zl[len-1] = ZIP_END;//后移结束标志 return zl;&#125;/* When an entry is inserted, we need to set the prevlen field of the next * entry to equal the length of the inserted entry. It can occur that this * length cannot be encoded in 1 byte and the next entry needs to be grow * a bit larger to hold the 5-byte encoded prevlen. This can be done for free, * because this only happens when an entry is already being inserted (which * causes a realloc and memmove). However, encoding the prevlen may require * that this entry is grown as well. This effect may cascade throughout * the ziplist when there are consecutive entries with a size close to * ZIP_BIG_PREVLEN, so we need to check that the prevlen can be encoded in * every consecutive entry. * * Note that this effect can also happen in reverse, where the bytes required * to encode the prevlen field can shrink. This effect is deliberately ignored, * because it can cause a "flapping" effect where a chain prevlen fields is * first grown and then shrunk again after consecutive inserts. Rather, the * field is allowed to stay larger than necessary, because a large prevlen * field implies the ziplist is holding large entries anyway. * * The pointer "p" points to the first entry that does NOT need to be * updated, i.e. consecutive fields MAY need an update. */ //级联更新实体 //当插入修改一个实体后，发现该实体的mata信息的长度大于后一个实体的prelen时，就要更新后一个实体，然后 //一次向后级联，知道有一个不需要修改停止unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) &#123; //当前ziplist占的字节数 size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize; size_t offset, noffset, extra; unsigned char *np; zlentry cur, next; while (p[0] != ZIP_END) &#123; zipEntry(p, &amp;cur); rawlen = cur.headersize + cur.len;//当前实体所占的字节数 rawlensize = zipStorePrevEntryLength(NULL,rawlen);//当前实体mata信息所占字节数 /* Abort if there is no next entry. */ //判断下一个实体是否为终止标志 if (p[rawlen] == ZIP_END) break; zipEntry(p+rawlen, &amp;next); /* Abort when "prevlen" has not changed. */ if (next.prevrawlen == rawlen) break; //如果下一个实体记录当前实体的长度小于当前实体长度，说明下一个实体需要更多空间存储当前实体长度 if (next.prevrawlensize &lt; rawlensize) &#123; /* The "prevlen" field of "next" needs more bytes to hold * the raw length of "cur". */ offset = p-zl;//当前实体的偏移量 extra = rawlensize-next.prevrawlensize;//需要扩展的空间 zl = ziplistResize(zl,curlen+extra);//调整ziplist的空间大小 p = zl+offset; /* Current pointer and offset for next element. */ np = p+rawlen;//下一个实体的指针 noffset = np-zl;//下一个实体的偏移量 /* Update tail offset when next element is not the tail element. */ if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) &#123;//修改ziplist中tailoffset参数 ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra); &#125; /* Move the tail to the back. */ memmove(np+rawlensize, np+next.prevrawlensize, curlen-noffset-next.prevrawlensize-1); //从下一个实体的prelen信息往后移动 zipStorePrevEntryLength(np,rawlen); //存储最新的prelen信息 /* Advance the cursor */ p += rawlen; curlen += extra; &#125; else &#123; if (next.prevrawlensize &gt; rawlensize) &#123; /* This would result in shrinking, which we want to avoid. * So, set "rawlen" in the available bytes. */ zipStorePrevEntryLengthLarge(p+rawlen,rawlen); &#125; else &#123; zipStorePrevEntryLength(p+rawlen,rawlen); &#125; /* Stop here, as the raw length of "next" has not changed. */ break; &#125; &#125; return zl;&#125;/* Delete "num" entries, starting at "p". Returns pointer to the ziplist. *///删除num个实体，从p指针指向的实体开始，返回指向ziplist 的指针unsigned char *__ziplistDelete(unsigned char *zl, unsigned char *p, unsigned int num) &#123; unsigned int i, totlen, deleted = 0; size_t offset; int nextdiff = 0; zlentry first, tail; zipEntry(p, &amp;first); for (i = 0; p[0] != ZIP_END &amp;&amp; i &lt; num; i++) &#123; p += zipRawEntryLength(p); deleted++; &#125; totlen = p-first.p; /* Bytes taken by the element(s) to delete. */ //总共要删除的字节数 if (totlen &gt; 0) &#123; if (p[0] != ZIP_END) &#123;//如果没有删除到结尾了 /* Storing `prevrawlen` in this entry may increase or decrease the * number of bytes required compare to the current `prevrawlen`. * There always is room to store this, because it was previously * stored by an entry that is now being deleted. */ nextdiff = zipPrevLenByteDiff(p,first.prevrawlen); //计算当前实体prelen的变化量 /* Note that there is always space when p jumps backward: if * the new previous entry is large, one of the deleted elements * had a 5 bytes prevlen header, so there is for sure at least * 5 bytes free and we need just 4. */ p -= nextdiff; //调整prelen的空间 zipStorePrevEntryLength(p,first.prevrawlen); //存储最新的prelen信息 /* Update offset for tail */ ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))-totlen); //调整tailoffset信息 /* When the tail contains more than one entry, we need to take * "nextdiff" in account as well. Otherwise, a change in the * size of prevlen doesn't have an effect on the *tail* offset. */ zipEntry(p, &amp;tail); if (p[tail.headersize+tail.len] != ZIP_END) &#123;//判断是否是最后一个实体 ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); &#125; /* Move tail to the front of the ziplist */ memmove(first.p,p, intrev32ifbe(ZIPLIST_BYTES(zl))-(p-zl)-1);//往前移动后面实体 &#125; else &#123; /* The entire tail was deleted. No need to move memory. */ ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe((first.p-zl)-first.prevrawlen); &#125; /* Resize and update length */ offset = first.p-zl; zl = ziplistResize(zl, intrev32ifbe(ZIPLIST_BYTES(zl))-totlen+nextdiff); ZIPLIST_INCR_LENGTH(zl,-deleted); p = zl+offset; /* When nextdiff != 0, the raw length of the next entry has changed, so * we need to cascade the update throughout the ziplist */ if (nextdiff != 0)//长度调整了，所以调用级联更新 zl = __ziplistCascadeUpdate(zl,p); &#125; return zl;&#125;/* Insert item at "p". *///在p出插入实体unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) &#123; size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; /* initialized to avoid warning. Using a value that is easy to see if for some reason we use it uninitialized. */ zlentry tail; /* Find out prevlen for the entry that is inserted. */ if (p[0] != ZIP_END) &#123; ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); &#125; else &#123; unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) &#123; prevlen = zipRawEntryLength(ptail); &#125; &#125; /* See if the entry can be encoded */ if (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) &#123; /* 'encoding' is set to the appropriate integer encoding */ reqlen = zipIntSize(encoding); &#125; else &#123; /* 'encoding' is untouched, however zipStoreEntryEncoding will use the * string length to figure out how to encode it. */ reqlen = slen; &#125; /* We need space for both the length of the previous entry and * the length of the payload. */ reqlen += zipStorePrevEntryLength(NULL,prevlen); reqlen += zipStoreEntryEncoding(NULL,encoding,slen); /* When the insert position is not equal to the tail, we need to * make sure that the next entry can hold this entry's length in * its prevlen field. */ int forcelarge = 0; nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; if (nextdiff == -4 &amp;&amp; reqlen &lt; 4) &#123; nextdiff = 0; forcelarge = 1; &#125; /* Store offset because a realloc may change the address of zl. */ offset = p-zl; zl = ziplistResize(zl,curlen+reqlen+nextdiff); p = zl+offset; /* Apply memory move when necessary and update tail offset. */ if (p[0] != ZIP_END) &#123; /* Subtract one because of the ZIP_END bytes */ memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff); /* Encode this entry's raw length in the next entry. */ if (forcelarge) zipStorePrevEntryLengthLarge(p+reqlen,reqlen); else zipStorePrevEntryLength(p+reqlen,reqlen); /* Update offset for tail */ ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen); /* When the tail contains more than one entry, we need to take * "nextdiff" in account as well. Otherwise, a change in the * size of prevlen doesn't have an effect on the *tail* offset. */ zipEntry(p+reqlen, &amp;tail); if (p[reqlen+tail.headersize+tail.len] != ZIP_END) &#123; ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff); &#125; &#125; else &#123; /* This element will be the new tail. */ ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl); &#125; /* When nextdiff != 0, the raw length of the next entry has changed, so * we need to cascade the update throughout the ziplist */ if (nextdiff != 0) &#123; offset = p-zl; zl = __ziplistCascadeUpdate(zl,p+reqlen); p = zl+offset; &#125; /* Write the entry */ p += zipStorePrevEntryLength(p,prevlen); p += zipStoreEntryEncoding(p,encoding,slen); if (ZIP_IS_STR(encoding)) &#123; memcpy(p,s,slen); &#125; else &#123; zipSaveInteger(p,value,encoding); &#125; ZIPLIST_INCR_LENGTH(zl,1); return zl;&#125;/* Merge ziplists 'first' and 'second' by appending 'second' to 'first'. * * NOTE: The larger ziplist is reallocated to contain the new merged ziplist. * Either 'first' or 'second' can be used for the result. The parameter not * used will be free'd and set to NULL. * * After calling this function, the input parameters are no longer valid since * they are changed and free'd in-place. * * The result ziplist is the contents of 'first' followed by 'second'. * * On failure: returns NULL if the merge is impossible. * On success: returns the merged ziplist (which is expanded version of either * 'first' or 'second', also frees the other unused input ziplist, and sets the * input ziplist argument equal to newly reallocated ziplist return value. */ //合并ziplistunsigned char *ziplistMerge(unsigned char **first, unsigned char **second) &#123; /* If any params are null, we can't merge, so NULL. */ if (first == NULL || *first == NULL || second == NULL || *second == NULL) return NULL; /* Can't merge same list into itself. */ if (*first == *second)//不能合并自己 return NULL; size_t first_bytes = intrev32ifbe(ZIPLIST_BYTES(*first)); size_t first_len = intrev16ifbe(ZIPLIST_LENGTH(*first)); size_t second_bytes = intrev32ifbe(ZIPLIST_BYTES(*second)); size_t second_len = intrev16ifbe(ZIPLIST_LENGTH(*second)); int append; unsigned char *source, *target; size_t target_bytes, source_bytes; /* Pick the largest ziplist so we can resize easily in-place. * We must also track if we are now appending or prepending to * the target ziplist. */ //用比较大的ziplist作为目标list，可以减少空间分配的大小，提高效率。 if (first_len &gt;= second_len) &#123; /* retain first, append second to first. */ target = *first; target_bytes = first_bytes; source = *second; source_bytes = second_bytes; append = 1; &#125; else &#123; /* else, retain second, prepend first to second. */ target = *second; target_bytes = second_bytes; source = *first; source_bytes = first_bytes; append = 0; &#125; //重置ziplist空间大小以及实体个数 /* Calculate final bytes (subtract one pair of metadata) */ size_t zlbytes = first_bytes + second_bytes - ZIPLIST_HEADER_SIZE - ZIPLIST_END_SIZE;//去重复的空间计算 size_t zllength = first_len + second_len; /* Combined zl length should be limited within UINT16_MAX */ zllength = zllength &lt; UINT16_MAX ? zllength : UINT16_MAX; //规范长度的最大值 /* Save offset positions before we start ripping memory apart. */ size_t first_offset = intrev32ifbe(ZIPLIST_TAIL_OFFSET(*first)); size_t second_offset = intrev32ifbe(ZIPLIST_TAIL_OFFSET(*second)); //两个ziplist的偏移量 /* Extend target to new zlbytes then append or prepend source. */ target = zrealloc(target, zlbytes); if (append) &#123; //合并ziplist 但是没有更新之间的prelen /* append == appending to target */ /* Copy source after target (copying over original [END]): * [TARGET - END, SOURCE - HEADER] */ memcpy(target + target_bytes - ZIPLIST_END_SIZE, source + ZIPLIST_HEADER_SIZE, source_bytes - ZIPLIST_HEADER_SIZE); &#125; else &#123; /* !append == prepending to target */ /* Move target *contents* exactly size of (source - [END]), * then copy source into vacataed space (source - [END]): * [SOURCE - END, TARGET - HEADER] */ memmove(target + source_bytes - ZIPLIST_END_SIZE, target + ZIPLIST_HEADER_SIZE, target_bytes - ZIPLIST_HEADER_SIZE); memcpy(target, source, source_bytes - ZIPLIST_END_SIZE); &#125; /* Update header metadata. */ //更新头信息 ZIPLIST_BYTES(target) = intrev32ifbe(zlbytes); ZIPLIST_LENGTH(target) = intrev16ifbe(zllength); /* New tail offset is: * + N bytes of first ziplist * - 1 byte for [END] of first ziplist * + M bytes for the offset of the original tail of the second ziplist * - J bytes for HEADER because second_offset keeps no header. */ ZIPLIST_TAIL_OFFSET(target) = intrev32ifbe( (first_bytes - ZIPLIST_END_SIZE) + (second_offset - ZIPLIST_HEADER_SIZE)); /* __ziplistCascadeUpdate just fixes the prev length values until it finds a * correct prev length value (then it assumes the rest of the list is okay). * We tell CascadeUpdate to start at the first ziplist's tail element to fix * the merge seam. */ target = __ziplistCascadeUpdate(target, target+first_offset);//从第一个ziplist的尾部开始级联更新 /* Now free and NULL out what we didn't realloc */ //释放多余的空间，意味着合并后之前的ziplist不存在了 if (append) &#123; zfree(*second); *second = NULL; *first = target; &#125; else &#123; zfree(*first); *first = NULL; *second = target; &#125; return target;&#125;unsigned char *ziplistPush(unsigned char *zl, unsigned char *s, unsigned int slen, int where) &#123; unsigned char *p; p = (where == ZIPLIST_HEAD) ? ZIPLIST_ENTRY_HEAD(zl) : ZIPLIST_ENTRY_END(zl);//从头部还是尾部添加 return __ziplistInsert(zl,p,s,slen);//添加实体&#125;/* Returns an offset to use for iterating with ziplistNext. When the given * index is negative, the list is traversed back to front. When the list * doesn't contain an element at the provided index, NULL is returned. */ //返回一个index实体的指针，如果index为负数，从尾部向前检索，如果没有提供的index，返回nullunsigned char *ziplistIndex(unsigned char *zl, int index) &#123; unsigned char *p; unsigned int prevlensize, prevlen = 0; if (index &lt; 0) &#123; index = (-index)-1; p = ZIPLIST_ENTRY_TAIL(zl); if (p[0] != ZIP_END) &#123; ZIP_DECODE_PREVLEN(p, prevlensize, prevlen);//计算当前实体的长度 while (prevlen &gt; 0 &amp;&amp; index--) &#123; p -= prevlen; ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); &#125; &#125; &#125; else &#123; p = ZIPLIST_ENTRY_HEAD(zl); while (p[0] != ZIP_END &amp;&amp; index--) &#123; p += zipRawEntryLength(p);//后移地址 加上当前实体的长度 &#125; &#125; return (p[0] == ZIP_END || index &gt; 0) ? NULL : p;&#125;/* Return pointer to next entry in ziplist. * * zl is the pointer to the ziplist * p is the pointer to the current element * * The element after 'p' is returned, otherwise NULL if we are at the end. */ //返回p指向实体的下一个实体的指针unsigned char *ziplistNext(unsigned char *zl, unsigned char *p) &#123; ((void) zl); /* "p" could be equal to ZIP_END, caused by ziplistDelete, * and we should return NULL. Otherwise, we should return NULL * when the *next* element is ZIP_END (there is no next entry). */ if (p[0] == ZIP_END) &#123; return NULL; &#125; //如果当前实体或者下一个实体的结尾标记则返回null p += zipRawEntryLength(p); if (p[0] == ZIP_END) &#123; return NULL; &#125; return p;&#125;/* Return pointer to previous entry in ziplist. *///返回p指向实体的上一个实体的指针unsigned char *ziplistPrev(unsigned char *zl, unsigned char *p) &#123; unsigned int prevlensize, prevlen = 0; /* Iterating backwards from ZIP_END should return the tail. When "p" is * equal to the first element of the list, we're already at the head, * and should return NULL. */ if (p[0] == ZIP_END) &#123;//如果p为结尾指针 p = ZIPLIST_ENTRY_TAIL(zl);//指向最后一个实体的指针 return (p[0] == ZIP_END) ? NULL : p; &#125; else if (p == ZIPLIST_ENTRY_HEAD(zl)) &#123;//如果p为头指针 return NULL; &#125; else &#123; ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); assert(prevlen &gt; 0); return p-prevlen; &#125;&#125;/* Get entry pointed to by 'p' and store in either '*sstr' or 'sval' depending * on the encoding of the entry. '*sstr' is always set to NULL to be able * to find out whether the string pointer or the integer value was set. * Return 0 if 'p' points to the end of the ziplist, 1 otherwise. */ //获取p指向的实体的值不管是string还是intunsigned int ziplistGet(unsigned char *p, unsigned char **sstr, unsigned int *slen, long long *sval) &#123; zlentry entry; if (p == NULL || p[0] == ZIP_END) return 0; if (sstr) *sstr = NULL; zipEntry(p, &amp;entry); if (ZIP_IS_STR(entry.encoding)) &#123; if (sstr) &#123; *slen = entry.len; *sstr = p+entry.headersize; &#125; &#125; else &#123; if (sval) &#123; *sval = zipLoadInteger(p+entry.headersize,entry.encoding); &#125; &#125; return 1;&#125;/* Insert an entry at "p". */unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) &#123; return __ziplistInsert(zl,p,s,slen);&#125;/* Delete a single entry from the ziplist, pointed to by *p. * Also update *p in place, to be able to iterate over the * ziplist, while deleting entries. */unsigned char *ziplistDelete(unsigned char *zl, unsigned char **p) &#123; size_t offset = *p-zl; zl = __ziplistDelete(zl,*p,1); /* Store pointer to current element in p, because ziplistDelete will * do a realloc which might result in a different "zl"-pointer. * When the delete direction is back to front, we might delete the last * entry and end up with "p" pointing to ZIP_END, so check this. */ *p = zl+offset; return zl;&#125;/* Delete a range of entries from the ziplist. *///删除一个范围内的实体unsigned char *ziplistDeleteRange(unsigned char *zl, int index, unsigned int num) &#123; unsigned char *p = ziplistIndex(zl,index); return (p == NULL) ? zl : __ziplistDelete(zl,p,num);&#125;/* Compare entry pointer to by 'p' with 'sstr' of length 'slen'. *//* Return 1 if equal. */unsigned int ziplistCompare(unsigned char *p, unsigned char *sstr, unsigned int slen) &#123; zlentry entry; unsigned char sencoding; long long zval, sval; if (p[0] == ZIP_END) return 0; zipEntry(p, &amp;entry); if (ZIP_IS_STR(entry.encoding)) &#123;//如果是字符串 /* Raw compare */ if (entry.len == slen) &#123;//长度相等 比较字符串 return memcmp(p+entry.headersize,sstr,slen) == 0; &#125; else &#123; return 0; &#125; &#125; else &#123; /* Try to compare encoded values. Don't compare encoding because * different implementations may encoded integers differently. */ //比较整数 不需要比较编码方式 if (zipTryEncoding(sstr,slen,&amp;sval,&amp;sencoding)) &#123; zval = zipLoadInteger(p+entry.headersize,entry.encoding); return zval == sval; &#125; &#125; return 0;&#125;/* Find pointer to the entry equal to the specified entry. Skip 'skip' entries * between every comparison. Returns NULL when the field could not be found. */ //每个skip的实体对比一次unsigned char *ziplistFind(unsigned char *p, unsigned char *vstr, unsigned int vlen, unsigned int skip) &#123; int skipcnt = 0; unsigned char vencoding = 0; long long vll = 0; while (p[0] != ZIP_END) &#123; unsigned int prevlensize, encoding, lensize, len; unsigned char *q; ZIP_DECODE_PREVLENSIZE(p, prevlensize); ZIP_DECODE_LENGTH(p + prevlensize, encoding, lensize, len); q = p + prevlensize + lensize; if (skipcnt == 0) &#123; /* Compare current entry with specified entry */ if (ZIP_IS_STR(encoding)) &#123; if (len == vlen &amp;&amp; memcmp(q, vstr, vlen) == 0) &#123; return p; &#125; &#125; else &#123; /* Find out if the searched field can be encoded. Note that * we do it only the first time, once done vencoding is set * to non-zero and vll is set to the integer value. */ if (vencoding == 0) &#123; if (!zipTryEncoding(vstr, vlen, &amp;vll, &amp;vencoding)) &#123; /* If the entry can't be encoded we set it to * UCHAR_MAX so that we don't retry again the next * time. */ vencoding = UCHAR_MAX; &#125; /* Must be non-zero by now */ assert(vencoding); &#125; /* Compare current entry with specified entry, do it only * if vencoding != UCHAR_MAX because if there is no encoding * possible for the field it can't be a valid integer. */ if (vencoding != UCHAR_MAX) &#123; long long ll = zipLoadInteger(q, encoding); if (ll == vll) &#123; return p; &#125; &#125; &#125; /* Reset skip count */ skipcnt = skip; &#125; else &#123; /* Skip entry */ skipcnt--; &#125; /* Move to next entry */ p = q + len; &#125; return NULL;&#125;/* Return length of ziplist. */unsigned int ziplistLen(unsigned char *zl) &#123; unsigned int len = 0; if (intrev16ifbe(ZIPLIST_LENGTH(zl)) &lt; UINT16_MAX) &#123; len = intrev16ifbe(ZIPLIST_LENGTH(zl));//小于UINT16_MAX 直接取值 &#125; else &#123; unsigned char *p = zl+ZIPLIST_HEADER_SIZE; while (*p != ZIP_END) &#123; p += zipRawEntryLength(p); len++; &#125;//获取真正的len /* Re-store length if small enough */ if (len &lt; UINT16_MAX) ZIPLIST_LENGTH(zl) = intrev16ifbe(len);//重置len &#125; return len;&#125;/* Return ziplist blob size in bytes. */size_t ziplistBlobLen(unsigned char *zl) &#123; return intrev32ifbe(ZIPLIST_BYTES(zl));&#125;//输出ziplist的所有内容void ziplistRepr(unsigned char *zl) &#123; unsigned char *p; int index = 0; zlentry entry; printf( "&#123;total bytes %d&#125; " "&#123;num entries %u&#125;\n" "&#123;tail offset %u&#125;\n", intrev32ifbe(ZIPLIST_BYTES(zl)), intrev16ifbe(ZIPLIST_LENGTH(zl)), intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))); p = ZIPLIST_ENTRY_HEAD(zl); while(*p != ZIP_END) &#123; zipEntry(p, &amp;entry); printf( "&#123;\n" "\taddr 0x%08lx,\n" "\tindex %2d,\n" "\toffset %5ld,\n" "\thdr+entry len: %5u,\n" "\thdr len%2u,\n" "\tprevrawlen: %5u,\n" "\tprevrawlensize: %2u,\n" "\tpayload %5u\n", (long unsigned)p, index, (unsigned long) (p-zl), entry.headersize+entry.len, entry.headersize, entry.prevrawlen, entry.prevrawlensize, entry.len); printf("\tbytes: "); for (unsigned int i = 0; i &lt; entry.headersize+entry.len; i++) &#123; printf("%02x|",p[i]); &#125; printf("\n"); p += entry.headersize; if (ZIP_IS_STR(entry.encoding)) &#123; printf("\t[str]"); if (entry.len &gt; 40) &#123; if (fwrite(p,40,1,stdout) == 0) perror("fwrite"); printf("..."); &#125; else &#123; if (entry.len &amp;&amp; fwrite(p,entry.len,1,stdout) == 0) perror("fwrite"); &#125; &#125; else &#123; printf("\t[int]%lld", (long long) zipLoadInteger(p,entry.encoding)); &#125; printf("\n&#125;\n"); p += entry.len; index++; &#125; printf("&#123;end&#125;\n\n");&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(3)——dict篇]]></title>
    <url>%2F2017%2F04%2F20%2Fredis%E6%BA%90%E7%A0%81-3-%E2%80%94%E2%80%94dict%E7%AF%87%2F</url>
    <content type="text"><![CDATA[dict字典，用来存储键值对，是redis中数据库中存储数据以及键值对表数据的底层实现。在dict中使用siphash.c来实现hash函数计算index。dict中包含两个dictht即字典表，这是为了redis中渐进重构rehash准备的，为了解决键冲突，dictEntry中包含一个next指针，dictht中table数组相当于一个一个的桶，当过多的键值对存储到dict中后，必然会导致字典结构失调，查询效率低等问题，所以要扩容增加size，这时候就启动rehash，但是redis不会等待rehash完成，在做下面的操作，所以提出渐进rehash，即每次操作时单步rehash一下，这样就避免了等待，因此需要两个dictht，一个副本，当完成rehash之后把新的ht移动到ht[0]，旧的释放空间后reset，在rehash期间，所有的改变dict状态的操作都在新表上进行。在dict中还提供了一个dicttype，里面用来存储键值的释放，复制，比较等操作的函数指针。dict提供了字典迭代器，有安全不安全迭代器，不安全迭代器通过fingerprint来判断是否有不安全操作。dict.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189/* Hash Tables Implementation. * * This file implements in-memory hash tables with insert/del/replace/find/ * get-random-element operations. Hash tables will auto-resize if needed * tables of power of two in size are used, collisions are handled by * chaining. See the source code for more information... :) * * Copyright (c) 2006-2012, Salvatore Sanfilippo &lt;antirez at gmail dot com&gt; * All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions are met: * * * Redistributions of source code must retain the above copyright notice, * this list of conditions and the following disclaimer. * * Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * Neither the name of Redis nor the names of its contributors may be used * to endorse or promote products derived from this software without * specific prior written permission. * * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE * POSSIBILITY OF SUCH DAMAGE. */#include &lt;stdint.h&gt;#ifndef __DICT_H#define __DICT_H#define DICT_OK 0#define DICT_ERR 1/* Unused arguments generate annoying warnings... */#define DICT_NOTUSED(V) ((void) V)typedef struct dictEntry &#123; void *key;//键值 union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v;//value可以是多种类型 struct dictEntry *next;//解决hash冲突而设置的指向下一个键值对的指针&#125; dictEntry;typedef struct dictType &#123;//字典类型结构，存储这个字典一些自定义的函数指针 uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType;/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123;//hash列表结构用来存储所有的键值对 dictEntry **table;//dictEntry指针数组 unsigned long size;//table数组的大小 unsigned long sizemask;//尺寸掩码等于size-1 unsigned long used;//已经存储的键值对个数&#125; dictht;typedef struct dict &#123;//字典结构 dictType *type; void *privdata; dictht ht[2];//存储两个hashtable是为了rehash时，充当副本作用 long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict;/* If safe is set to 1 this is a safe iterator, that means, you can call * dictAdd, dictFind, and other functions against the dictionary even while * iterating. Otherwise it is a non safe iterator, and only dictNext() * should be called while iterating. */typedef struct dictIterator &#123;//字典迭代器 dict *d;//当前迭代器指向的字典 long index; int table, safe;//是否为安全迭代器，当迭代不安全时只可以调用dictNext()方法 dictEntry *entry, *nextEntry;//当前字典中指向的键值对 /* unsafe iterator fingerprint for misuse detection. */ long long fingerprint;&#125; dictIterator;typedef void (dictScanFunction)(void *privdata, const dictEntry *de);typedef void (dictScanBucketFunction)(void *privdata, dictEntry **bucketref);/* This is the initial size of every hash table */#define DICT_HT_INITIAL_SIZE 4//初始化哈希列表的数组大小为4，size=4/* ------------------------------- Macros ------------------------------------*/#define dictFreeVal(d, entry) \ if ((d)-&gt;type-&gt;valDestructor) \ (d)-&gt;type-&gt;valDestructor((d)-&gt;privdata, (entry)-&gt;v.val)#define dictSetVal(d, entry, _val_) do &#123; \ if ((d)-&gt;type-&gt;valDup) \ (entry)-&gt;v.val = (d)-&gt;type-&gt;valDup((d)-&gt;privdata, _val_); \ else \ (entry)-&gt;v.val = (_val_); \&#125; while(0)#define dictSetSignedIntegerVal(entry, _val_) \ do &#123; (entry)-&gt;v.s64 = _val_; &#125; while(0)#define dictSetUnsignedIntegerVal(entry, _val_) \ do &#123; (entry)-&gt;v.u64 = _val_; &#125; while(0)#define dictSetDoubleVal(entry, _val_) \ do &#123; (entry)-&gt;v.d = _val_; &#125; while(0)#define dictFreeKey(d, entry) \ if ((d)-&gt;type-&gt;keyDestructor) \ (d)-&gt;type-&gt;keyDestructor((d)-&gt;privdata, (entry)-&gt;key)#define dictSetKey(d, entry, _key_) do &#123; \ if ((d)-&gt;type-&gt;keyDup) \ (entry)-&gt;key = (d)-&gt;type-&gt;keyDup((d)-&gt;privdata, _key_); \ else \ (entry)-&gt;key = (_key_); \&#125; while(0)#define dictCompareKeys(d, key1, key2) \ (((d)-&gt;type-&gt;keyCompare) ? \ (d)-&gt;type-&gt;keyCompare((d)-&gt;privdata, key1, key2) : \ (key1) == (key2))#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)//获取字典中key的hash对应#define dictGetKey(he) ((he)-&gt;key)//获取键值对的key#define dictGetVal(he) ((he)-&gt;v.val)//获取键值对的val#define dictGetSignedIntegerVal(he) ((he)-&gt;v.s64)//获取有符号整型val#define dictGetUnsignedIntegerVal(he) ((he)-&gt;v.u64)//获取无符号整型val#define dictGetDoubleVal(he) ((he)-&gt;v.d)//获取浮点型val#define dictSlots(d) ((d)-&gt;ht[0].size+(d)-&gt;ht[1].size)//获取字典总size#define dictSize(d) ((d)-&gt;ht[0].used+(d)-&gt;ht[1].used)//获取字典已经使用的键值对#define dictIsRehashing(d) ((d)-&gt;rehashidx != -1)//字典是否在重构/* API */dict *dictCreate(dictType *type, void *privDataPtr);//创建字典 传入类型和私有数据int dictExpand(dict *d, unsigned long size);//创建或者扩展字典sizeint dictAdd(dict *d, void *key, void *val);//字典中添加键值对dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing);//添加一个没有val的键值对，如果存在key键值对存在existing中dictEntry *dictAddOrFind(dict *d, void *key);//添加或者查询key键值对int dictReplace(dict *d, void *key, void *val);//字典中替换key键值对的value值int dictDelete(dict *d, const void *key);//字典中删除key键值对dictEntry *dictUnlink(dict *ht, const void *key);//从字典中揭开键值对，但是不释放空间void dictFreeUnlinkedEntry(dict *d, dictEntry *he);//释放解开键值对的空间void dictRelease(dict *d);//释放字典空间dictEntry * dictFind(dict *d, const void *key);//字典中查找键值对根据keyvoid *dictFetchValue(dict *d, const void *key);//获取key键值对的valint dictResize(dict *d);//根据usesd调整字典大小到最小dictIterator *dictGetIterator(dict *d);//获得字典迭代器dictIterator *dictGetSafeIterator(dict *d);//获得安全字典迭代器dictEntry *dictNext(dictIterator *iter);//迭代器内部指针后移void dictReleaseIterator(dictIterator *iter);//释放迭代器空间dictEntry *dictGetRandomKey(dict *d);//获得一个随机的键值对unsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count);//随机获得一些键值对void dictGetStats(char *buf, size_t bufsize, dict *d);//获取字典当前状态uint64_t dictGenHashFunction(const void *key, int len);//调用hash算法uint64_t dictGenCaseHashFunction(const unsigned char *buf, int len);//调用忽略大小写的hash算法void dictEmpty(dict *d, void(callback)(void*));//清空字典void dictEnableResize(void);//能够重构void dictDisableResize(void);//不能重构int dictRehash(dict *d, int n);//分n步重构字典int dictRehashMilliseconds(dict *d, int ms);//在固定时间内重构void dictSetHashFunctionSeed(uint8_t *seed);//设置重构因子uint8_t *dictGetHashFunctionSeed(void);//获取重构因子unsigned long dictScan(dict *d, unsigned long v, dictScanFunction *fn, dictScanBucketFunction *bucketfn, void *privdata);//扫描字典unsigned int dictGetHash(dict *d, const void *key);//获取字典key值的hash对应dictEntry **dictFindEntryRefByPtrAndHash(dict *d, const void *oldptr, unsigned int hash);//根据ptr和hash获取键值对/* Hash table types */extern dictType dictTypeHeapStringCopyKey;extern dictType dictTypeHeapStrings;extern dictType dictTypeHeapStringCopyKeyValue;#endif /* __DICT_H */ dict.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100#include "fmacros.h"#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;#include &lt;string.h&gt;#include &lt;stdarg.h&gt;#include &lt;limits.h&gt;#include &lt;sys/time.h&gt;#include "dict.h"#include "zmalloc.h"#ifndef DICT_BENCHMARK_MAIN#include "redisassert.h"#else#include &lt;assert.h&gt;#endif/* Using dictEnableResize() / dictDisableResize() we make possible to * enable/disable resizing of the hash table as needed. This is very important * for Redis, as we use copy-on-write and don't want to move too much memory * around when there is a child performing saving operations. * * Note that even when dict_can_resize is set to 0, not all resizes are * prevented: a hash table is still allowed to grow if the ratio between * the number of elements and the buckets &gt; dict_force_resize_ratio. */ //在需要时使用dictEnableResize() / dictDisableResize()使得字典可以调节size，这对于redis很重要， //当有一个子进程在save操作时，我们使用copy-on-write,不想移动过多内存 //dict_can_resize=0不能阻止字典resize，当used-buckets&gt;dict_force_resize_ratio时 依然可以resizestatic int dict_can_resize = 1;static unsigned int dict_force_resize_ratio = 5;/* -------------------------- private prototypes ---------------------------- */static int _dictExpandIfNeeded(dict *ht);//在需要时扩展字典static unsigned long _dictNextPower(unsigned long size);//计算次幂数static int _dictKeyIndex(dict *ht, const void *key, unsigned int hash, dictEntry **existing);//返回字典中key的桶index，如果存在填充exsitingstatic int _dictInit(dict *ht, dictType *type, void *privDataPtr);//初始化字典/* -------------------------- hash functions -------------------------------- */static uint8_t dict_hash_function_seed[16];//hash种子，用于hash函数计算void dictSetHashFunctionSeed(uint8_t *seed) &#123; memcpy(dict_hash_function_seed,seed,sizeof(dict_hash_function_seed));&#125;uint8_t *dictGetHashFunctionSeed(void) &#123; return dict_hash_function_seed;&#125;/* The default hashing function uses SipHash implementation * in siphash.c. *///hash映射默认实现在siphash.c中 采用的是简单的hash算法 分为区分大小写和忽略大小写uint64_t siphash(const uint8_t *in, const size_t inlen, const uint8_t *k);uint64_t siphash_nocase(const uint8_t *in, const size_t inlen, const uint8_t *k);uint64_t dictGenHashFunction(const void *key, int len) &#123; return siphash(key,len,dict_hash_function_seed);&#125;uint64_t dictGenCaseHashFunction(const unsigned char *buf, int len) &#123; return siphash_nocase(buf,len,dict_hash_function_seed);&#125;/* ----------------------------- API implementation ------------------------- *//* Reset a hash table already initialized with ht_init(). * NOTE: This function should only be called by ht_destroy(). */ static void _dictReset(dictht *ht)&#123; //重置dictht ht-&gt;table = NULL; ht-&gt;size = 0; ht-&gt;sizemask = 0; ht-&gt;used = 0;&#125;/* Create a new hash table */dict *dictCreate(dictType *type, void *privDataPtr)&#123; dict *d = zmalloc(sizeof(*d)); //调用私有方法 _dictInit(d,type,privDataPtr); return d;&#125;/* Initialize the hash table */int _dictInit(dict *d, dictType *type, void *privDataPtr)&#123; //初始化变量 _dictReset(&amp;d-&gt;ht[0]); _dictReset(&amp;d-&gt;ht[1]); d-&gt;type = type; d-&gt;privdata = privDataPtr; d-&gt;rehashidx = -1;//是否重构过 d-&gt;iterators = 0;//迭代器个数0 return DICT_OK;&#125;/* Resize the table to the minimal size that contains all the elements, * but with the invariant of a USED/BUCKETS ratio near to &lt;= 1 *///调整表size到最小容纳所有的元素//used/buckets接近1小于1int dictResize(dict *d)&#123; int minimal; //如果不能resiaze或者正在重构散列 if (!dict_can_resize || dictIsRehashing(d)) return DICT_ERR; minimal = d-&gt;ht[0].used;//使得minimal等于已经添加的键值对数目 if (minimal &lt; DICT_HT_INITIAL_SIZE) minimal = DICT_HT_INITIAL_SIZE;//确保最小size为4 //创建新的字典 return dictExpand(d, minimal);&#125;/* Expand or create the hash table */int dictExpand(dict *d, unsigned long size)&#123; dictht n; /* the new hash table */ //在redis中used参数必须为2的n次幂 unsigned long realsize = _dictNextPower(size);//计算扩容的realsize 应该小于等于size的最小2的n次幂 /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size)//如果正在rehash或者size变小了丢失数据返回失败 return DICT_ERR; /* Rehashing to the same table size is not useful. */ if (realsize == d-&gt;ht[0].size) return DICT_ERR;//此时size不变 不需要扩容 /* Allocate the new hash table and initialize all pointers to NULL */ n.size = realsize; n.sizemask = realsize-1; n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; /* Is this the first initialization? If so it's not really a rehashing * we just set the first hash table so that it can accept keys. */ if (d-&gt;ht[0].table == NULL) &#123;//d为刚刚创建的字典 d-&gt;ht[0] = n; return DICT_OK; &#125; /* Prepare a second hash table for incremental rehashing */ //将dictht赋给ht[1] 然后让dict开始重构 d-&gt;ht[1] = n; d-&gt;rehashidx = 0; return DICT_OK;&#125;/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. *///字典重构//n为step 一次step将一个桶中所有的键值对move到dictht[1]中int dictRehash(dict *d, int n) &#123; //空桶的最大数目为n*10 int empty_visits = n*10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx); while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123;//查找不为空的桶 d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125;dictEntry de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while(de) &#123;//遍历不为空的桶，将所有的键值对move到新键值对表中 unsigned int h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; /* Check if we already rehashed the whole table... */ if (d-&gt;ht[0].used == 0) &#123;//如果移动完毕就释放内存，将ht[1]赋给ht[0] zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125;long long timeInMilliseconds(void) &#123; struct timeval tv; gettimeofday(&amp;tv,NULL); return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);&#125;/* Rehash for an amount of time between ms milliseconds and ms+1 milliseconds */int dictRehashMilliseconds(dict *d, int ms) &#123; long long start = timeInMilliseconds(); int rehashes = 0; while(dictRehash(d,100)) &#123; rehashes += 100; if (timeInMilliseconds()-start &gt; ms) break; &#125; return rehashes;&#125;/* This function performs just a step of rehashing, and only if there are * no safe iterators bound to our hash table. When we have iterators in the * middle of a rehashing we can't mess with the two hash tables otherwise * some element can be missed or duplicated. * * This function is called by common lookup or update operations in the * dictionary so that the hash table automatically migrates from H1 to H2 * while it is actively used. */ //单步重构static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125;/* Add an element to the target hash table *///添加键值对int dictAdd(dict *d, void *key, void *val)&#123; dictEntry *entry = dictAddRaw(d,key,NULL); if (!entry) return DICT_ERR; dictSetVal(d, entry, val); return DICT_OK;&#125;/* Low level add or find: * This function adds the entry but instead of setting a value returns the * dictEntry structure to the user, that will make sure to fill the value * field as he wishes. * * This function is also directly exposed to the user API to be called * mainly in order to store non-pointers inside the hash value, example: * * entry = dictAddRaw(dict,mykey,NULL); * if (entry != NULL) dictSetSignedIntegerVal(entry,1000); * * Return values: * * If key already exists NULL is returned, and "*existing" is populated * with the existing entry if existing is not NULL. * * If key was added, the hash entry is returned to be manipulated by the caller. */dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; int index; dictEntry *entry; dictht *ht; if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ //计算key的字典中桶index if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL;//已经存在的key键值对返回null /* Allocate the memory and store the new entry. * Insert the element in top, with the assumption that in a database * system it is more likely that recently added entries are accessed * more frequently. */ ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];//如果任然在重构，操作基于ht[1]否则ht[0] entry = zmalloc(sizeof(*entry)); entry-&gt;next = ht-&gt;table[index];//添加在桶的头部 ht-&gt;table[index] = entry; ht-&gt;used++; /* Set the hash entry fields. */ dictSetKey(d, entry, key);//添加了一个没有val的键值对 return entry;&#125;/* Add or Overwrite: * Add an element, discarding the old value if the key already exists. * Return 1 if the key was added from scratch, 0 if there was already an * element with such key and dictReplace() just performed a value update * operation. */int dictReplace(dict *d, void *key, void *val)&#123; dictEntry *entry, *existing, auxentry; /* Try to add the element. If the key * does not exists dictAdd will suceed. */ entry = dictAddRaw(d,key,&amp;existing); if (entry) &#123;//如果不存在 直接添加 dictSetVal(d, entry, val); return 1; &#125; /* Set the new value and free the old one. Note that it is important * to do that in this order, as the value may just be exactly the same * as the previous one. In this context, think to reference counting, * you want to increment (set), and then decrement (free), and not the * reverse. */ auxentry = *existing;//存在这个key dictSetVal(d, existing, val);//替换新的val dictFreeVal(d, &amp;auxentry);//释放旧的val return 0;&#125;/* Add or Find: * dictAddOrFind() is simply a version of dictAddRaw() that always * returns the hash entry of the specified key, even if the key already * exists and can't be added (in that case the entry of the already * existing key is returned.) * * See dictAddRaw() for more information. */dictEntry *dictAddOrFind(dict *d, void *key) &#123; dictEntry *entry, *existing; entry = dictAddRaw(d,key,&amp;existing); return entry ? entry : existing;&#125;/* Search and remove an element. This is an helper function for * dictDelete() and dictUnlink(), please check the top comment * of those functions. */static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) &#123; unsigned int h, idx; dictEntry *he, *prevHe; int table; if (d-&gt;ht[0].used == 0 &amp;&amp; d-&gt;ht[1].used == 0) return NULL; if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); //对于新旧表分别遍历 for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask;//计算桶的index he = d-&gt;ht[table].table[idx]; prevHe = NULL; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; /* Unlink the element from the list */ if (prevHe) prevHe-&gt;next = he-&gt;next; else d-&gt;ht[table].table[idx] = he-&gt;next; if (!nofree) &#123;//是否释放空间 dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); &#125; d-&gt;ht[table].used--; return he; &#125; prevHe = he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break;//如果没有重构 不需要扫描ht[1] &#125; return NULL; /* not found */&#125;/* Remove an element, returning DICT_OK on success or DICT_ERR if the * element was not found. */int dictDelete(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,0) ? DICT_OK : DICT_ERR;&#125;/* Remove an element from the table, but without actually releasing * the key, value and dictionary entry. The dictionary entry is returned * if the element was found (and unlinked from the table), and the user * should later call `dictFreeUnlinkedEntry()` with it in order to release it. * Otherwise if the key is not found, NULL is returned. * * This function is useful when we want to remove something from the hash * table but want to use its value before actually deleting the entry. * Without this function the pattern would require two lookups: * * entry = dictFind(...); * // Do something with entry * dictDelete(dictionary,entry); * * Thanks to this function it is possible to avoid this, and use * instead: * * entry = dictUnlink(dictionary,entry); * // Do something with entry * dictFreeUnlinkedEntry(entry); // &lt;- This does not need to lookup again. */ //从表中删除键值对，但是不释放空间dictEntry *dictUnlink(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,1);&#125;/* You need to call this function to really free the entry after a call * to dictUnlink(). It's safe to call this function with 'he' = NULL. */void dictFreeUnlinkedEntry(dict *d, dictEntry *he) &#123; if (he == NULL) return; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he);&#125;/* Destroy an entire dictionary *///清空dict中dictht 但不释放它的空间 callback为私有数据的释放函数int _dictClear(dict *d, dictht *ht, void(callback)(void *)) &#123; unsigned long i; /* Free all the elements */ for (i = 0; i &lt; ht-&gt;size &amp;&amp; ht-&gt;used &gt; 0; i++) &#123; dictEntry *he, *nextHe; if (callback &amp;&amp; (i &amp; 65535) == 0) callback(d-&gt;privdata); if ((he = ht-&gt;table[i]) == NULL) continue; while(he) &#123;//释放所有的键值对 nextHe = he-&gt;next; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); ht-&gt;used--; he = nextHe; &#125; &#125; /* Free the table and the allocated cache structure */ zfree(ht-&gt;table); /* Re-initialize the table */ _dictReset(ht); return DICT_OK; /* never fails */&#125;/* Clear &amp; Release the hash table *///释放dict的空间void dictRelease(dict *d)&#123; _dictClear(d,&amp;d-&gt;ht[0],NULL); _dictClear(d,&amp;d-&gt;ht[1],NULL); zfree(d);&#125;dictEntry *dictFind(dict *d, const void *key)&#123; dictEntry *he; unsigned int h, idx, table; if (d-&gt;ht[0].used + d-&gt;ht[1].used == 0) return NULL; /* dict is empty */ if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key);//计算hash值 for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask;//计算桶index he = d-&gt;ht[table].table[idx]; while(he) &#123;//遍历查找 if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) return NULL; &#125; return NULL;&#125;void *dictFetchValue(dict *d, const void *key) &#123; dictEntry *he; he = dictFind(d,key);//查找键值对 return he ? dictGetVal(he) : NULL;&#125;/* A fingerprint is a 64 bit number that represents the state of the dictionary * at a given time, it's just a few dict properties xored together. * When an unsafe iterator is initialized, we get the dict fingerprint, and check * the fingerprint again when the iterator is released. * If the two fingerprints are different it means that the user of the iterator * performed forbidden operations against the dictionary while iterating. *///对于字典状态通过异或运算生成64位数，当获取不安全迭代器调用，释放时对比前后fingerprint，不同代表中间有其他操作long long dictFingerprint(dict *d) &#123; long long integers[6], hash = 0; int j; integers[0] = (long) d-&gt;ht[0].table; integers[1] = d-&gt;ht[0].size; integers[2] = d-&gt;ht[0].used; integers[3] = (long) d-&gt;ht[1].table; integers[4] = d-&gt;ht[1].size; integers[5] = d-&gt;ht[1].used; /* We hash N integers by summing every successive integer with the integer * hashing of the previous sum. Basically: * * Result = hash(hash(hash(int1)+int2)+int3) ... * * This way the same set of integers in a different order will (likely) hash * to a different number. */ for (j = 0; j &lt; 6; j++) &#123; hash += integers[j]; /* For the hashing step we use Tomas Wang's 64 bit integer hash. */ hash = (~hash) + (hash &lt;&lt; 21); // hash = (hash &lt;&lt; 21) - hash - 1; hash = hash ^ (hash &gt;&gt; 24); hash = (hash + (hash &lt;&lt; 3)) + (hash &lt;&lt; 8); // hash * 265 hash = hash ^ (hash &gt;&gt; 14); hash = (hash + (hash &lt;&lt; 2)) + (hash &lt;&lt; 4); // hash * 21 hash = hash ^ (hash &gt;&gt; 28); hash = hash + (hash &lt;&lt; 31); &#125; return hash;&#125;dictIterator *dictGetIterator(dict *d)&#123; dictIterator *iter = zmalloc(sizeof(*iter)); iter-&gt;d = d; iter-&gt;table = 0; iter-&gt;index = -1; iter-&gt;safe = 0;//默认不安全 iter-&gt;entry = NULL; iter-&gt;nextEntry = NULL; return iter;&#125;dictIterator *dictGetSafeIterator(dict *d) &#123; dictIterator *i = dictGetIterator(d); i-&gt;safe = 1; return i;&#125;dictEntry *dictNext(dictIterator *iter)&#123; while (1) &#123; if (iter-&gt;entry == NULL) &#123; dictht *ht = &amp;iter-&gt;d-&gt;ht[iter-&gt;table]; if (iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0) &#123; if (iter-&gt;safe) iter-&gt;d-&gt;iterators++; else iter-&gt;fingerprint = dictFingerprint(iter-&gt;d); &#125; iter-&gt;index++; if (iter-&gt;index &gt;= (long) ht-&gt;size) &#123; if (dictIsRehashing(iter-&gt;d) &amp;&amp; iter-&gt;table == 0) &#123; iter-&gt;table++; iter-&gt;index = 0; ht = &amp;iter-&gt;d-&gt;ht[1];//切换到ht[1] &#125; else &#123; break; &#125; &#125; iter-&gt;entry = ht-&gt;table[iter-&gt;index]; &#125; else &#123; iter-&gt;entry = iter-&gt;nextEntry; &#125; if (iter-&gt;entry) &#123; /* We need to save the 'next' here, the iterator user * may delete the entry we are returning. */ iter-&gt;nextEntry = iter-&gt;entry-&gt;next; return iter-&gt;entry; &#125; &#125; return NULL;&#125;void dictReleaseIterator(dictIterator *iter)&#123; if (!(iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0)) &#123; if (iter-&gt;safe) iter-&gt;d-&gt;iterators--; else //不安全迭代器释放之前对比前后的fingerprint assert(iter-&gt;fingerprint == dictFingerprint(iter-&gt;d)); &#125; zfree(iter);&#125;/* Return a random entry from the hash table. Useful to * implement randomized algorithms */dictEntry *dictGetRandomKey(dict *d)&#123; dictEntry *he, *orighe; unsigned int h; int listlen, listele; if (dictSize(d) == 0) return NULL; if (dictIsRehashing(d)) _dictRehashStep(d); if (dictIsRehashing(d)) &#123; do &#123; /* We are sure there are no elements in indexes from 0 * to rehashidx-1 */ //在0-rehashidx-1的桶没有键值对所以如下随机数生成 h = d-&gt;rehashidx + (random() % (d-&gt;ht[0].size + d-&gt;ht[1].size - d-&gt;rehashidx)); he = (h &gt;= d-&gt;ht[0].size) ? d-&gt;ht[1].table[h - d-&gt;ht[0].size] : d-&gt;ht[0].table[h]; &#125; while(he == NULL); &#125; else &#123; do &#123; h = random() &amp; d-&gt;ht[0].sizemask;//在ht[0]中随机一个桶 he = d-&gt;ht[0].table[h]; &#125; while(he == NULL); &#125; /* Now we found a non empty bucket, but it is a linked * list and we need to get a random element from the list. * The only sane way to do so is counting the elements and * select a random index. */ //在桶上随机一个键值对 listlen = 0; orighe = he; while(he) &#123; he = he-&gt;next; listlen++;//获取桶上键值对总数 &#125; listele = random() % listlen;//生成随机键值对 he = orighe; while(listele--) he = he-&gt;next; return he;&#125;/* This function samples the dictionary to return a few keys from random * locations. * * It does not guarantee to return all the keys specified in 'count', nor * it does guarantee to return non-duplicated elements, however it will make * some effort to do both things. * * Returned pointers to hash table entries are stored into 'des' that * points to an array of dictEntry pointers. The array must have room for * at least 'count' elements, that is the argument we pass to the function * to tell how many random elements we need. * * The function returns the number of items stored into 'des', that may * be less than 'count' if the hash table has less than 'count' elements * inside, or if not enough elements were found in a reasonable amount of * steps. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to "sample" a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements. */ //随机生成一些键值对，不一定达到count数目在某些情况下，并且可能有重复，比单个随机获取键值对快unsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) &#123; unsigned long j; /* internal hash table id, 0 or 1. */ unsigned long tables; /* 1 or 2 tables? */ unsigned long stored = 0, maxsizemask; unsigned long maxsteps; if (dictSize(d) &lt; count) count = dictSize(d);//确保count不超过size maxsteps = count*10; /* Try to do a rehashing work proportional to 'count'. */ for (j = 0; j &lt; count; j++) &#123; if (dictIsRehashing(d)) _dictRehashStep(d); else break; &#125; tables = dictIsRehashing(d) ? 2 : 1; maxsizemask = d-&gt;ht[0].sizemask; if (tables &gt; 1 &amp;&amp; maxsizemask &lt; d-&gt;ht[1].sizemask) maxsizemask = d-&gt;ht[1].sizemask;//更新掩码 /* Pick a random point inside the larger table. */ unsigned long i = random() &amp; maxsizemask; unsigned long emptylen = 0; /* Continuous empty entries so far. */ while(stored &lt; count &amp;&amp; maxsteps--) &#123; for (j = 0; j &lt; tables; j++) &#123; /* Invariant of the dict.c rehashing: up to the indexes already * visited in ht[0] during the rehashing, there are no populated * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */ if (tables == 2 &amp;&amp; j == 0 &amp;&amp; i &lt; (unsigned long) d-&gt;rehashidx) &#123; /* Moreover, if we are currently out of range in the second * table, there will be no elements in both tables up to * the current rehashing index, so we jump if possible. * (this happens when going from big to small table). */ //由于重构过程中rehashidx参数的参考，所以i小于它是可以确保为空桶 if (i &gt;= d-&gt;ht[1].size) i = d-&gt;rehashidx; continue; &#125; if (i &gt;= d-&gt;ht[j].size) continue; /* Out of range for this table. */ dictEntry *he = d-&gt;ht[j].table[i]; /* Count contiguous empty buckets, and jump to other * locations if they reach 'count' (with a minimum of 5). */ if (he == NULL) &#123; emptylen++; if (emptylen &gt;= 5 &amp;&amp; emptylen &gt; count) &#123; i = random() &amp; maxsizemask;//重新随机 emptylen = 0; &#125; &#125; else &#123; emptylen = 0; while (he) &#123; /* Collect all the elements of the buckets found non * empty while iterating. */ *des = he;//存储随机的键值对 des++; he = he-&gt;next; stored++; if (stored == count) return stored; &#125; &#125; &#125; i = (i+1) &amp; maxsizemask;//i+1后重新计算桶index &#125; return stored;&#125;/* Function to reverse bits. Algorithm from: * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */ //翻转一个长整形bit位static unsigned long rev(unsigned long v) &#123; unsigned long s = 8 * sizeof(v); // bit size; must be power of 2 unsigned long mask = ~0; while ((s &gt;&gt;= 1) &gt; 0) &#123; mask ^= (mask &lt;&lt; s); v = ((v &gt;&gt; s) &amp; mask) | ((v &lt;&lt; s) &amp; ~mask); &#125; return v;&#125;/* dictScan() is used to iterate over the elements of a dictionary. * * Iterating works the following way: * * 1) Initially you call the function using a cursor (v) value of 0. * 2) The function performs one step of the iteration, and returns the * new cursor value you must use in the next call. * 3) When the returned cursor is 0, the iteration is complete. * * The function guarantees all elements present in the * dictionary get returned between the start and end of the iteration. * However it is possible some elements get returned multiple times. * * For every element returned, the callback argument 'fn' is * called with 'privdata' as first argument and the dictionary entry * 'de' as second argument. * * HOW IT WORKS. * * The iteration algorithm was designed by Pieter Noordhuis. * The main idea is to increment a cursor starting from the higher order * bits. That is, instead of incrementing the cursor normally, the bits * of the cursor are reversed, then the cursor is incremented, and finally * the bits are reversed again. * * This strategy is needed because the hash table may be resized between * iteration calls. * * dict.c hash tables are always power of two in size, and they * use chaining, so the position of an element in a given table is given * by computing the bitwise AND between Hash(key) and SIZE-1 * (where SIZE-1 is always the mask that is equivalent to taking the rest * of the division between the Hash of the key and SIZE). * * For example if the current hash table size is 16, the mask is * (in binary) 1111. The position of a key in the hash table will always be * the last four bits of the hash output, and so forth. * * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE? * * If the hash table grows, elements can go anywhere in one multiple of * the old bucket: for example let's say we already iterated with * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16). * * If the hash table will be resized to 64 elements, then the new mask will * be 111111. The new buckets you obtain by substituting in ??1100 * with either 0 or 1 can be targeted only by keys we already visited * when scanning the bucket 1100 in the smaller hash table. * * By iterating the higher bits first, because of the inverted counter, the * cursor does not need to restart if the table size gets bigger. It will * continue iterating using cursors without '1100' at the end, and also * without any other combination of the final 4 bits already explored. * * Similarly when the table size shrinks over time, for example going from * 16 to 8, if a combination of the lower three bits (the mask for size 8 * is 111) were already completely explored, it would not be visited again * because we are sure we tried, for example, both 0111 and 1111 (all the * variations of the higher bit) so we don't need to test it again. * * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING! * * Yes, this is true, but we always iterate the smaller table first, then * we test all the expansions of the current cursor into the larger * table. For example if the current cursor is 101 and we also have a * larger table of size 16, we also test (0)101 and (1)101 inside the larger * table. This reduces the problem back to having only one table, where * the larger one, if it exists, is just an expansion of the smaller one. * * LIMITATIONS * * This iterator is completely stateless, and this is a huge advantage, * including no additional memory used. * * The disadvantages resulting from this design are: * * 1) It is possible we return elements more than once. However this is usually * easy to deal with in the application level. * 2) The iterator must return multiple elements per call, as it needs to always * return all the keys chained in a given bucket, and all the expansions, so * we are sure we don't miss keys moving during rehashing. * 3) The reverse cursor is somewhat hard to understand at first, but this * comment is supposed to help. */unsigned long dictScan(dict *d, unsigned long v, dictScanFunction *fn, dictScanBucketFunction* bucketfn, void *privdata)&#123; dictht *t0, *t1; const dictEntry *de, *next; unsigned long m0, m1; if (dictSize(d) == 0) return 0; if (!dictIsRehashing(d)) &#123; t0 = &amp;(d-&gt;ht[0]); m0 = t0-&gt;sizemask; /* Emit entries at cursor */ if (bucketfn) bucketfn(privdata, &amp;t0-&gt;table[v &amp; m0]); de = t0-&gt;table[v &amp; m0]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; &#125; else &#123; t0 = &amp;d-&gt;ht[0]; t1 = &amp;d-&gt;ht[1]; /* Make sure t0 is the smaller and t1 is the bigger table */ if (t0-&gt;size &gt; t1-&gt;size) &#123; t0 = &amp;d-&gt;ht[1]; t1 = &amp;d-&gt;ht[0]; &#125; m0 = t0-&gt;sizemask; m1 = t1-&gt;sizemask; /* Emit entries at cursor */ if (bucketfn) bucketfn(privdata, &amp;t0-&gt;table[v &amp; m0]); de = t0-&gt;table[v &amp; m0]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; /* Iterate over indices in larger table that are the expansion * of the index pointed to by the cursor in the smaller table */ do &#123; /* Emit entries at cursor */ if (bucketfn) bucketfn(privdata, &amp;t1-&gt;table[v &amp; m1]); de = t1-&gt;table[v &amp; m1]; while (de) &#123; next = de-&gt;next; fn(privdata, de); de = next; &#125; /* Increment bits not covered by the smaller mask */ v = (((v | m0) + 1) &amp; ~m0) | (v &amp; m0); /* Continue while bits covered by mask difference is non-zero */ &#125; while (v &amp; (m0 ^ m1)); &#125; /* Set unmasked bits so incrementing the reversed cursor * operates on the masked bits of the smaller table */ v |= ~m0; /* Increment the reverse cursor */ v = rev(v); v++; v = rev(v); return v;&#125;/* ------------------------- private functions ------------------------------ *//* Expand the hash table if needed */static int _dictExpandIfNeeded(dict *d)&#123; /* Incremental rehashing already in progress. Return. */ if (dictIsRehashing(d)) return DICT_OK;//正在rehash /* If the hash table is empty expand it to the initial size. */ //当dict在空的时候 if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); /* If we reached the 1:1 ratio, and we are allowed to resize the hash * table (global setting) or we should avoid it but the ratio between * elements/buckets is over the "safe" threshold, we resize doubling * the number of buckets. */ //当used大于size并且可以resize或者used和size比值大于ratio if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp; (dict_can_resize || d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio)) &#123; return dictExpand(d, d-&gt;ht[0].used*2);//扩展2倍的used &#125; return DICT_OK;&#125;/* Our hash table capability is a power of two */static unsigned long _dictNextPower(unsigned long size)&#123; unsigned long i = DICT_HT_INITIAL_SIZE; if (size &gt;= LONG_MAX) return LONG_MAX; while(1) &#123; if (i &gt;= size) return i; i *= 2; &#125;&#125;/* Returns the index of a free slot that can be populated with * a hash entry for the given 'key'. * If the key already exists, -1 is returned * and the optional output parameter may be filled. * * Note that if we are in the process of rehashing the hash table, the * index is always returned in the context of the second (new) hash table. */ //在给定的hash值确定的桶中查找key键值对，返回-1代表有并且填充existing 否则返回桶indexstatic int _dictKeyIndex(dict *d, const void *key, unsigned int hash, dictEntry **existing)&#123; unsigned int idx, table; dictEntry *he; if (existing) *existing = NULL; /* Expand the hash table if needed */ if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; for (table = 0; table &lt;= 1; table++) &#123; idx = hash &amp; d-&gt;ht[table].sizemask;//计算桶index /* Search if this slot does not already contain the given key */ he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; if (existing) *existing = he; return -1; &#125; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break; &#125; return idx;&#125;//清空字典void dictEmpty(dict *d, void(callback)(void*)) &#123; _dictClear(d,&amp;d-&gt;ht[0],callback);//清空键值对表 _dictClear(d,&amp;d-&gt;ht[1],callback); d-&gt;rehashidx = -1;//还原字段初始值 d-&gt;iterators = 0;&#125;void dictEnableResize(void) &#123; dict_can_resize = 1;&#125;void dictDisableResize(void) &#123; dict_can_resize = 0;&#125;unsigned int dictGetHash(dict *d, const void *key) &#123; return dictHashKey(d, key);&#125;/* Finds the dictEntry reference by using pointer and pre-calculated hash. * oldkey is a dead pointer and should not be accessed. * the hash value should be provided using dictGetHash. * no string / key comparison is performed. * return value is the reference to the dictEntry if found, or NULL if not found. */ //根据提前提供的hash以及oldptr查找键值对dictEntry **dictFindEntryRefByPtrAndHash(dict *d, const void *oldptr, unsigned int hash) &#123; dictEntry *he, **heref; unsigned int idx, table; if (d-&gt;ht[0].used + d-&gt;ht[1].used == 0) return NULL; /* dict is empty */ for (table = 0; table &lt;= 1; table++) &#123; idx = hash &amp; d-&gt;ht[table].sizemask; heref = &amp;d-&gt;ht[table].table[idx]; he = *heref; while(he) &#123; if (oldptr==he-&gt;key)//判断是否相等 return heref; heref = &amp;he-&gt;next; he = *heref; &#125; if (!dictIsRehashing(d)) return NULL; &#125; return NULL;&#125;/* ------------------------------- Debugging ---------------------------------*/#define DICT_STATS_VECTLEN 50//答应dictht的状态属性size_t _dictGetStatsHt(char *buf, size_t bufsize, dictht *ht, int tableid) &#123; unsigned long i, slots = 0, chainlen, maxchainlen = 0; unsigned long totchainlen = 0; unsigned long clvector[DICT_STATS_VECTLEN]; size_t l = 0; if (ht-&gt;used == 0) &#123; return snprintf(buf,bufsize, "No stats available for empty dictionaries\n"); &#125; /* Compute stats. */ for (i = 0; i &lt; DICT_STATS_VECTLEN; i++) clvector[i] = 0; for (i = 0; i &lt; ht-&gt;size; i++) &#123; dictEntry *he; if (ht-&gt;table[i] == NULL) &#123; clvector[0]++; continue; &#125; slots++; /* For each hash entry on this slot... */ chainlen = 0; he = ht-&gt;table[i]; while(he) &#123; chainlen++; he = he-&gt;next; &#125; clvector[(chainlen &lt; DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++; if (chainlen &gt; maxchainlen) maxchainlen = chainlen; totchainlen += chainlen; &#125; /* Generate human readable stats. */ l += snprintf(buf+l,bufsize-l, "Hash table %d stats (%s):\n" " table size: %ld\n" " number of elements: %ld\n" " different slots: %ld\n" " max chain length: %ld\n" " avg chain length (counted): %.02f\n" " avg chain length (computed): %.02f\n" " Chain length distribution:\n", tableid, (tableid == 0) ? "main hash table" : "rehashing target", ht-&gt;size, ht-&gt;used, slots, maxchainlen, (float)totchainlen/slots, (float)ht-&gt;used/slots); for (i = 0; i &lt; DICT_STATS_VECTLEN-1; i++) &#123; if (clvector[i] == 0) continue; if (l &gt;= bufsize) break; l += snprintf(buf+l,bufsize-l, " %s%ld: %ld (%.02f%%)\n", (i == DICT_STATS_VECTLEN-1)?"&gt;= ":"", i, clvector[i], ((float)clvector[i]/ht-&gt;size)*100); &#125; /* Unlike snprintf(), teturn the number of characters actually written. */ if (bufsize) buf[bufsize-1] = '\0'; return strlen(buf);&#125;void dictGetStats(char *buf, size_t bufsize, dict *d) &#123; size_t l; char *orig_buf = buf; size_t orig_bufsize = bufsize; l = _dictGetStatsHt(buf,bufsize,&amp;d-&gt;ht[0],0); buf += l; bufsize -= l; if (dictIsRehashing(d) &amp;&amp; bufsize &gt; 0) &#123; _dictGetStatsHt(buf,bufsize,&amp;d-&gt;ht[1],1); &#125; /* Make sure there is a NULL term at the end. */ if (orig_bufsize) orig_buf[orig_bufsize-1] = '\0';&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(2)——adlist篇]]></title>
    <url>%2F2017%2F04%2F18%2Fredis%E6%BA%90%E7%A0%81-2-%E2%80%94%E2%80%94adlist%E7%AF%87%2F</url>
    <content type="text"><![CDATA[adlist对应的是redis中的链表这个类型，redis中命令有添加，删除节点等操作，在adlist中都一一实现。按照惯例来看adlist.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#ifndef __ADLIST_H__#define __ADLIST_H__/* Node, List, and Iterator are the only data structures used currently. *///链表节点typedef struct listNode &#123; struct listNode *prev;//前指针 struct listNode *next;//后指针 void *value;//值&#125; listNode;//链表迭代器typedef struct listIter &#123; listNode *next; int direction;//迭代器方向&#125; listIter;//链表结构typedef struct list &#123; listNode *head;//头指针 listNode *tail;//尾指针 void *(*dup)(void *ptr);//函数指针 void (*free)(void *ptr); int (*match)(void *ptr, void *key); unsigned long len;//链表长度&#125; list;/* Functions implemented as macros */#define listLength(l) ((l)-&gt;len)#define listFirst(l) ((l)-&gt;head)#define listLast(l) ((l)-&gt;tail)#define listPrevNode(n) ((n)-&gt;prev)#define listNextNode(n) ((n)-&gt;next)#define listNodeValue(n) ((n)-&gt;value)#define listSetDupMethod(l,m) ((l)-&gt;dup = (m))#define listSetFreeMethod(l,m) ((l)-&gt;free = (m))#define listSetMatchMethod(l,m) ((l)-&gt;match = (m))#define listGetDupMethod(l) ((l)-&gt;dup)#define listGetFree(l) ((l)-&gt;free)#define listGetMatchMethod(l) ((l)-&gt;match)/* Prototypes */list *listCreate(void);//创建链表void listRelease(list *list);//释放列表空间list *listAddNodeHead(list *list, void *value);//从头部添加节点list *listAddNodeTail(list *list, void *value);//从尾部添加节点list *listInsertNode(list *list, listNode *old_node, void *value, int after);//链表中插入节点void listDelNode(list *list, listNode *node);//删除列表中节点listIter *listGetIterator(list *list, int direction);//获取链表迭代器listNode *listNext(listIter *iter);//操作迭代器，指向下一个节点void listReleaseIterator(listIter *iter);//释放迭代器空间list *listDup(list *orig);//复制链表listNode *listSearchKey(list *list, void *key);//根据key查找节点listNode *listIndex(list *list, long index);//返回index的搅幢碲点void listRewind(list *list, listIter *li);//重置迭代器方向为从头到尾void listRewindTail(list *list, listIter *li);//重置迭代器方向为从尾部到头部void listRotate(list *list);//把list的tail移到head处/* Directions for iterators */#define AL_START_HEAD 0#define AL_START_TAIL 1#endif /* __ADLIST_H__ */ 在头文件中定义了链表结构为一个双向列表以及很多常用的列表函数，插入，删除，值得注意的是c语言中遍历采用的迭代器，在list结构中对应了三个函数指针，是针对（void *）类型的value的操作包括匹配，复制，释放。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314#include &lt;stdlib.h&gt;#include "adlist.h"#include "zmalloc.h"/* Create a new list. The created list can be freed with * AlFreeList(), but private value of every node need to be freed * by the user before to call AlFreeList(). * * On error, NULL is returned. Otherwise the pointer to the new list. */list *listCreate(void)&#123; struct list *list; if ((list = zmalloc(sizeof(*list))) == NULL)//分配空间 return NULL; //初始化成员 list-&gt;head = list-&gt;tail = NULL; list-&gt;len = 0; //函数指针初始化为null list-&gt;dup = NULL; list-&gt;free = NULL; list-&gt;match = NULL; return list;&#125;/* Free the whole list. * * This function can't fail. */void listRelease(list *list)&#123; unsigned long len; listNode *current, *next; current = list-&gt;head; len = list-&gt;len; while(len--) &#123;//逐个释放链表节点 next = current-&gt;next; if (list-&gt;free) list-&gt;free(current-&gt;value);//如果有函数指针就调用自定义的函数释放空间 zfree(current);//释放当前节点 current = next; &#125; zfree(list);//释放list空间&#125;/* Add a new node to the list, to head, containing the specified 'value' * pointer as value. * * On error, NULL is returned and no operation is performed (i.e. the * list remains unaltered). * On success the 'list' pointer you pass to the function is returned. */list *listAddNodeHead(list *list, void *value)&#123; listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-&gt;value = value; if (list-&gt;len == 0) &#123;//如果链表没有节点 list-&gt;head = list-&gt;tail = node; node-&gt;prev = node-&gt;next = NULL; &#125; else &#123;//如果链表有节点 node-&gt;prev = NULL;//头结点更换 node-&gt;next = list-&gt;head; list-&gt;head-&gt;prev = node; list-&gt;head = node; &#125; list-&gt;len++; return list;&#125;/* Add a new node to the list, to tail, containing the specified 'value' * pointer as value. * * On error, NULL is returned and no operation is performed (i.e. the * list remains unaltered). * On success the 'list' pointer you pass to the function is returned. */list *listAddNodeTail(list *list, void *value)&#123; listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-&gt;value = value; if (list-&gt;len == 0) &#123;//同在头部添加节点 list-&gt;head = list-&gt;tail = node; node-&gt;prev = node-&gt;next = NULL; &#125; else &#123; node-&gt;prev = list-&gt;tail; node-&gt;next = NULL; list-&gt;tail-&gt;next = node; list-&gt;tail = node; &#125; list-&gt;len++; return list;&#125;list *listInsertNode(list *list, listNode *old_node, void *value, int after) &#123; listNode *node; if ((node = zmalloc(sizeof(*node))) == NULL) return NULL; node-&gt;value = value; if (after) &#123;//是否在old_node之后 node-&gt;prev = old_node; node-&gt;next = old_node-&gt;next; if (list-&gt;tail == old_node) &#123; list-&gt;tail = node; &#125; &#125; else &#123; node-&gt;next = old_node; node-&gt;prev = old_node-&gt;prev; if (list-&gt;head == old_node) &#123; list-&gt;head = node; &#125; &#125; //更改添加节点之前或者之后节点的指针 if (node-&gt;prev != NULL) &#123; node-&gt;prev-&gt;next = node; &#125; if (node-&gt;next != NULL) &#123; node-&gt;next-&gt;prev = node; &#125; list-&gt;len++; return list;&#125;/* Remove the specified node from the specified list. * It's up to the caller to free the private value of the node. * * This function can't fail. */void listDelNode(list *list, listNode *node)&#123; //判断该节点是否是头结点或者是尾节点 if (node-&gt;prev) node-&gt;prev-&gt;next = node-&gt;next; else list-&gt;head = node-&gt;next; if (node-&gt;next) node-&gt;next-&gt;prev = node-&gt;prev; else list-&gt;tail = node-&gt;prev; //释放删除的节点空间 if (list-&gt;free) list-&gt;free(node-&gt;value); zfree(node); list-&gt;len--;&#125;/* Returns a list iterator 'iter'. After the initialization every * call to listNext() will return the next element of the list. * * This function can't fail. */listIter *listGetIterator(list *list, int direction)&#123; listIter *iter; if ((iter = zmalloc(sizeof(*iter))) == NULL) return NULL;//分配空间 //两个方向的list迭代器，初始化next不同 if (direction == AL_START_HEAD) iter-&gt;next = list-&gt;head; else iter-&gt;next = list-&gt;tail; iter-&gt;direction = direction; return iter;&#125;/* Release the iterator memory */void listReleaseIterator(listIter *iter) &#123; zfree(iter);&#125;/* Create an iterator in the list private iterator structure */void listRewind(list *list, listIter *li) &#123; li-&gt;next = list-&gt;head; li-&gt;direction = AL_START_HEAD;&#125;void listRewindTail(list *list, listIter *li) &#123; li-&gt;next = list-&gt;tail; li-&gt;direction = AL_START_TAIL;&#125;/* Return the next element of an iterator. * It's valid to remove the currently returned element using * listDelNode(), but not to remove other elements. * * The function returns a pointer to the next element of the list, * or NULL if there are no more elements, so the classical usage patter * is: * * iter = listGetIterator(list,&lt;direction&gt;); * while ((node = listNext(iter)) != NULL) &#123; * doSomethingWith(listNodeValue(node)); * &#125; * * */ //迭代器指向下一个节点，返回当前节点listNode *listNext(listIter *iter)&#123; listNode *current = iter-&gt;next; if (current != NULL) &#123; if (iter-&gt;direction == AL_START_HEAD) iter-&gt;next = current-&gt;next; else iter-&gt;next = current-&gt;prev; &#125; return current;&#125;/* Duplicate the whole list. On out of memory NULL is returned. * On success a copy of the original list is returned. * * The 'Dup' method set with listSetDupMethod() function is used * to copy the node value. Otherwise the same pointer value of * the original node is used as value of the copied node. * * The original list both on success or error is never modified. */list *listDup(list *orig)&#123; list *copy; listIter iter; listNode *node; if ((copy = listCreate()) == NULL) return NULL; copy-&gt;dup = orig-&gt;dup; copy-&gt;free = orig-&gt;free; copy-&gt;match = orig-&gt;match; listRewind(orig, &amp;iter); //遍历所有节点 while((node = listNext(&amp;iter)) != NULL) &#123; void *value; if (copy-&gt;dup) &#123; value = copy-&gt;dup(node-&gt;value); if (value == NULL) &#123; //节点值为null的话，复制节点失败 listRelease(copy);//释放之前创建的list return NULL; &#125; &#125; else value = node-&gt;value; if (listAddNodeTail(copy, value) == NULL) &#123; //添加节点失败，释放之前创建的list listRelease(copy); return NULL; &#125; &#125; return copy;&#125;/* Search the list for a node matching a given key. * The match is performed using the 'match' method * set with listSetMatchMethod(). If no 'match' method * is set, the 'value' pointer of every node is directly * compared with the 'key' pointer. * * On success the first matching node pointer is returned * (search starts from head). If no matching node exists * NULL is returned. */listNode *listSearchKey(list *list, void *key)&#123; listIter iter; listNode *node; listRewind(list, &amp;iter); while((node = listNext(&amp;iter)) != NULL) &#123; if (list-&gt;match) &#123;//自定义match if (list-&gt;match(node-&gt;value, key)) &#123; return node; &#125; &#125; else &#123;//拍闲断值是否相等 if (key == node-&gt;value) &#123; return node; &#125; &#125; &#125; return NULL;&#125;/* Return the element at the specified zero-based index * where 0 is the head, 1 is the element next to head * and so on. Negative integers are used in order to count * from the tail, -1 is the last element, -2 the penultimate * and so on. If the index is out of range NULL is returned. */listNode *listIndex(list *list, long index) &#123; listNode *n; if (index &lt; 0) &#123; index = (-index)-1; n = list-&gt;tail; //index为负数从尾部开始计数 while(index-- &amp;&amp; n) n = n-&gt;prev; &#125; else &#123; n = list-&gt;head; while(index-- &amp;&amp; n) n = n-&gt;next; &#125; return n;&#125;/* Rotate the list removing the tail node and inserting it to the head. */void listRotate(list *list) &#123; listNode *tail = list-&gt;tail; if (listLength(list) &lt;= 1) return; /* Detach current tail */ list-&gt;tail = tail-&gt;prev; list-&gt;tail-&gt;next = NULL; /* Move it as head */ list-&gt;head-&gt;prev = tail; tail-&gt;prev = NULL; tail-&gt;next = list-&gt;head; list-&gt;head = tail;&#125; 通过阅读adlist.c中的代码，是对自己C语言中列表操作实现的一次温习吧，对于如何插入头结点尾节点，在list中间插入节点的指针操作等，受益匪浅，同时一样要注意内存空间的申请和释放，在涉及到迭代器的几个函数实现中，可以通过listIter listGetIterator(list list, int direction)和void listReleaseIterator(listIter *iter)来获取和释放迭代器或许更好。可能迭代器的内存空间很小可以忽略吧。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis源码(1)——sds篇]]></title>
    <url>%2F2017%2F04%2F17%2Fredis%E6%BA%90%E7%A0%81-1-%E2%80%94%E2%80%94sds%E7%AF%87%2F</url>
    <content type="text"><![CDATA[redis源码(1)——sds篇sds简单动态字符串，redis中的字符串与C语言中的字符串不同，redis中对char数组封装成一个数据结构sdshdr，sdshdr中包含分配长度以及已经使用的长度，这样字符串没必要以“/0”结尾，并且是二进制安全的，redis中的sds还实现了许多C语言中字符串的常用操作。下面开始源码：sds.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278/* SDSLib 2.0 -- A C dynamic strings library * * Copyright (c) 2006-2015, Salvatore Sanfilippo &lt;antirez at gmail dot com&gt; * Copyright (c) 2015, Oran Agra * Copyright (c) 2015, Redis Labs, Inc * All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions are met: * * * Redistributions of source code must retain the above copyright notice, * this list of conditions and the following disclaimer. * * Redistributions in binary form must reproduce the above copyright * notice, this list of conditions and the following disclaimer in the * documentation and/or other materials provided with the distribution. * * Neither the name of Redis nor the names of its contributors may be used * to endorse or promote products derived from this software without * specific prior written permission. * * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE * POSSIBILITY OF SUCH DAMAGE. */#ifndef __SDS_H#define __SDS_H#define SDS_MAX_PREALLOC (1024*1024)#include &lt;sys/types.h&gt;#include &lt;stdarg.h&gt;#include &lt;stdint.h&gt;typedef char *sds;/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;#define SDS_TYPE_5 0#define SDS_TYPE_8 1#define SDS_TYPE_16 2#define SDS_TYPE_32 3#define SDS_TYPE_64 4#define SDS_TYPE_MASK 7#define SDS_TYPE_BITS 3//由sds复制sdshdr结构体指针给sh#define SDS_HDR_VAR(T,s) struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T)));//由sds获得sdshdr结构体指针#define SDS_HDR(T,s) ((struct sdshdr##T *)((s)-(sizeof(struct sdshdr##T))))#define SDS_TYPE_5_LEN(f) ((f)&gt;&gt;SDS_TYPE_BITS)//获取sds的已经使用的长度static inline size_t sdslen(const sds s) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return SDS_TYPE_5_LEN(flags); case SDS_TYPE_8: return SDS_HDR(8,s)-&gt;len; case SDS_TYPE_16: return SDS_HDR(16,s)-&gt;len; case SDS_TYPE_32: return SDS_HDR(32,s)-&gt;len; case SDS_TYPE_64: return SDS_HDR(64,s)-&gt;len; &#125; return 0;&#125;//获取sds的未使用的长度static inline size_t sdsavail(const sds s) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: &#123; return 0; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); return sh-&gt;alloc - sh-&gt;len; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); return sh-&gt;alloc - sh-&gt;len; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); return sh-&gt;alloc - sh-&gt;len; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); return sh-&gt;alloc - sh-&gt;len; &#125; &#125; return 0;&#125;//设置sdshdr的已使用值即flagstatic inlin使用e void sdssetlen(sds s, size_t newlen) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: &#123; unsigned char *fp = ((unsigned char*)s)-1; *fp = SDS_TYPE_5 | (newlen &lt;&lt; SDS_TYPE_BITS); &#125; break; case SDS_TYPE_8: SDS_HDR(8,s)-&gt;len = newlen; break; case SDS_TYPE_16: SDS_HDR(16,s)-&gt;len = newlen; break; case SDS_TYPE_32: SDS_HDR(32,s)-&gt;len = newlen; break; case SDS_TYPE_64: SDS_HDR(64,s)-&gt;len = newlen; break; &#125;&#125;//增加sdshdr的已使用值即flagstatic inline void sdsinclen(sds s, size_t inc) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: &#123; unsigned char *fp = ((unsigned char*)s)-1; unsigned char newlen = SDS_TYPE_5_LEN(flags)+inc; *fp = SDS_TYPE_5 | (newlen &lt;&lt; SDS_TYPE_BITS); &#125; break; case SDS_TYPE_8: SDS_HDR(8,s)-&gt;len += inc; break; case SDS_TYPE_16: SDS_HDR(16,s)-&gt;len += inc; break; case SDS_TYPE_32: SDS_HDR(32,s)-&gt;len += inc; break; case SDS_TYPE_64: SDS_HDR(64,s)-&gt;len += inc; break; &#125;&#125;//获取sdshdr分配的buf大小/* sdsalloc() = sdsavail() + sdslen() */static inline size_t sdsalloc(const sds s) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return SDS_TYPE_5_LEN(flags); case SDS_TYPE_8: return SDS_HDR(8,s)-&gt;alloc; case SDS_TYPE_16: return SDS_HDR(16,s)-&gt;alloc; case SDS_TYPE_32: return SDS_HDR(32,s)-&gt;alloc; case SDS_TYPE_64: return SDS_HDR(64,s)-&gt;alloc; &#125; return 0;&#125;//设置sdshdr分配的buf大小static inline void sdssetalloc(sds s, size_t newlen) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: /* Nothing to do, this type has no total allocation info. */ break; case SDS_TYPE_8: SDS_HDR(8,s)-&gt;alloc = newlen; break; case SDS_TYPE_16: SDS_HDR(16,s)-&gt;alloc = newlen; break; case SDS_TYPE_32: SDS_HDR(32,s)-&gt;alloc = newlen; break; case SDS_TYPE_64: SDS_HDR(64,s)-&gt;alloc = newlen; break; &#125;&#125;sds sdsnewlen(const void *init, size_t initlen);//通过init字符串以及initlen创建并初始化sdshdrsds sdsnew(const char *init);//通过init字符串以及strlen(init)创建并初始化sdshdrsds sdsempty(void);//创建一个len=0，init=“”的sdshdrsds sdsdup(const sds s);//复制一个sdsvoid sdsfree(sds s);//释放sdshdr空间sds sdsgrowzero(sds s, size_t len);//增加sds的长度并且用0填充sds sdscatlen(sds s, const void *t, size_t len);//在sds尾部append字符串t的前len个字符sds sdscat(sds s, const char *t);//在sds尾部append字符串tsds sdscatsds(sds s, const sds t);//在sds s尾部添加sds tsds sdscpylen(sds s, const char *t, size_t len);//截取t的前len段复制到sds ssds sdscpy(sds s, const char *t);//复制t到sds ssds sdscatvprintf(sds s, const char *fmt, va_list ap);//格式化字符串添加到sds s尾部#ifdef __GNUC__sds sdscatprintf(sds s, const char *fmt, ...) __attribute__((format(printf, 2, 3)));#elsesds sdscatprintf(sds s, const char *fmt, ...);#endifsds sdscatfmt(sds s, char const *fmt, ...);//不依赖print组函数实现格式化字符串，效率更高sds sdstrim(sds s, const char *cset);//去除首尾的字符串集合中的字符void sdsrange(sds s, int start, int end);//截取字符串中一段字符串void sdsupdatelen(sds s);//按照第一个‘/0’出现的长度，更新lenvoid sdsclear(sds s);//清空sdshdr，但不freeint sdscmp(const sds s1, const sds s2);//比较两个sdshdr,与字符串cmp相似sds *sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count);//按照指定字符串分割给定字符串void sdsfreesplitres(sds *tokens, int count);//释放sdssplitlen后，返回字符串数组的空间void sdstolower(sds s);//小写void sdstoupper(sds s);//大写sds sdsfromlonglong(long long value);//长整型转字符串sds sdscatrepr(sds s, const char *p, size_t len);//绝对复制忽略/r/n等这些字符sds *sdssplitargs(const char *line, int *argc);//分割参数sds sdsmapchars(sds s, const char *from, const char *to, size_t setlen);//用to*代替from*，但是是但字符替换sds sdsjoin(char **argv, int argc, char *sep);//合并字符串char*sds sdsjoinsds(sds *argv, int argc, const char *sep, size_t seplen);//合并字符串sds/* Low level functions exposed to the user API */sds sdsMakeRoomFor(sds s, size_t addlen);//为sds增加buf空间void sdsIncrLen(sds s, int incr);//增加sds的lensds sdsRemoveFreeSpace(sds s);//释放sds空间size_t sdsAllocSize(sds s);//返回sds的sdshdr申请空间void *sdsAllocPtr(sds s);//返回sds的sdshdr指针/* Export the allocator used by SDS to the program using SDS. * Sometimes the program SDS is linked to, may use a different set of * allocators, but may want to allocate or free things that SDS will * respectively free or allocate. */void *sds_malloc(size_t size);void *sds_realloc(void *ptr, size_t size);void sds_free(void *ptr);#ifdef REDIS_TESTint sdsTest(int argc, char *argv[]);#endif#endif 通过sds.h文件发现redis中的字符串，通过一般是sds来找到sdshdr，之后得到相关的参数，可以参见开始定义的2个宏函数，并且拥有很多c语言字符串常用的操作，很期待看一下这些函数的源码。由于篇幅有限，这里不能将所有函数一一列出。sds.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293//通过init字符串以及initlen创建并初始化sdshdrsds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen);//判断类型 /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8;//type5在实际中不使用 int hdrlen = sdsHdrSize(type); unsigned char *fp; /* flags pointer. */ sh = s_malloc(hdrlen+initlen+1);//分配空间 if (!init) memset(sh, 0, hdrlen+initlen+1); if (sh == NULL) return NULL; s = (char*)sh+hdrlen;//buf数组首地址 fp = ((unsigned char*)s)-1;//flag switch(type) &#123;//初始化变量 case SDS_TYPE_5: &#123; *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); break; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen);//初始化buf s[initlen] = '\0'; return s;&#125;/* Enlarge the free space at the end of the sds string so that the caller * is sure that after calling this function can overwrite up to addlen * bytes after the end of the string, plus one more byte for nul term. * * Note: this does not change the *length* of the sds string as returned * by sdslen(), but only the free buffer space we have. */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; void *sh, *newsh; size_t avail = sdsavail(s); size_t len, newlen; char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ if (avail &gt;= addlen) return s;//有足够的空间return len = sdslen(s); sh = (char*)s-sdsHdrSize(oldtype);//得到原sdshdr的指针 newlen = (len+addlen);//得到新的len if (newlen &lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; //这里可能是为了避免多次开辟空间，做一个预开辟一些空间 type = sdsReqType(newlen);//判断类型 /* Don't use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type);//得到该类型sdshdr需要的空间 if (oldtype==type) &#123; newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can't use realloc */ //如果新类型，需要释放sh，创建新的newsh newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; memcpy((char*)newsh+hdrlen, s, len+1);//复制sds到newsh的buf s_free(sh); s = (char*)newsh+hdrlen; s[-1] = type;//set type sdssetlen(s, len);//set len &#125; sdssetalloc(s, newlen);//set alloc return s;&#125;int sdsll2str(char *s, long long value) &#123; char *p, aux; unsigned long long v; size_t l; /* Generate the string representation, this method produces * an reversed string. */ v = (value &lt; 0) ? -value : value;//判断正负 p = s; do &#123; *p++ = '0'+(v%10); v /= 10; &#125; while(v); if (value &lt; 0) *p++ = '-'; //倒序存储在p指针 /* Compute length and add null term. */ l = p-s;//字符串长度 *p = '\0'; /* Reverse the string. */ p--; while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--; &#125; //将p倒序存储到s中 return l;&#125;sds sdscatfmt(sds s, char const *fmt, ...) &#123; size_t initlen = sdslen(s);//原始长度 const char *f = fmt; int i; va_list ap; va_start(ap,fmt); //初始化变量 f = fmt; /* Next format specifier byte to process. */ i = initlen; /* Position of the next byte to write to dest str. */ while(*f) &#123; //用来存储输出变量 char next, *str; size_t l; long long num; unsigned long long unum; /* Make sure there is always space for at least 1 char. */ if (sdsavail(s)==0) &#123;//确保有可用空间 s = sdsMakeRoomFor(s,1); &#125; switch(*f) &#123; case '%': //如果是%分析下一个字符 否则输出 next = *(f+1); f++; switch(next) &#123; case 's': case 'S': //对于字符串输出处理 str = va_arg(ap,char*); l = (next == 's') ? strlen(str) : sdslen(str); if (sdsavail(s) &lt; l) &#123; s = sdsMakeRoomFor(s,l); &#125; memcpy(s+i,str,l); sdsinclen(s,l); i += l; break; case 'i': case 'I': //对于整型处理 if (next == 'i') num = va_arg(ap,int); else num = va_arg(ap,long long); &#123; char buf[SDS_LLSTR_SIZE]; l = sdsll2str(buf,num);//转化为字符串 if (sdsavail(s) &lt; l) &#123; s = sdsMakeRoomFor(s,l); &#125; memcpy(s+i,buf,l); sdsinclen(s,l); i += l; &#125; break; case 'u': case 'U': //对于非负整型的处理 if (next == 'u') unum = va_arg(ap,unsigned int); else unum = va_arg(ap,unsigned long long); &#123; char buf[SDS_LLSTR_SIZE]; l = sdsull2str(buf,unum); if (sdsavail(s) &lt; l) &#123; s = sdsMakeRoomFor(s,l); &#125; memcpy(s+i,buf,l); sdsinclen(s,l); i += l; &#125; break; //对于没有特殊字符的 直接忽略% 然后输出字符 default: /* Handle %% and generally %&lt;unknown&gt;. */ s[i++] = next; sdsinclen(s,1); break; &#125; break; default: s[i++] = *f; sdsinclen(s,1); break; &#125; f++; &#125; va_end(ap); /* Add null-term */ s[i] = '\0'; return s;&#125; //由于分割字符串result 分配了内存空间来存储结果，所以要使用sdsfreesliptres()来释放内存sds *sdssplitlen(const char *s, int len, const char *sep, int seplen, int *count) &#123; int elements = 0, slots = 5, start = 0, j; sds *tokens; if (seplen &lt; 1 || len &lt; 0) return NULL; //默认分为5组 预分配空间 tokens = s_malloc(sizeof(sds)*slots); if (tokens == NULL) return NULL; //如果len为0 没有需要split的字符串 if (len == 0) &#123; *count = 0; return tokens; &#125; //遍历字符串 for (j = 0; j &lt; (len-(seplen-1)); j++) &#123; /* make sure there is room for the next element and the final one */ //确保有可用的slots存储分割的字符串 if (slots &lt; elements+2) &#123; sds *newtokens; slots *= 2;//预分配 newtokens = s_realloc(tokens,sizeof(sds)*slots); if (newtokens == NULL) goto cleanup;//分配失败 goto free之前分配的空间 防止内存泄漏 tokens = newtokens; &#125; /* search the separator */ //单字符或者字符串 分析 if ((seplen == 1 &amp;&amp; *(s+j) == sep[0]) || (memcmp(s+j,sep,seplen) == 0)) &#123; tokens[elements] = sdsnewlen(s+start,j-start);//创建分割字符串 if (tokens[elements] == NULL) goto cleanup;//防止内存泄漏 elements++; start = j+seplen; j = j+seplen-1; /* skip the separator */ &#125; &#125; //最后一个字符串存储 /* Add the final element. We are sure there is room in the tokens array. */ tokens[elements] = sdsnewlen(s+start,len-start); if (tokens[elements] == NULL) goto cleanup; elements++; *count = elements; return tokens;cleanup: &#123; int i; for (i = 0; i &lt; elements; i++) sdsfree(tokens[i]); s_free(tokens); *count = 0; return NULL; &#125;&#125; 对于sds中函数，大都涉及到了C语言字符串的操作，通过底层自己实现一遍，特别比如格式化输出，有利用printf组函数实现也有用自己单字符分析来处理的，加快了效率，还有要注意的就是防止内存泄漏溢出，这对于长期写java等高级语言的同志是经常忽略的，在split函数中，redis都用检查分配是否成功，以及goto来free空间，开辟的空间使用完毕后要及时释放，否则程序会出现意想不到的错误，这就是为什么所有c语言项目中都有关于malloc以及free的文件函数等。 对比C语言中字符串主要有几个优点：1.对于获取len效率高2.防止内存溢出，因为len以及alloc属性3.空间预分配以及空间惰性释放4.二进制安全5.兼容一些C语言字符串函数]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开启redis源码]]></title>
    <url>%2F2017%2F04%2F16%2F%E5%BC%80%E5%90%AFredis%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[redis介绍redis一个键值对的内存数据库，支持string，list，hash，set，zset五种类型，也是它的优势之一，并且支持一些类型操作，可以通过aof或者rdb永久化数据库，提供许多语言的api，支持集群。官网:http://www.redis.cn/github:https://github.com/antirez/redis基础学习:http://www.runoob.com/redis/redis-tutorial.html redis源码结构redis所有的源码都放在src目录下，但相对来说可以大致分为以下几个部分：test:（测试）1.memtest.c 内存检测2.redis_benchmark.c 用于redis性能测试的实现。3.redis_check_aof.c 用于更新日志检查的实现。4.redis_check_dump.c 用于本地数据库检查的实现。5.testhelp.c 一个C风格的小型测试框架。 struct:（结构体）1.adlist.c 用于对list的定义，它是个双向链表结构2.dict.c 主要对于内存中的hash进行管理3.sds.c 用于对字符串的定义4.sparkline.c 一个拥有sample列表的序列5.t_hash.c hash在Server/Client中的应答操作。主要通过redisObject进行类型转换。6.t_list.c list在Server/Client中的应答操作。主要通过redisObject进行类型转换。7.t_set.c set在Server/Client中的应答操作。主要通过redisObject进行类型转换。8.t_string.c string在Server/Client中的应答操作。主要通过redisObject进行类型转换。9.t_zset.c zset在Server/Client中的应答操作。主要通过redisObject进行类型转换。10.ziplist.c ziplist是一个类似于list的存储对象。它的原理类似于zipmap。11.zipmap.c zipmap是一个类似于hash的存储对象。 data:（数据操作）1.aof.c 全称为append only file，作用就是记录每次的写操作,在遇到断电等问题时可以用它来恢复数据库状态。2.config.c 用于将配置文件redis.conf文件中的配置读取出来的属性通过程序放到server对象中。3.db.c对于Redis内存数据库的相关操作。4.multi.c用于事务处理操作。5.rdb.c 对于Redis本地数据库的相关操作，默认文件是dump.rdb（通过配置文件获得），包括的操作包括保存，移除，查询等等。6.replication.c 用于主从数据库的复制操作的实现。 tool:（工具）1.bitops.c 位操作相关类2.debug.c 用于调试时使用3.endianconv.c 高低位转换，不同系统，高低位顺序不同4.help.h 辅助于命令的提示信息5.lzf_c.c 压缩算法系列6.lzf_d.c 压缩算法系列7.rand.c 用于产生随机数8.release.c 用于发步时使用9.sha1.c sha加密算法的实现10.util.c 通用工具方法11.crc64.c 循环冗余校验 event:（事件）1.ae.c 用于Redis的事件处理，包括句柄事件和超时事件。2.ae_epoll.c 实现了epoll系统调用的接口3.ae_evport.c 实现了evport系统调用的接口4.ae_kqueue.c 实现了kqueuex系统调用的接口5.ae_select.c 实现了select系统调用的接口 baseinfo:（基本信息）1.asciilogo,c redis的logo显示2.version.h定有Redis的版本号 compatible:（兼容）1.fmacros.h 兼容Mac系统下的问题2.solarisfixes.h 兼容solary下的问题 main:（主程序）1.redis.c redis服务端程序2.redis_cli.c redis客户端程序 net:（网络）1.anet.c 作为Server/Client通信的基础封装2.networking.c 网络协议传输方法定义相关的都放在这个文件里面了。 wrapper:（封装类）1.bio.c background I/O的意思，开启后台线程用的2.hyperloglog.c 一种日志类型的3.intset.c 整数范围内的使用set，并包含相关set操作。4.latency.c 延迟类5.migrate.c 命令迁移类，包括命令的还原迁移等6.notify.c 通知类7.object.c 用于创建和释放redisObject对象8.pqsort.c 排序算法类9.pubsub.c 用于订阅模式的实现，有点类似于Client广播发送的方式。10.rio.c redis定义的一个I/O类11.slowlog.c 一种日志类型的，与hyperloglog.c类似12.sort.c 排序算法类，与pqsort.c使用的场景不同13.syncio.c 用于同步Socket和文件I/O操作。14.zmalloc.c 关于Redis的内存分配的封装实现 others:（存放了一些我暂时还不是很清楚的类,所以没有解释了）1.scripting.c2.sentinel.c2.setproctitle.c3.valgrind.sh4.redisassert.h 借鉴:http://blog.csdn.net/androidlushangderen/article/details/39803337 计划计划按照数据结构定义到单机数据库到集群数据库到独立功能来分析redis源码，并且在总体上按照上面的分包。通过阅读redis源码，这样一个相对较小的项目，是想提高自己阅读代码的能力，以及体会内存存储的机制，以及集群的基本实现，培养自己对于存储的理解或提出一些改进。 千里之行，始于足下。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
        <tag>redis</tag>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[香港之行]]></title>
    <url>%2F2017%2F04%2F08%2F%E9%A6%99%E6%B8%AF%E4%B9%8B%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[对于香港这座城市的印象当然要追溯到那一系列的电影，没错就是《古惑仔》系列了，铜锣湾扛把子是何等的威风，电影里面香港繁华的夜景，匆忙的行人，各种交通工具的声音混杂在一起，形成了香港独特的街景。所有对于香港还是挺神往的。时机很好，小伙伴在深圳工作，我们相约清明假期去香港玩一趟，第一次去当然要踩挺多坑，这里就说一下去香港的一些要准备的东西吧。1.港澳通行证当然是必须的啦，由于大部分人都是L旅游签，所以要提前几天预订旅游签注，当天加急的或者在过境处的话会被坑一大笔钱，我和小伙伴就是当天加急在深圳湾口岸办的签注，现场大都被垄断了要价很高。2.港澳无线流量通信电话卡以及八达通，在香港用八达通做交通工具很方便，不需要等待排队买票啦。3.当然可以选择坐飞机去香港，如果选择坐车的话，可以先到深圳，再从深圳的各个口岸选择过关，一般就是深圳湾，皇甫，罗湖，等口岸。口岸有过境bus直接买票就ok了。4.在香港那种寸土如金的地方，酒店当然很贵了，可以根据自己的情况来选择，一般便宜的300-400，贵的800+了，最好提前预定，并且搞清楚具体的街道，一般都是街道名+单元号+大厦名字+几楼几室，实在不行就锻炼一下交际能力了，香港人不会说普通话就很蛋疼了，不过可以向店家打听。5.可以在国内兑换适当的港币，在香港visa或者unionpay都是可以用的。6.香港可玩的地方：1)维多利亚港2)太平山顶3)铜锣湾1-3都在香港中环附近，如果你在尖沙咀这边抵达，可以选择地铁，轮渡过去，这里推荐轮渡，天星小轮，出了尖沙咀地铁站就可以看到了。维港晚上有灯光表演8点开始，所以我和小伙伴白天在维港走了一趟，放松一下心情，呼吸一下海水的味道，景色绝佳拍照绝佳毋庸置疑咯。夕阳将至，可以到太平山铁索缆车上山欣赏夕阳，用八达通45港币往返不算贵，坐缆车是一种奇特的体验，角度可以达到40度左右，整个人都倒在座椅上。山顶上有纪念品，还有很多餐厅以及蜡像馆可以玩。当然不得不提时光慢递了，一面墙上有366个格子，可以书写信投入，会在相应的日期寄出去，还挺有意义的。晚上我们找到酒店，吃完饭就去看了维港的灯光表演。由于比较匆忙这次并没有去湾仔看一下街景，据说都是高档的品牌店和餐厅。4）尖沙咀比较繁华的街道都在这段，酒店比较多也比较安全，还有各种外国餐厅，港茶。5）旺角这是一条买买买的街道，也很接地气，这里可以真切感受香港的老街道以及老居民区，说到购物，这里有化妆品，球鞋，日用品，手表，水族等等都是按照街道来分的，第一次去感觉自己都快审美疲劳了，当然还有卖唱一条街，以及街头的小游戏比如用铁环把倒得酒瓶立起来就可以得到玩偶什么的，总之准备好钱就可以来。6)九龙，兰桂坊很遗憾这次没有去地方，这两个地方有香港出名的酒吧街，晚上很多人嗨。人生一场旅行，兜兜转转，回归原地。我变了，我没变。 ——xubin]]></content>
      <categories>
        <category>旅行</category>
      </categories>
      <tags>
        <tag>旅行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB基本使用]]></title>
    <url>%2F2017%2F03%2F20%2FGDB%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[GDB简介GDB是UNIX及UNIX-like下的调试工具。或许，各位比较喜欢那种图形界面方式的，像VC、BCB等IDE的调试 ，但如 果你是在 UNIX平台下做软件，你会发现GDB这个调试工具有比VC、BCB的图形化调试器更强大的功能。所谓“寸有所长，尺有所短”就是这个道理。 基本指令GDB虽然指令比较多，但只要掌握基本的几个指令就可以调试程序了： file filename file加上生成的可执行文件 注意可执行文件编译时要加上-g 获取到一些调试信息，包括文件名变量名等 ，不然 调试都显示为地址。 list列出加载的源程序的所有代码，可能会有显示行数限制，通过help查看 break添加断点，简写为b，添加断点的几种方式：1.b 行号2.b 函数名3.b *代码地址 delete可简写为d，直接执行d删除所有断点，也可以加上断点号，删除指定断点。 next/step可简写为n/s,分别为单步跟踪和单步跳入调试。 run可简写为r，执行程序。 continue可简写为c，继续执行程序。 si/ni同s/n，只是会显示c语句相应的汇编程序，很强大。 print可简写为p，加上局部或全局变量名，打印当前值。 display/undisplay可以添加调试时显示的信息，比如汇编代码。执行display /i $pc,undisplay+编号取消自定义调试信息显示。 info显示固件或调试信息，常用info break显示所有断点信息，info r显示所有寄存器信息。 quit退出gdb环境。 helphelp加上指令名查看相应的指令帮助。 指令演示演示的示例程序如下：1234567891011121314151617181920212223#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int func(int loop)&#123; int i=0,result=0; for (int i = 1; i &lt; loop; ++i) &#123; result+=i; &#125;&#125;int main(int argc, char const *argv[])&#123; int i=0,sum=0,result=0; for (i=1;i&lt;=10;i++) &#123; sum+=i; &#125; i=20; result=func(20); printf("%d\n", sum); printf("%d\n", result); return 0;&#125; 首先需要将源程序编译成调试用的可执行文件1gcc gdbdemo.c -o gdbdemo -g -g的意义在将函数名变量名等加入到执行文件中，便于显示调试信息。然后输入gdb进入gdb调试环境1234567891011$ gdbGNU gdb (GDB) 7.6.1Copyright (C) 2013 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "mingw32".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.(gdb) 接下就是载入可调试的可执行文件12(gdb) file gdbdemo.exeReading symbols from C:\Users\Bin\Desktop\gdbѧϰ\gdbdemo.exe...done. 既然是调试当然要添加断点，我们用两种方式添加断点，并通过info break命令查看断点信息。12345678(gdb) b 14Breakpoint 1 at 0x401498: file gdbdemo.c, line 14.(gdb) b funcBreakpoint 2 at 0x401446: file gdbdemo.c, line 5.(gdb) info breakNum Type Disp Enb Address What1 breakpoint keep y 0x00401498 in main at gdbdemo.c:142 breakpoint keep y 0x00401446 in func at gdbdemo.c:5 成功添加断点后，就是执行run命令，然后单步调试，并通过print查看变量的值了。1234567(gdb) rStarting program: C:\Users\Bin\Desktop\gdbѧϰ/gdbdemo.exe[New Thread 6244.0x442c][New Thread 6244.0x5320]Breakpoint 1, main (argc=1, argv=0xe31560) at gdbdemo.c:1414 for (i=1;i&lt;=10;i++) 可以看到程序在断点一，14行停住了，并且输出了下面将要执行的语句123456789101112(gdb) s16 sum+=i;(gdb) s14 for (i=1;i&lt;=10;i++)(gdb) p sum$1 = 1(gdb) s16 sum+=i;(gdb) s14 for (i=1;i&lt;=10;i++)(gdb) p sum$2 = 3 执行单步调试，用p sum查看变量sum的值变化，符合预期的效果。下面执行continue，让程序继续执行到下一个断点。12345(gdb) cContinuing.Breakpoint 2, func (loop=20) at gdbdemo.c:55 int i=0,result=0; 程序执行到第二断点处了，我们用display演示输出汇编语句以及语句地址，并且用info r查看寄存器值。1234567(gdb) display /i $pc1: x/i $pc=&gt; 0x401446 &lt;func+6&gt;: movl $0x0,-0xc(%ebp)(gdb) s6 for (int i = 1; i &lt; loop; ++i)1: x/i $pc=&gt; 0x401454 &lt;func+20&gt;: movl $0x1,-0x8(%ebp) 12345678910111213141516171819(gdb) info reax 0xa 10ecx 0x401970 4200816edx 0x0 0ebx 0x38e000 3727360esp 0x61fef8 0x61fef8ebp 0x61ff08 0x61ff08esi 0x4012c0 4199104edi 0x4012c0 4199104eip 0x401454 0x401454 &lt;func+20&gt;eflags 0x202 [ IF ]cs 0x23 35ss 0x2b 43ds 0x2b 43es 0x2b 43fs 0x53 83gs 0x2b 43(gdb) info r eaxeax 0xa 10 可以看到相应的效果，gdb的功能果然很强大，基本上掌握上面的命令就够用了，如果还想学习对于多线程，守护进程调试以及其他知识，可以见参考[2]。 参考GDB十分钟教程：http://blog.csdn.net/liigo/article/details/582231linux c/c++ GDB教程详解：http://blog.csdn.net/nancygreen/article/details/16962467 有什么意见，问题请积极留言呦。]]></content>
      <categories>
        <category>编程工具</category>
      </categories>
      <tags>
        <tag>调试</tag>
        <tag>GDB</tag>
        <tag>linux c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[少年未老]]></title>
    <url>%2F2017%2F03%2F20%2F%E5%B0%91%E5%B9%B4%E6%9C%AA%E8%80%81%2F</url>
    <content type="text"><![CDATA[少年未老 要记得，生命极短。短到，用来做自己喜欢的事情，都不够；更不要说用来犹豫，以及妥协——尤其是，妥协给那些——你自己都清楚“这只是妥协”的东西。时光匆匆流逝，不知不觉武汉就进入雨季，透过夜晚的霓虹，空气中分不清是水汽还是雾霾。似乎难以想象一周前还是艳阳高照，做好了穿一件单衣的打算，苦笑。生活似乎有条不紊的进行着，但计划总是赶不上变化，有些事情既然做好了打算那就去尽快去做完，对于一个没有尝试的人来说，不管结局是失败还是成功，过程是苦涩还是欢喜，都只留下幻想，痛苦的遗憾。来华科快20天了，每天走同样的路，坐在同样的位置，辗转于几个食堂之间，很怕逆行于人群，这或许就是所谓的归属感，怕是要花很长一段时间去适应。曾经苦口婆心开导别人，语重心长来一套一套的我，似乎自己面对问题的时候，大部分都是选择逃避，既然一件做起来并不开心的事情还要逼自己的坚持呢，很多自己看似平常的特点或许可能是自己的闪光点，但我还是说服不来自己，好像踏上了奈何桥就没有回头路一般。和好友聊天中，我会意会到其实我并不是一个多么会交流的人，至少在一部分人看来，我骨子里不服输，好像欠缺一点谦逊的气质，但其实我喜欢并享受着竞争，我坚持自己的见解不轻易改变，很多时候我听到别人的建议，但我并不愿意那么快否定自己。毕业季即将来临，有的人从一个城市到另一个城市，有的人离开学校到企业，幸好大家都还活得体面，再一次聊天中，一位好友说明天出去走走，武汉最后一瞥，那一刻我觉得大家离各奔东西是如此的接近，不禁暗暗心伤，而我还要在武汉在另一所学校，完成属于我的使命，一个我也不知道是好是坏的使命。人看多了，就想要美景相伴独守清高，物看多了，就想要佳人相依超然物外，现在的状态，没有什么期盼，所以很想出去走走，看看世界的另一个角落。会不会偶遇那个梦里出现过得老爷爷，穿的破破烂烂不修边幅，来到我的桌前，默默的看着，看的我浑身难受，我就慷慨解囊给了他10块，不用谢，去兰州拉面吃一顿好的，我说，大爷并不接过钱，就在我纳闷的时候，大爷指着我的屏幕冒出一句，你这里好像少了一个括号吧。我跟好多朋友都说过，有时候不是因为喜欢一件事而付出努力，而是我们付出了太多的努力，所以我们从而喜欢。所以当你发现你是如此的喜欢一样东西一件事的时候，其实是你在物质或心理已经投资了足够多的精力，但是你没有得到自己的预期，所以要不就义无反顾的继续努力，要不就说服自己爱的不够，旧的不去新的不来。仔细回想，23岁的我，在父母面前以及那样的成长环境下，活的很乖，似乎成为他们眼中的好孩子已经成为一种思维惯性，我还有很多没有干过的事情，甚至以后可能都没有机会干了。在时间的转轮下，我们就这样的认真的老去了。 尚未佩妥剑，转眼便是江湖愿历尽千帆，归来仍是少年 但愿]]></content>
      <categories>
        <category>随口一说</category>
      </categories>
      <tags>
        <tag>心情</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c语言pthread学习]]></title>
    <url>%2F2017%2F03%2F19%2Fc%E8%AF%AD%E8%A8%80pthread%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[C语言pthread学习简介&nbsp;&nbsp;&nbsp;&nbsp;早期的多线程指的是一个进程只有一个线程，即多进程就是多线程，操作系统启动创建一个主线程在该线程下fork多个进程运行。&nbsp;&nbsp;&nbsp;&nbsp;后来一个进程中可以创建多个线程，相较于多进程来说，多线程程序主要有一下优势:1.创建一个进程需要为它分配响应的数据程序空间以及堆栈看空间，因为进程之间的空间是互相独立的，而开启线程的开销就小得多，各线程共享主线程的空间，并且线程之间的切换比进程容易得多。2.进程之间的数据共享必须通过通信的方式进行，而线程之间共享主线程的数据达到数据交换的目的，并且拥有自己的私有数据，比进程方便的多。 常用函数 int pthread_create(pthread_t thread,pthread_attr_t attr,void (start_routine)(void ),void arg);创建线程thread:线程标号与进程pid类似，用户只需要定义一个pthread_t类型的变量，将地址传给函数就可以。attr：线程参数，pthread_attr_t参数类型，将在以后章节讲解，不需要传NULL。start_routine:线程启动函数，定义为 void functionname(void arg)。arg:为启动函数的参数，为(void *)指针可以传基本类型和自定义结构体。调用该函数创建线程后，线程即启动，不需要像java中调用start()函数，成功返回0,否则返回错误编码。 int pthread_join(pthread_t thread,void **retval);阻塞线程，等待相应的线程执行完毕thread:等待的线程标号retval:线程返回值等待的线程结束后，可以通过retval来获取线程的返回值，注意同一个线程不能被多个线程等待，否则会出现一个阻塞函数成功返回0，别的出现错误标号。 void pthread_exit(void *retval);退出线程的方式：1.线程执行完毕2.别的线程取消该线程3.线程执行pthread_exit();retval：返回参数。 int pthread_cancel(pthread_t pthread);取消线程:只可以取消同一进程下的线程pthread:线程标号 void pthread_cleanup_push(void (routine)(void ),void *arg);在线程执行exit或者cancel，会先执行清理函数，这里可以手动添加自定义清理函数。routine:清理函数arg:清理函数参数函数被添加到线程的堆栈中，所以执行顺序与添加顺序相反。 void pthread_cleanup_pop(int execute);将栈顶的函数清除，如果execute=0不执行，否则执行该函数。 int pthread_detach(pthread_t pthread);线程分为分离和非分离状态，默认非分离，在子线程执行完，父线程没有显示调用join的情况下，会出现父线程没有及时释放子线程的信息，大量这种情况后会出现堆栈空间不足。当线程为分离状态时，线程不能被阻塞，执行完即自动释放所有信息。在使用上面的函数时，记得加上头文件#include ,在编译时，加上指令-lpthread，加上动态链接库。程序示例12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;void *threadroutine1(void *arg);void *threadroutine2(void *arg);int main(int argc,char **argv)&#123; pthread_t thread1; pthread_t thread2; void *str; pthread_create(&amp;thread1,NULL,threadroutine1,NULL); pthread_create(&amp;thread2,NULL,threadroutine2,NULL); int ret = pthread_join(thread1,&amp;str); if(ret==0)&#123; printf("%s\n",(char *)str); &#125;else&#123; printf("%s:%d\n","error",ret); &#125; ret = pthread_join(thread2,&amp;str); if(ret==0)&#123; printf("%s\n",(char *)str); &#125;else&#123; printf("%s:%d\n","error",ret); &#125; printf("%s\n","main end"); return 0;&#125;void *threadroutine1(void *arg)&#123; int i=0; for(i=0;i&lt;5;i++)&#123; printf("%s\n","thread1"); sleep(1); &#125; pthread_exit("thread1 exit....");&#125;void *threadroutine2(void *arg)&#123; int i=0; for(i=0;i&lt;5;i++)&#123; printf("%s\n","thread2"); sleep(1); &#125; pthread_exit("thread2 exit....");&#125; 运行结果：thread1thread2thread1thread2thread1thread2thread2thread1thread1thread2thread1 exit….thread2 exit….main end可以看到线程1和2之间相互竞争cpu导致输出不固定，主线程确实阻塞了等待子线程完成后输出子线程各自的返回值，然后输出main end。对于pthread_cancal和pthread_cleanup_push和pop的示例123456789101112131415161718192021222324252627282930313233#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;void clean1(void *arg)&#123; printf("%s\n","clean1");&#125;void clean2(void *arg)&#123; printf("%s\n","clean2");&#125;void *threadroutine(void *arg);int main(int argc,char **argv)&#123; pthread_t thread; pthread_create(&amp;thread,NULL,threadroutine,NULL); sleep(3); int ret=pthread_cancel(thread); if(ret!=0)&#123; printf("%s:%d\n","error",ret); &#125; ret=pthread_join(thread,NULL); if(ret!=0) &#123; printf("%s:%d\n","error",ret); &#125; return 0;&#125;void *threadroutine(void *arg)&#123; pthread_cleanup_push(clean1,NULL); pthread_cleanup_push(clean2,NULL); sleep(100); pthread_cleanup_pop(0); pthread_cleanup_pop(0);&#125; 结果：clean2clean1注意：这里面push与pop必须在函数中成双成对出现，并且遵循先进后除原则。清理函数执行的时机：1.显示的调用pthread_exit()。对于第三点比较难理解2.在cancel点线程被cancel并且通过join()或exit()销毁了进程。3.pthread_cleanup_pop()的参数不为0时。对于第三点比较难理解举个例子：1234567void *threadroutine(void *arg)&#123; pthread_cleanup_push(unlock,NULL); lock(); sleep(100); unlock();//目的是为了让这段程序总能解锁 pthread_cleanup_pop(0);//设想当线程沉睡时调用cancel()那么会调用unlock，而如果没有cancel，且这里参数非0,就会解锁2次，导致错误。&#125; 在举一个例子：1234567891011pthread_cleanup_push(clean,NULL);pthread_exit(NULL);pthread_cleanup_pop(0);//执行cleanpthread_cleanup_push(clean,NULL);pthread_cleanup_pop(0);//不执行cleanpthread_exit(NULL);pthread_cleanup_push(clean,NULL);pthread_cleanup_pop(1);//执行cleanpthread_exit(NULL); 参考http://www.cnblogs.com/chenyadong/archive/2011/10/25/2223610.htmlhttp://blog.sina.com.cn/s/blog_907af1fc0102v6y0.html]]></content>
      <categories>
        <category>C语言学习</category>
      </categories>
      <tags>
        <tag>Linux c</tag>
        <tag>多线程</tag>
        <tag>pthread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jerasure Library入门]]></title>
    <url>%2F2017%2F03%2F17%2FJerasure-Library%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Jerasure Library入门介绍Jerasure是由C语言编写的实现了纠删码编解码的开源库，提供了范德摩尔RS，柯西RS，优化柯西RS，以及针对RAID-6的Liberation,Liber8tion,Boomth编码，以及基于VRS的optRaid-6编码。纠删码起源通信中防止信息丢失，现在被广泛应用到存储系统中包括分布式存储系统，内存存储系统，闪存存储系统，磁盘阵列中，以防止系统出错导致的信息丢失，它的优点是：相较于传统的副本存储机制，一份数据在系统中复制三份存储，纠删码编码后数据有效的减少了冗余数据大小，并且拥有相同的容错率，有效减少存储空间，举个列子一块size为M的数据块，在副本机制中要占据3*M的空间，容错为2，而纠删码(6,2)系统来说，只占据1.3 M空间拥有相同容错，减少了40% 的空间，但 是它的缺陷是：在编解码上的耗时，以及增加了系统的网络负载。 github：https://github.com/tsuraan/Jerasuredoc：http://jerasure.org/jerasure-2.0/Online-home：http://jerasure.org/jerasure/jerasure 安装在github中打开或者项目首页中可看见最新的版本的是Jeraure2.0，通过README可以知道，为了增加Jerasure的灵活性，version2.0中将gf运算与编码库分离，所以使用Jeraure2.0之前，我需要先安装GF-Complete库。Online-home：http://jerasure.org/jerasure/gf-complete 123456git clone http://lab.jerasure.org/jerasure/gf-complete.gitcd gf-complete./autogen.sh #(如果通过tar包安装这步忽略)./congfiguremakesudo make install 在相关目录下(一般是/usr/local/lib和/usr/local/include),有相应的头文件以及.so库文件，即安装成功。 接下来安装Jeraure2.0：123456git clone http://lab.jerasure.org/jerasure/jerasure.gitcd jerasureautoreconf --force --install -I m4 #(如果通过tar包安装这步忽略)./configuremakesudo make install 同样的方法查看是否安装成功。 之后就可以在程序中应用头文件，并且通过 -lJeraure来链接库文件编译。 Jeraure2.0库的使用首先当然要仔细阅读文档地址上面已经给了，通过文档你可以对纠删码的编码流程有所了解，请务必知晓库中各参数的意义。我们主要阅读example文件夹下的encoder.c和decoder.c源文件，这两个文件中包含了所有编码的编解码过程 ，以及相关函数的调用，具体的API会在下一篇文章中讲解，这里我们运行生成的obj文件，看一下Jerasure纠删码的效果，达到一个直观的了解。encoder.o参数1./encoder "inputfilepath" k m "tech_method_name" w packetize buffersize inputfilepath:编码文件路径k:源数据块个数m:冗余块个数w:数据字长tech_method_name:{“reed_sol_van”, “reed_sol_r6_op”, “cauchy_orig”, “cauchy_good”, “liberation”, “blaum_roth”, “liber8tion”, “no_coding”};packetsize:数据块大小buffersize:数据缓冲区大小程序流程大致是：1.根据packetsize以及运行环境来调整buffersize，计算blocksize即每个块的大小，malloc空间2.根据不同的方法，准备编码矩阵/位矩阵/调度表3.根据不同的方法，执行不同的编码方法4.完成文件生成 编码1./encoder "/home/xubin/图片/test02.jpg" 4 2 "reed_sol_van" 8 8 1024 执行后,在相应的目录下，产生test02_k1.jpg，test02_k2.jpg，test02_k3.jpg，test02_k4.jpgtest02_m1.jpg，test02_m2.jpg,以及test02_meta.txt配置文件。 解码删除一个原始数据块和一个冗余块1./decoder "test02.jpg" 执行后在相对目录下，生成test02decoder.jpg可以看到命令的相应效率以及编码效率，对于各个编码的效率问题主要涉及到编码方法以及一吸血参数的选择上，会在以后的博客中对比讲解。有不解或错误的地方记得留言或者@我呀。]]></content>
      <categories>
        <category>纠删码</category>
      </categories>
      <tags>
        <tag>erasure code</tag>
        <tag>Jerasure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-java]]></title>
    <url>%2F2017%2F03%2F16%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95-java%2F</url>
    <content type="text"><![CDATA[排序算法快速排序 QuickSort快速排序是一个就地排序，分而治之，大规模递归的算法。从本质上来说，它是归并排序的就地版本。快速排序可以由下面四步组成。 （1） 如果不多于1个数据，直接返回。 （2） 一般选择序列最左边的值作为支点数据。 （3） 将序列分成2部分，一部分都大于支点数据，另外一部分都小于支点数据。 （4） 对两边利用递归排序数列。 快速排序比大部分排序算法都要快。尽管我们可以在某些特殊的情况下写出比快速排序快的算法，但是就通常情况而言，没有比它更快的了。快速排序是递归的，对于内存非常有限的机器来说，它不是一个好的选择。 归并排序 MergeSort归并排序先分解要排序的序列，从1分成2，2分成4，依次分解，当分解到只有1个一组的时候，就可以排序这些分组，然后依次合并回原来的序列中，这样就可以排序所有数据。合并排序比堆排序稍微快一点，但是需要比堆排序多一倍的内存空间，因为它需要一个额外的数组。 堆排序 HeapSort堆排序适合于数据量非常大的场合（百万数据）。堆排序不需要大量的递归或者多维的暂存数组。这对于数据量非常巨大的序列是合适的。比如超过数百万条记录，因为快速排序，归并排序都使用递归来设计算法，在数据量非常大的时候，可能会发生堆栈溢出错误。 堆排序会将所有的数据建成一个堆，最大的数据在堆顶，然后将堆顶数据和序列的最后一个数据交换。接下来再次重建堆，交换数据，依次下去，就可以排序所有的数据。 Shell排序 ShellSortShell排序通过将数据分成不同的组，先对每一组进行排序，然后再对所有的元素进行一次插入排序，以减少数据交换和移动的次数。平均效率是O(nlogn)。其中分组的合理性会对算法产生重要的影响。现在多用D.E.Knuth的分组方法。 Shell排序比冒泡排序快5倍，比插入排序大致快2倍。Shell排序比起QuickSort，MergeSort，HeapSort慢很多。但是它相对比较简单，它适合于数据量在5000以下并且速度并不是特别重要的场合。它对于数据量较小的数列重复排序是非常好的。 插入排序 InsertSort插入排序通过把序列中的值插入一个已经排序好的序列中，直到该序列的结束。插入排序是对冒泡排序的改进。它比冒泡排序快2倍。一般不用在数据大于1000的场合下使用插入排序，或者重复排序超过200数据项的序列。 冒泡排序 BubbleSort冒泡排序是最慢的排序算法。在实际运用中它是效率最低的算法。它通过一趟又一趟地比较数组中的每一个元素，使较大的数据下沉，较小的数据上升。它是O(n^2)的算法。 交换排序 ExchangeSort 和选择排序 SelectSort这两种排序方法都是交换方法的排序算法，效率都是 O(n2)。在实际应用中处于和冒泡排序基本相同的地位。它们只是排序算法发展的初级阶段，在实际中使用较少。 基数排序 RadixSort基数排序和通常的排序算法并不走同样的路线。它是一种比较新颖的算法，但是它只能用于整数的排序，如果我们要把同样的办法运用到浮点数上，我们必须了解浮点数的存储格式，并通过特殊的方式将浮点数映射到整数上，然后再映射回去，这是非常麻烦的事情，因此，它的使用同样也不多。而且，最重要的是，这样算法也需要较多的存储空间。 总结 Java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296package com.whut.sort;/** * 排序算法 * @author Bin * */public class SortUtils &#123;private static int[] t;// 全局的样本// 此处之排列int类型。。。/** * 冒泡排序 * * @param data * @return */public static int[] bublleSort(int[] data) &#123; int len = data.length; for (int i = 1; i &lt; len; i++) &#123; for (int j = len - 1; j &gt;= i; j--) &#123; if (data[j] &lt; data[j - 1]) &#123; int temp = data[j - 1]; data[j - 1] = data[j]; data[j] = temp; &#125; &#125; &#125; return data;&#125;/** * 优化的冒泡排序 * * @param data * @return */public static int[] optbublleSort(int[] data) &#123; int len = data.length; for (int i = 1; i &lt; len; i++) &#123; boolean flag = false;// 设置一个标志，若不变说明已排序完成 for (int j = len - 1; j &gt;= i; j--) &#123; if (data[j] &lt; data[j - 1]) &#123; flag = true; int temp = data[j - 1]; data[j - 1] = data[j]; data[j] = temp; &#125; &#125; if (flag == false) &#123; return data; &#125; &#125; return data;&#125;/** * 直接插入排序 * * @param data * @return */public static int[] insertSort(int[] data) &#123; int left = 0, right = data.length; // 2 3 4 1 for (int i = left + 1; i &lt; right; i++) &#123; int temp = data[i]; for (int j = 0; j &lt; i; j++) &#123; if (temp &lt; data[j]) &#123; // 交换 int t = i - 1; do &#123; data[t + 1] = data[t]; t--; &#125; while (t &gt; j - 1); data[j] = temp; break; &#125; &#125; &#125; return data;&#125;/** * 搜索插入的位置对排序部分使用二分搜索法 * * @param data * @return */public static int[] binaryInsertSort(int[] data) &#123; int left = 0, right = data.length; for (int i = left + 1; i &lt; right; i++) &#123; int temp = data[i]; int low = 0, high = i - 1, mid; while (low &lt;= high) &#123; mid = (low + high) / 2; if (temp &lt; data[mid]) &#123; high = mid - 1; &#125; else &#123; low = mid + 1; &#125; &#125; for (int k = i; k &gt; low; k--) &#123; data[k] = data[k - 1]; &#125; data[low] = temp; &#125; return data;&#125;/** * 希尔排序 适合于大数据排序 用gap间隔gap缩小到一排序完成，后续排序在前面的基础上，开始gap较大，数据小排序快。 * * @param data * @return */public static int[] shellSort(int[] data) &#123; int left = 0, right = data.length; int gap = right - left; do &#123; gap = gap / 3 + 1; for (int i = gap + left; i &lt; right; i++) &#123; int temp = data[i]; if (temp &lt; data[i - gap]) &#123; int j = i - gap; do &#123; data[j + gap] = data[j]; j = j - gap; &#125; while (j &gt;= left &amp;&amp; temp &lt; data[j]); data[j + gap] = temp; &#125; &#125; &#125; while (gap &gt; 1); return data;&#125;/** * 快速排序 一个递归过程 分块处理 优化方法：对于小规模的数组直接用插入排序，或者先忽略小规模数组，拍完后整体用插入排序。 * 可在头尾中间端选取中间值作为基准元素防止左右划分严重不平衡。所以说快排以来与数据输入的顺序。 * * @param data * @return */public static int[] quickSort(int[] data) &#123; t = data; quickSort(0, data.length - 1); return t;&#125;private static void quickSort(int left, int right) &#123; if (left &lt; right) &#123; int pos = getPos(left, right); quickSort(left, pos - 1); quickSort(pos + 1, right); &#125;&#125;private static int getPos(int left, int right) &#123; int temp = t[left]; int pos = left; for (int i = left + 1; i &lt;= right; i++) &#123; if (temp &gt; t[i]) &#123; pos++; if (pos != i) &#123; int tt = t[pos]; t[pos] = t[i]; t[i] = tt; &#125; &#125; &#125; t[left] = t[pos]; t[pos] = temp; return pos;&#125;/** * 选择排序 * * @param data * @return */public static int[] selectSort(int[] data) &#123; int len = data.length; for (int i = 1; i &lt; len; i++) &#123; int temp = data[i - 1]; for (int j = i; j &lt; len; j++) &#123; if (data[j] &lt; temp) &#123; temp = data[j]; data[j] = data[i - 1]; data[i - 1] = temp; &#125; &#125; &#125; return data;&#125;/** * 堆排序 * * @param data * @return */public static int[] heapSort(int[] data) &#123; t = data; int len = data.length; int currentPos = (len - 2) / 2; while (currentPos &gt;= 0) &#123; shiftDown(currentPos, len - 1); currentPos--; &#125; for (int i = len - 1; i &gt;= 0; i--) &#123; int temp = t[i]; t[i] = t[0]; t[0] = temp; shiftDown(0, i - 1); &#125; return t;&#125;/** * 对堆的currentPos位进行下滑调整 构造最大堆 * * @param currentPos */private static void shiftDown(int currentPos, int end) &#123; int i = currentPos; int j = 2 * i + 1; int temp = t[i];// 可能需要下滑的点 while (j &lt;= end) &#123; if (j + 1 &lt;= end &amp;&amp; t[j + 1] &gt; t[j]) &#123; j++; &#125; if (temp &gt;= t[j]) &#123; break; &#125; else &#123; t[i] = t[j]; i = j; j = 2 * j + 1; &#125; &#125; t[i] = temp;&#125;/** * 归并排序 * * @param data * @return */public static int[] mergeSort(int[] data) &#123; int left = 0; int right = data.length - 1; t = data; mergeSort(left, right); return t;&#125;private static void mergeSort(int left, int right) &#123; if (left &gt;= right) return; int mid = (left + right) / 2; mergeSort(left, mid); mergeSort(mid + 1, right); merge(left, mid, right);&#125;private static void merge(int left, int mid, int right) &#123; int[] temp = new int[t.length]; for (int m = 0; m &lt; t.length; m++) &#123; temp[m] = t[m]; &#125; int i = left; int j = mid + 1; int k = left; while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (temp[i] &lt; temp[j]) &#123; t[k++] = temp[i++]; &#125; else &#123; t[k++] = temp[j++]; &#125; &#125; while (i &lt;= mid) &#123; t[k++] = temp[i++]; &#125; while (j &lt;= right) &#123; t[k++] = temp[j++]; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MY first blog]]></title>
    <url>%2F2017%2F03%2F14%2FMY-first-blog%2F</url>
    <content type="text"><![CDATA[这是我的第一篇博客，从这里就开启了我的博客之旅了。]]></content>
      <categories>
        <category>随口一说</category>
      </categories>
      <tags>
        <tag>Welcome</tag>
      </tags>
  </entry>
</search>
